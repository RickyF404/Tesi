{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "zLJigUu7FnVd",
        "OgvCePDBN037",
        "76PI-5qYP4ZK"
      ],
      "mount_file_id": "1b1i2A70GMgkaGORQJ5y6jv2USo7lzfuK",
      "authorship_tag": "ABX9TyMPRoWwZj5/MCLjDsztSF+D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RickyF404/Tesi/blob/main/Dataset_inclinometri.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.svm import OneClassSVM\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import gdown\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Layer"
      ],
      "metadata": {
        "id": "h9IGVcgBEVxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url_inc = \"https://drive.google.com/uc?id=1jZZ7Oje34Rj_H0_R7SkHntEhu2KZv_It\"\n",
        "output_inc = \"data_inc.csv\"\n",
        "gdown.download(url_inc, output_inc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "WnXS4DXVEbZj",
        "outputId": "f1a3c560-afa3-4b7f-95f0-8ed8301357d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1jZZ7Oje34Rj_H0_R7SkHntEhu2KZv_It\n",
            "To: /content/data_inc.csv\n",
            "100%|██████████| 2.59M/2.59M [00:00<00:00, 74.7MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'data_inc.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_inc = pd.read_csv(\"/content/data_inc.csv\", encoding = \"utf-8\")\n",
        "\n",
        "mapping = {\n",
        "    \"I_P01_01_C_X\": \"Mode 1\",\n",
        "    \"I_P01_01_C_Y\": \"Mode 2\",\n",
        "    \"I_P02_01_C_X\": \"Mode 3\",\n",
        "    \"I_P02_01_C_Y\": \"Mode 4\",\n",
        "    \"I_P03_01_C_X\": \"Mode 5\",\n",
        "    \"I_P03_01_C_Y\": \"Mode 6\",\n",
        "}\n",
        "\n",
        "df_inc = df_inc.rename(columns=mapping)\n",
        "\n",
        "df_inc[\"timestamp\"] = pd.to_datetime(df_inc[\"timestamp\"])\n",
        "df_inc[\"timestamp\"] = df_inc[\"timestamp\"].dt.tz_localize(None)\n",
        "df_inc = df_inc.sort_values(\"timestamp\")\n",
        "\n",
        "percentuale_nan = (df_inc.isna().sum() / len(df_inc)) * 100\n",
        "\n",
        "print(\"Percentuale di NaN per colonna:\")\n",
        "print(percentuale_nan)\n",
        "\n",
        "df_inc = df_inc.set_index('timestamp')\n",
        "\n",
        "# interpolazione temporale\n",
        "df_inc = df_inc.interpolate(method='time')\n",
        "\n",
        "df_inc = df_inc.reset_index()\n",
        "\n",
        "end = \"2025-01-01\"\n",
        "df = df_inc[(df_inc[\"timestamp\"] < end)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3BBdaovN7v-",
        "outputId": "3bcf388d-577b-4ad9-baa2-8ca6e552d9da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentuale di NaN per colonna:\n",
            "Unnamed: 0    0.000000\n",
            "timestamp     0.000000\n",
            "Mode 1        1.021038\n",
            "Mode 2        1.025155\n",
            "Mode 3        0.065873\n",
            "Mode 4        0.065873\n",
            "Mode 5        0.374655\n",
            "Mode 6        0.374655\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_fake_month(df, frac_per_month, random_state):\n",
        "  rng = np.random.default_rng(seed=random_state) # generatore casuale con seed\n",
        "  df[\"day\"] = df[\"timestamp\"].dt.floor(\"D\")\n",
        "  df[\"year_month\"] = df[\"timestamp\"].dt.to_period(\"M\")\n",
        "  train_indices = []\n",
        "\n",
        "  for ym, group in df.groupby(\"year_month\"):\n",
        "    days = group[\"day\"].unique()\n",
        "    n_take = max(1, int(len(days) * frac_per_month))\n",
        "    sampled_days = rng.choice(days, size=n_take, replace=False)\n",
        "    sel = group[group[\"day\"].isin(sampled_days)].index.tolist()\n",
        "    train_indices += sel\n",
        "\n",
        "  train_df = df.loc[train_indices].copy()\n",
        "  valid_df = df.drop(index=train_indices).copy()\n",
        "  train_df = train_df.drop(columns=[\"day\", \"year_month\"])\n",
        "  valid_df = valid_df.drop(columns=[\"day\", \"year_month\"])\n",
        "  train_df = train_df.sort_values(\"timestamp\")\n",
        "  valid_df = valid_df.sort_values(\"timestamp\")\n",
        "\n",
        "  return train_df, valid_df"
      ],
      "metadata": {
        "id": "J5piXbfIOLVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PCA"
      ],
      "metadata": {
        "id": "zLJigUu7FnVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def anomaly_rate_PCA(train_df, valid_df, features):\n",
        "  scaler = StandardScaler()\n",
        "  # scaler = RobustScaler()\n",
        "  X_train = scaler.fit_transform(train_df[features])\n",
        "  X_val = scaler.transform(valid_df[features])\n",
        "\n",
        "  pca = PCA(n_components = 0.95)\n",
        "  X_train_pca = pca.fit_transform(X_train)\n",
        "  X_train_reconstructed = pca.inverse_transform(X_train_pca)\n",
        "  train_err = np.mean((X_train - X_train_reconstructed)**2, axis = 1)\n",
        "  threshold = np.percentile(train_err, 98.5)\n",
        "\n",
        "  X_val_pca = pca.transform(X_val)\n",
        "  X_val_reconstructed = pca.inverse_transform(X_val_pca)\n",
        "  val_err = np.mean((X_val - X_val_reconstructed)**2, axis = 1)\n",
        "  anomaly_rate = np.mean(val_err > threshold)\n",
        "\n",
        "  return anomaly_rate"
      ],
      "metadata": {
        "id": "PhDzWbC7Fv64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_df = df[(df[\"timestamp\"] >= train_start) & (df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  valid_df = df[~df[\"timestamp\"].isin(train_df[\"timestamp\"])]\n",
        "\n",
        "  anomaly = anomaly_rate_PCA(train_df, valid_df, features)\n",
        "\n",
        "  train_months = sorted(train_df[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "\n",
        "  results.append({\"train_months\": [str(x) for x in train_months] , \"window_size\": len(train_months), \"anomaly rate\": anomaly})\n",
        "\n",
        "results_df_2m_PCA = pd.DataFrame(results)\n",
        "print(results_df_2m_PCA)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyTcR8vkF1BC",
        "outputId": "73558ccc-a35d-476e-e2a6-0996555dfe6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          train_months  window_size  anomaly rate\n",
            "0   [2023-01, 2023-02]            2      0.973144\n",
            "1   [2023-02, 2023-03]            2      0.880097\n",
            "2   [2023-03, 2023-04]            2      0.875854\n",
            "3   [2023-04, 2023-05]            2      0.839577\n",
            "4   [2023-05, 2023-06]            2      0.625249\n",
            "5   [2023-06, 2023-07]            2      0.886005\n",
            "6   [2023-07, 2023-08]            2      0.829417\n",
            "7   [2023-08, 2023-09]            2      0.726599\n",
            "8   [2023-09, 2023-10]            2      0.914651\n",
            "9   [2023-10, 2023-11]            2      0.964980\n",
            "10  [2023-11, 2023-12]            2      0.917455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_df = df[(df[\"timestamp\"] >= train_start) & (df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  valid_df = df[~df[\"timestamp\"].isin(train_df[\"timestamp\"])]\n",
        "\n",
        "  anomaly = anomaly_rate_PCA(train_df, valid_df, features)\n",
        "\n",
        "  train_months = sorted(train_df[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "\n",
        "  results.append({\"train_months\": [str(x) for x in train_months] , \"window_size\": len(train_months), \"anomaly rate\": anomaly})\n",
        "\n",
        "results_df_4m_PCA = pd.DataFrame(results)\n",
        "print(results_df_4m_PCA)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNGWadZfF3q3",
        "outputId": "0f076b13-1869-4808-8d57-428cb686a31b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                           train_months  window_size  anomaly rate\n",
            "0  [2023-01, 2023-02, 2023-03, 2023-04]            4      0.979952\n",
            "1  [2023-02, 2023-03, 2023-04, 2023-05]            4      0.921442\n",
            "2  [2023-03, 2023-04, 2023-05, 2023-06]            4      0.889820\n",
            "3  [2023-04, 2023-05, 2023-06, 2023-07]            4      0.802832\n",
            "4  [2023-05, 2023-06, 2023-07, 2023-08]            4      0.573937\n",
            "5  [2023-06, 2023-07, 2023-08, 2023-09]            4      0.645421\n",
            "6  [2023-07, 2023-08, 2023-09, 2023-10]            4      0.879128\n",
            "7  [2023-08, 2023-09, 2023-10, 2023-11]            4      0.925893\n",
            "8  [2023-09, 2023-10, 2023-11, 2023-12]            4      0.847549\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_df = df[(df[\"timestamp\"] >= train_start) & (df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  valid_df = df[~df[\"timestamp\"].isin(train_df[\"timestamp\"])]\n",
        "\n",
        "  anomaly = anomaly_rate_PCA(train_df, valid_df, features)\n",
        "\n",
        "  train_months = sorted(train_df[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "\n",
        "  results.append({\"train_months\": [str(x) for x in train_months] ,  \"window_size\": len(train_months), \"anomaly rate\": anomaly})\n",
        "\n",
        "results_df_6m_PCA = pd.DataFrame(results)\n",
        "print(results_df_6m_PCA)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXKzMokuF6AE",
        "outputId": "aa9212a4-89a7-41cc-b899-7273d26b6ae9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                        train_months  window_size  \\\n",
            "0  [2023-01, 2023-02, 2023-03, 2023-04, 2023-05, ...            6   \n",
            "1  [2023-02, 2023-03, 2023-04, 2023-05, 2023-06, ...            6   \n",
            "2  [2023-03, 2023-04, 2023-05, 2023-06, 2023-07, ...            6   \n",
            "3  [2023-04, 2023-05, 2023-06, 2023-07, 2023-08, ...            6   \n",
            "4  [2023-05, 2023-06, 2023-07, 2023-08, 2023-09, ...            6   \n",
            "5  [2023-06, 2023-07, 2023-08, 2023-09, 2023-10, ...            6   \n",
            "6  [2023-07, 2023-08, 2023-09, 2023-10, 2023-11, ...            6   \n",
            "\n",
            "   anomaly rate  \n",
            "0      0.983343  \n",
            "1      0.908405  \n",
            "2      0.855312  \n",
            "3      0.806559  \n",
            "4      0.718390  \n",
            "5      0.874790  \n",
            "6      0.910440  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results_2m_fake = []\n",
        "train_df, valid_df = create_fake_month(df_inc, frac_per_month=0.1, random_state=42)\n",
        "\n",
        "print(\"Giorni training:\", train_df[\"timestamp\"].dt.date.nunique())\n",
        "print(\"Giorni validation:\", valid_df[\"timestamp\"].dt.date.nunique())\n",
        "\n",
        "anomaly = anomaly_rate_PCA(train_df, valid_df, features)\n",
        "results_2m_fake.append({\"window_size\": 2, \"anomaly\": anomaly})\n",
        "\n",
        "results_df_2m_fake_PCA = pd.DataFrame(results_2m_fake)\n",
        "print(results_df_2m_fake_PCA)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cD9PA11iF72c",
        "outputId": "31c63584-feb1-4894-dfda-2e153f790f65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Giorni training: 86\n",
            "Giorni validation: 833\n",
            "   window_size   anomaly\n",
            "0            2  0.027422\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results_4m_fake = []\n",
        "\n",
        "train_df, valid_df = create_fake_month(df_inc, frac_per_month=0.2, random_state=42)\n",
        "\n",
        "print(\"Giorni training:\", train_df[\"timestamp\"].dt.date.nunique())\n",
        "print(\"Giorni validation:\", valid_df[\"timestamp\"].dt.date.nunique())\n",
        "\n",
        "anomaly = anomaly_rate_PCA(train_df, valid_df, features)\n",
        "results_4m_fake.append({\"window_size\": 4, \"anomaly\": anomaly})\n",
        "\n",
        "results_df_4m_fake_PCA = pd.DataFrame(results_4m_fake)\n",
        "print(results_df_4m_fake_PCA)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwnSnWykF-CD",
        "outputId": "eb13b47b-7349-46f3-a090-f6ba8d6d137b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Giorni training: 177\n",
            "Giorni validation: 742\n",
            "   window_size   anomaly\n",
            "0            4  0.010725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results_6m_fake = []\n",
        "\n",
        "train_df, valid_df = create_fake_month(df_inc, frac_per_month=0.3, random_state=42)\n",
        "\n",
        "print(\"Giorni training:\", train_df[\"timestamp\"].dt.date.nunique())\n",
        "print(\"Giorni validation:\", valid_df[\"timestamp\"].dt.date.nunique())\n",
        "\n",
        "anomaly = anomaly_rate_PCA(train_df, valid_df, features)\n",
        "results_6m_fake.append({\"window_size\": 6, \"anomaly\": anomaly})\n",
        "\n",
        "results_df_6m_fake_PCA = pd.DataFrame(results_6m_fake)\n",
        "print(results_df_6m_fake_PCA)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqQ6K-lxGA0N",
        "outputId": "c5841a17-a393-46a5-aa09-a0db241533dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Giorni training: 268\n",
            "Giorni validation: 651\n",
            "   window_size   anomaly\n",
            "0            6  0.008764\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# salvataggio dei risultati PCA\n",
        "# real_results_df_PCA = pd.concat([results_df_2m_PCA, results_df_4m_PCA, results_df_6m_PCA])\n",
        "# real_results_df_PCA.to_csv(\"/content/drive/MyDrive/real_inclinometri_PCA.csv\", index=False)\n",
        "\n",
        "# fake_results_df_PCA = pd.concat([results_df_2m_fake_PCA, results_df_4m_fake_PCA, results_df_6m_fake_PCA])\n",
        "# fake_results_df_PCA.to_csv(\"/content/drive/MyDrive/fake_inclinometri_PCA.csv\", index=False)"
      ],
      "metadata": {
        "id": "YMpV_i7NM9ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM"
      ],
      "metadata": {
        "id": "OgvCePDBN037"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def anomaly_rate_SVM(train_df, valid_df, features):\n",
        "  scaler = StandardScaler()\n",
        "  # scaler = RobustScaler()\n",
        "  X_train = scaler.fit_transform(train_df[features])\n",
        "  X_val = scaler.transform(valid_df[features])\n",
        "\n",
        "  ocsvm = OneClassSVM(kernel=\"rbf\", nu=0.01, gamma=0.01)\n",
        "  ocsvm.fit(X_train)\n",
        "\n",
        "  preds = ocsvm.predict(X_val)\n",
        "  anomaly_rate = np.mean(preds == -1)\n",
        "\n",
        "  return anomaly_rate"
      ],
      "metadata": {
        "id": "ZTgpx0caN4WG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_df = df[(df[\"timestamp\"] >= train_start) & (df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  valid_df = df[~df[\"timestamp\"].isin(train_df[\"timestamp\"])]\n",
        "\n",
        "  anomaly = anomaly_rate_SVM(train_df, valid_df, features)\n",
        "\n",
        "  train_months = sorted(train_df[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "\n",
        "  results.append({\"train_months\": [str(x) for x in train_months] , \"window_size\": len(train_months), \"anomaly rate\": anomaly})\n",
        "\n",
        "results_df_2m_SVM = pd.DataFrame(results)\n",
        "print(results_df_2m_SVM)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rw-kiJ7QOQIP",
        "outputId": "7b07664f-2493-4a3f-ae87-dcf4d7436967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          train_months  window_size  anomaly rate\n",
            "0   [2023-01, 2023-02]            2      0.935520\n",
            "1   [2023-02, 2023-03]            2      0.920559\n",
            "2   [2023-03, 2023-04]            2      0.931890\n",
            "3   [2023-04, 2023-05]            2      0.940693\n",
            "4   [2023-05, 2023-06]            2      0.987146\n",
            "5   [2023-06, 2023-07]            2      0.948760\n",
            "6   [2023-07, 2023-08]            2      0.964297\n",
            "7   [2023-08, 2023-09]            2      0.980950\n",
            "8   [2023-09, 2023-10]            2      0.942378\n",
            "9   [2023-10, 2023-11]            2      0.975728\n",
            "10  [2023-11, 2023-12]            2      0.990483\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_df = df[(df[\"timestamp\"] >= train_start) & (df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  valid_df = df[~df[\"timestamp\"].isin(train_df[\"timestamp\"])]\n",
        "\n",
        "  anomaly = anomaly_rate_SVM(train_df, valid_df, features)\n",
        "\n",
        "  train_months = sorted(train_df[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "\n",
        "  results.append({\"train_months\": [str(x) for x in train_months] , \"window_size\": len(train_months), \"anomaly rate\": anomaly})\n",
        "\n",
        "results_df_4m_SVM = pd.DataFrame(results)\n",
        "print(results_df_4m_SVM)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZdD6F91OctS",
        "outputId": "d7668e3c-74ad-4bff-f5a7-6e62885829e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                           train_months  window_size  anomaly rate\n",
            "0  [2023-01, 2023-02, 2023-03, 2023-04]            4      0.993937\n",
            "1  [2023-02, 2023-03, 2023-04, 2023-05]            4      0.945603\n",
            "2  [2023-03, 2023-04, 2023-05, 2023-06]            4      0.896966\n",
            "3  [2023-04, 2023-05, 2023-06, 2023-07]            4      0.831537\n",
            "4  [2023-05, 2023-06, 2023-07, 2023-08]            4      0.968461\n",
            "5  [2023-06, 2023-07, 2023-08, 2023-09]            4      0.988293\n",
            "6  [2023-07, 2023-08, 2023-09, 2023-10]            4      0.931371\n",
            "7  [2023-08, 2023-09, 2023-10, 2023-11]            4      0.918030\n",
            "8  [2023-09, 2023-10, 2023-11, 2023-12]            4      0.995464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_df = df[(df[\"timestamp\"] >= train_start) & (df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  valid_df = df[~df[\"timestamp\"].isin(train_df[\"timestamp\"])]\n",
        "\n",
        "  anomaly = anomaly_rate_SVM(train_df, valid_df, features)\n",
        "\n",
        "  train_months = sorted(train_df[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "\n",
        "  results.append({\"train_months\": [str(x) for x in train_months] ,  \"window_size\": len(train_months), \"anomaly rate\": anomaly})\n",
        "\n",
        "results_df_6m_SVM = pd.DataFrame(results)\n",
        "print(results_df_6m_SVM)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lCWcVFlOkHa",
        "outputId": "c809e971-0035-4894-cfde-369f3a94f2a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                        train_months  window_size  \\\n",
            "0  [2023-01, 2023-02, 2023-03, 2023-04, 2023-05, ...            6   \n",
            "1  [2023-02, 2023-03, 2023-04, 2023-05, 2023-06, ...            6   \n",
            "2  [2023-03, 2023-04, 2023-05, 2023-06, 2023-07, ...            6   \n",
            "3  [2023-04, 2023-05, 2023-06, 2023-07, 2023-08, ...            6   \n",
            "4  [2023-05, 2023-06, 2023-07, 2023-08, 2023-09, ...            6   \n",
            "5  [2023-06, 2023-07, 2023-08, 2023-09, 2023-10, ...            6   \n",
            "6  [2023-07, 2023-08, 2023-09, 2023-10, 2023-11, ...            6   \n",
            "\n",
            "   anomaly rate  \n",
            "0      0.997113  \n",
            "1      0.883471  \n",
            "2      0.848613  \n",
            "3      0.852796  \n",
            "4      0.926990  \n",
            "5      0.912998  \n",
            "6      0.938652  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results_2m_fake = []\n",
        "train_df, valid_df = create_fake_month(df_inc, frac_per_month=0.1, random_state=42)\n",
        "\n",
        "print(\"Giorni training:\", train_df[\"timestamp\"].dt.date.nunique())\n",
        "print(\"Giorni validation:\", valid_df[\"timestamp\"].dt.date.nunique())\n",
        "\n",
        "anomaly = anomaly_rate_SVM(train_df, valid_df, features)\n",
        "results_2m_fake.append({\"window_size\": 2, \"anomaly\": anomaly})\n",
        "\n",
        "results_df_2m_fake_SVM = pd.DataFrame(results_2m_fake)\n",
        "print(results_df_2m_fake_SVM)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9mrt9PZOxuw",
        "outputId": "f673a5db-3c11-40cc-f5b3-3a44bb1f22f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Giorni training: 86\n",
            "Giorni validation: 833\n",
            "   window_size   anomaly\n",
            "0            2  0.010823\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results_4m_fake = []\n",
        "\n",
        "train_df, valid_df = create_fake_month(df_inc, frac_per_month=0.2, random_state=42)\n",
        "\n",
        "print(\"Giorni training:\", train_df[\"timestamp\"].dt.date.nunique())\n",
        "print(\"Giorni validation:\", valid_df[\"timestamp\"].dt.date.nunique())\n",
        "\n",
        "anomaly = anomaly_rate_SVM(train_df, valid_df, features)\n",
        "results_4m_fake.append({\"window_size\": 4, \"anomaly\": anomaly})\n",
        "\n",
        "results_df_4m_fake_SVM = pd.DataFrame(results_4m_fake)\n",
        "print(results_df_4m_fake_SVM)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSGrfuyUO0El",
        "outputId": "de8574cf-8eaf-4dc0-f839-932f86ed2698"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Giorni training: 177\n",
            "Giorni validation: 742\n",
            "   window_size   anomaly\n",
            "0            4  0.006252\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results_6m_fake = []\n",
        "\n",
        "train_df, valid_df = create_fake_month(df_inc, frac_per_month=0.3, random_state=42)\n",
        "\n",
        "print(\"Giorni training:\", train_df[\"timestamp\"].dt.date.nunique())\n",
        "print(\"Giorni validation:\", valid_df[\"timestamp\"].dt.date.nunique())\n",
        "\n",
        "anomaly = anomaly_rate_SVM(train_df, valid_df, features)\n",
        "results_6m_fake.append({\"window_size\": 6, \"anomaly\": anomaly})\n",
        "\n",
        "results_df_6m_fake_SVM = pd.DataFrame(results_6m_fake)\n",
        "print(results_df_6m_fake_SVM)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4qkbenCO21W",
        "outputId": "122c6bc7-8f86-4bd3-9139-a601a383efda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Giorni training: 268\n",
            "Giorni validation: 651\n",
            "   window_size   anomaly\n",
            "0            6  0.011782\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# salvataggio dei risultati SVM\n",
        "real_results_df_SVM = pd.concat([results_df_2m_SVM, results_df_4m_SVM, results_df_6m_SVM])\n",
        "real_results_df_SVM.to_csv(\"/content/drive/MyDrive/real_inclinometri_SVM.csv\", index=False)\n",
        "\n",
        "fake_results_df_SVM = pd.concat([results_df_2m_fake_SVM, results_df_4m_fake_SVM, results_df_6m_fake_SVM])\n",
        "fake_results_df_SVM.to_csv(\"/content/drive/MyDrive/fake_inclinometri_SVM.csv\", index=False)"
      ],
      "metadata": {
        "id": "-lDcGs6-O5OK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LOF"
      ],
      "metadata": {
        "id": "76PI-5qYP4ZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def anomaly_rate_LOF(train_df, valid_df, features, n_neighbors=20, contamination=0.01):\n",
        "  scaler = StandardScaler()\n",
        "  # scaler = RobustScaler()\n",
        "  X_train = scaler.fit_transform(train_df[features])\n",
        "  X_valid = scaler.transform(valid_df[features])\n",
        "\n",
        "  lof = LocalOutlierFactor(n_neighbors=n_neighbors, contamination=contamination, novelty=True)\n",
        "  lof.fit(X_train)\n",
        "\n",
        "  y_pred = lof.predict(X_valid)\n",
        "  anomaly_rate = np.mean(y_pred == -1)\n",
        "  return anomaly_rate"
      ],
      "metadata": {
        "id": "sICgrpXaP6Lj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_df = df[(df[\"timestamp\"] >= train_start) & (df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  valid_df = df[~df[\"timestamp\"].isin(train_df[\"timestamp\"])]\n",
        "\n",
        "  anomaly = anomaly_rate_LOF(train_df, valid_df, features)\n",
        "\n",
        "  train_months = sorted(train_df[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "\n",
        "  results.append({\"train_months\": [str(x) for x in train_months] , \"window_size\": len(train_months), \"anomaly rate\": anomaly})\n",
        "\n",
        "results_df_2m_LOF = pd.DataFrame(results)\n",
        "print(results_df_2m_LOF)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Iaw5o7nQDyY",
        "outputId": "e1bf571a-bc6d-4e35-add8-1c7c3aca6e34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          train_months  window_size  anomaly rate\n",
            "0   [2023-01, 2023-02]            2      0.975743\n",
            "1   [2023-02, 2023-03]            2      0.930830\n",
            "2   [2023-03, 2023-04]            2      0.956951\n",
            "3   [2023-04, 2023-05]            2      0.941339\n",
            "4   [2023-05, 2023-06]            2      0.981864\n",
            "5   [2023-06, 2023-07]            2      0.975995\n",
            "6   [2023-07, 2023-08]            2      0.980897\n",
            "7   [2023-08, 2023-09]            2      0.993415\n",
            "8   [2023-09, 2023-10]            2      0.979690\n",
            "9   [2023-10, 2023-11]            2      0.981929\n",
            "10  [2023-11, 2023-12]            2      0.989628\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_df = df[(df[\"timestamp\"] >= train_start) & (df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  valid_df = df[~df[\"timestamp\"].isin(train_df[\"timestamp\"])]\n",
        "\n",
        "  anomaly = anomaly_rate_LOF(train_df, valid_df, features)\n",
        "\n",
        "  train_months = sorted(train_df[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "\n",
        "  results.append({\"train_months\": [str(x) for x in train_months] , \"window_size\": len(train_months), \"anomaly rate\": anomaly})\n",
        "\n",
        "results_df_4m_LOF = pd.DataFrame(results)\n",
        "print(results_df_4m_LOF)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i62fZsNbQHIO",
        "outputId": "7266ad29-e165-42e7-ebd8-149fa932e5ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                           train_months  window_size  anomaly rate\n",
            "0  [2023-01, 2023-02, 2023-03, 2023-04]            4      0.992559\n",
            "1  [2023-02, 2023-03, 2023-04, 2023-05]            4      0.935701\n",
            "2  [2023-03, 2023-04, 2023-05, 2023-06]            4      0.922367\n",
            "3  [2023-04, 2023-05, 2023-06, 2023-07]            4      0.923107\n",
            "4  [2023-05, 2023-06, 2023-07, 2023-08]            4      0.974054\n",
            "5  [2023-06, 2023-07, 2023-08, 2023-09]            4      0.993561\n",
            "6  [2023-07, 2023-08, 2023-09, 2023-10]            4      0.973532\n",
            "7  [2023-08, 2023-09, 2023-10, 2023-11]            4      0.977982\n",
            "8  [2023-09, 2023-10, 2023-11, 2023-12]            4      0.996220\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_df = df[(df[\"timestamp\"] >= train_start) & (df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  valid_df = df[~df[\"timestamp\"].isin(train_df[\"timestamp\"])]\n",
        "\n",
        "  anomaly = anomaly_rate_LOF(train_df, valid_df, features)\n",
        "\n",
        "  train_months = sorted(train_df[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "\n",
        "  results.append({\"train_months\": [str(x) for x in train_months] ,  \"window_size\": len(train_months), \"anomaly rate\": anomaly})\n",
        "\n",
        "results_df_6m_LOF = pd.DataFrame(results)\n",
        "print(results_df_6m_LOF)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCWqMi0AQJ4x",
        "outputId": "ed7c9d46-c6a7-4fe5-9ee0-63baa93179f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                        train_months  window_size  \\\n",
            "0  [2023-01, 2023-02, 2023-03, 2023-04, 2023-05, ...            6   \n",
            "1  [2023-02, 2023-03, 2023-04, 2023-05, 2023-06, ...            6   \n",
            "2  [2023-03, 2023-04, 2023-05, 2023-06, 2023-07, ...            6   \n",
            "3  [2023-04, 2023-05, 2023-06, 2023-07, 2023-08, ...            6   \n",
            "4  [2023-05, 2023-06, 2023-07, 2023-08, 2023-09, ...            6   \n",
            "5  [2023-06, 2023-07, 2023-08, 2023-09, 2023-10, ...            6   \n",
            "6  [2023-07, 2023-08, 2023-09, 2023-10, 2023-11, ...            6   \n",
            "\n",
            "   anomaly rate  \n",
            "0      0.997853  \n",
            "1      0.934004  \n",
            "2      0.927037  \n",
            "3      0.936912  \n",
            "4      0.964538  \n",
            "5      0.974411  \n",
            "6      0.992402  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results_2m_fake = []\n",
        "train_df, valid_df = create_fake_month(df_inc, frac_per_month=0.1, random_state=42)\n",
        "\n",
        "print(\"Giorni training:\", train_df[\"timestamp\"].dt.date.nunique())\n",
        "print(\"Giorni validation:\", valid_df[\"timestamp\"].dt.date.nunique())\n",
        "\n",
        "anomaly = anomaly_rate_LOF(train_df, valid_df, features)\n",
        "results_2m_fake.append({\"window_size\": 2, \"anomaly\": anomaly})\n",
        "\n",
        "results_df_2m_fake_LOF = pd.DataFrame(results_2m_fake)\n",
        "print(results_df_2m_fake_LOF)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-rIq0xcQMqV",
        "outputId": "40d1bca9-fa30-4a06-a7cd-fbace7b1bd97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Giorni training: 86\n",
            "Giorni validation: 833\n",
            "   window_size   anomaly\n",
            "0            2  0.076489\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results_4m_fake = []\n",
        "\n",
        "train_df, valid_df = create_fake_month(df_inc, frac_per_month=0.2, random_state=42)\n",
        "\n",
        "print(\"Giorni training:\", train_df[\"timestamp\"].dt.date.nunique())\n",
        "print(\"Giorni validation:\", valid_df[\"timestamp\"].dt.date.nunique())\n",
        "\n",
        "anomaly = anomaly_rate_LOF(train_df, valid_df, features)\n",
        "results_4m_fake.append({\"window_size\": 4, \"anomaly\": anomaly})\n",
        "\n",
        "results_df_4m_fake_LOF = pd.DataFrame(results_4m_fake)\n",
        "print(results_df_4m_fake_LOF)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uurGLd0PQPP1",
        "outputId": "ea972c64-fb32-4f97-fe4d-9730357f8e23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Giorni training: 177\n",
            "Giorni validation: 742\n",
            "   window_size   anomaly\n",
            "0            4  0.078428\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results_6m_fake = []\n",
        "\n",
        "train_df, valid_df = create_fake_month(df_inc, frac_per_month=0.3, random_state=42)\n",
        "\n",
        "print(\"Giorni training:\", train_df[\"timestamp\"].dt.date.nunique())\n",
        "print(\"Giorni validation:\", valid_df[\"timestamp\"].dt.date.nunique())\n",
        "\n",
        "anomaly = anomaly_rate_LOF(train_df, valid_df, features)\n",
        "results_6m_fake.append({\"window_size\": 6, \"anomaly\": anomaly})\n",
        "\n",
        "results_df_6m_fake_LOF = pd.DataFrame(results_6m_fake)\n",
        "print(results_df_6m_fake_LOF)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSUPcx8xQRoV",
        "outputId": "b5affb69-6e98-449c-ae59-aa8544a1dc3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Giorni training: 268\n",
            "Giorni validation: 651\n",
            "   window_size   anomaly\n",
            "0            6  0.066976\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# salvataggio dei risultati LOF\n",
        "real_results_df_LOF = pd.concat([results_df_2m_LOF, results_df_4m_LOF, results_df_6m_LOF])\n",
        "real_results_df_LOF.to_csv(\"/content/drive/MyDrive/real_inclinometri_LOF.csv\", index=False)\n",
        "\n",
        "fake_results_df_LOF = pd.concat([results_df_2m_fake_LOF, results_df_4m_fake_LOF, results_df_6m_fake_LOF])\n",
        "fake_results_df_LOF.to_csv(\"/content/drive/MyDrive/fake_inclinometri_LOF.csv\", index=False)"
      ],
      "metadata": {
        "id": "-O5rxOrgQUrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VAE senza temperatura"
      ],
      "metadata": {
        "id": "c2Tl6450RNJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Sampling(Layer):\n",
        "  def call(self, inputs):\n",
        "    z_mean, z_log_var = inputs\n",
        "    epsilon = tf.random.normal(shape=tf.shape(z_mean))\n",
        "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "\n",
        "class VAE(keras.Model):\n",
        "  def __init__(self, input_dim, latent_dim = 2, beta = 0.01, **kwargs):\n",
        "    super(VAE, self).__init__(**kwargs)\n",
        "    self.beta = beta\n",
        "\n",
        "    #encoder\n",
        "    x_input = keras.Input(shape=(input_dim,))\n",
        "    x = layers.Dense(48, activation=\"relu\")(x_input)\n",
        "    x = layers.Dense(24, activation=\"relu\")(x)\n",
        "    x = layers.Dense(12, activation=\"relu\")(x)\n",
        "    z_mean = layers.Dense(latent_dim)(x)\n",
        "    z_log_var = layers.Dense(latent_dim)(x)\n",
        "\n",
        "    z = Sampling()([z_mean, z_log_var])\n",
        "    self.encoder = keras.Model(x_input, [z_mean, z_log_var, z])\n",
        "\n",
        "    #decoder\n",
        "    latent_inputs = keras.Input(shape=(latent_dim,))\n",
        "    x = layers.Dense(12, activation=\"relu\")(latent_inputs)\n",
        "    x = layers.Dense(24, activation=\"relu\")(x)\n",
        "    x = layers.Dense(48, activation=\"relu\")(x)\n",
        "    outputs = layers.Dense(input_dim, activation=\"linear\")(x)\n",
        "\n",
        "    self.decoder = keras.Model(latent_inputs, outputs)\n",
        "\n",
        "  def train_step(self, data):\n",
        "    x, y = data\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "      z_mean, z_log_var, z = self.encoder(x, training = True)\n",
        "      reconstruction = self.decoder(z, training = True)\n",
        "\n",
        "      reconstruction_loss = tf.reduce_mean(tf.square(x - reconstruction))\n",
        "      kl_loss = -0.5 * tf.reduce_mean(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
        "      total_loss = reconstruction_loss + self.beta * kl_loss\n",
        "\n",
        "    grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "    self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "\n",
        "    return {\"loss\": total_loss, \"recon_loss\": reconstruction_loss, \"kl_loss\": kl_loss}\n",
        "\n",
        "  def call(self, inputs):\n",
        "    z_mean, _,  z = self.encoder(inputs)\n",
        "    return self.decoder(z)"
      ],
      "metadata": {
        "id": "mbLBf7F9RQdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = df[(df[\"timestamp\"] >= train_start) & (df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  val_data = df[~df[\"timestamp\"].isin(train_data[\"timestamp\"])]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(val_data[features])\n",
        "\n",
        "  vae = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "  vae.build(input_shape=(None, X_train.shape[1]))\n",
        "\n",
        "  vae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "  vae.fit(\n",
        "      X_train,\n",
        "      X_train,\n",
        "      epochs = 50,\n",
        "      batch_size = 64,\n",
        "      verbose = 0\n",
        "  )\n",
        "\n",
        "  vae.save_weights(f\"/content/drive/MyDrive/VAE_no_temp_1month_inclinometro_{m}.weights.h5\")\n",
        "\n",
        "  X_pred = vae.predict(X_val)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  mean_mse = np.mean(mse)\n",
        "  std_mse = np.std(mse)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_VAE = pd.DataFrame(results)\n",
        "print(results_df_1m_VAE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mspyb_KRmuC",
        "outputId": "3d3d370d-dde9-4db0-af91-450ec221eb50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m538/538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m532/532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m538/538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m539/539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m558/558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m539/539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m538/538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m539/539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m558/558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m555/555\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "\u001b[1m539/539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m538/538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "   train_months  window_size  anomaly rate\n",
            "0     [2023-01]            1      0.000000\n",
            "1     [2023-02]            1      0.000000\n",
            "2     [2023-03]            1      0.000000\n",
            "3     [2023-04]            1      0.000000\n",
            "4     [2023-05]            1      0.000392\n",
            "5     [2023-06]            1      0.000638\n",
            "6     [2023-07]            1      0.000000\n",
            "7     [2023-08]            1      0.000000\n",
            "8     [2023-09]            1      0.000000\n",
            "9     [2023-10]            1      0.000000\n",
            "10    [2023-11]            1      0.000000\n",
            "11    [2023-12]            1      0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = df[(df[\"timestamp\"] >= train_start) & (df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  val_data = df[~df[\"timestamp\"].isin(train_data[\"timestamp\"])]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(val_data[features])\n",
        "\n",
        "  vae = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "  vae.build(input_shape=(None, X_train.shape[1]))\n",
        "\n",
        "  vae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "  vae.fit(\n",
        "      X_train,\n",
        "      X_train,\n",
        "      epochs = 50,\n",
        "      batch_size = 64,\n",
        "      verbose = 0\n",
        "  )\n",
        "\n",
        "  vae.save_weights(f\"/content/drive/MyDrive/VAE_no_temp_2month_inclinometro_{m}.weights.h5\")\n",
        "\n",
        "  X_pred = vae.predict(X_val)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  mean_mse = np.mean(mse)\n",
        "  std_mse = np.std(mse)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_VAE = pd.DataFrame(results)\n",
        "print(results_df_2m_VAE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQWrdRg_SEqi",
        "outputId": "f906e62b-b9f5-4b54-b748-9eb170896404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m505/505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m506/506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m533/533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m533/533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m532/532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "          train_months  window_size  anomaly rate\n",
            "0   [2023-01, 2023-02]            2      0.000000\n",
            "1   [2023-02, 2023-03]            2      0.000186\n",
            "2   [2023-03, 2023-04]            2      0.000000\n",
            "3   [2023-04, 2023-05]            2      0.003053\n",
            "4   [2023-05, 2023-06]            2      0.001350\n",
            "5   [2023-06, 2023-07]            2      0.000000\n",
            "6   [2023-07, 2023-08]            2      0.000000\n",
            "7   [2023-08, 2023-09]            2      0.000000\n",
            "8   [2023-09, 2023-10]            2      0.000000\n",
            "9   [2023-10, 2023-11]            2      0.000000\n",
            "10  [2023-11, 2023-12]            2      0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = df[(df[\"timestamp\"] >= train_start) & (df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  val_data = df[~df[\"timestamp\"].isin(train_data[\"timestamp\"])]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(val_data[features])\n",
        "\n",
        "  vae = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "  vae.build(input_shape=(None, X_train.shape[1]))\n",
        "\n",
        "  vae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "  vae.fit(\n",
        "      X_train,\n",
        "      X_train,\n",
        "      epochs = 50,\n",
        "      batch_size = 64,\n",
        "      verbose = 0\n",
        "  )\n",
        "\n",
        "  vae.save_weights(f\"/content/drive/MyDrive/VAE_no_temp_4month_inclinometro_{m}.weights.h5\")\n",
        "\n",
        "  X_pred = vae.predict(X_val)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  mean_mse = np.mean(mse)\n",
        "  std_mse = np.std(mse)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_VAE = pd.DataFrame(results)\n",
        "print(results_df_4m_VAE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CP1EEGkXSKYG",
        "outputId": "ad5c21f6-f5dd-4616-c621-7c1d9cf3ada0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m481/481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m481/481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "                           train_months  window_size  anomaly rate\n",
            "0  [2023-01, 2023-02, 2023-03, 2023-04]            4      0.000000\n",
            "1  [2023-02, 2023-03, 2023-04, 2023-05]            4      0.009572\n",
            "2  [2023-03, 2023-04, 2023-05, 2023-06]            4      0.015981\n",
            "3  [2023-04, 2023-05, 2023-06, 2023-07]            4      0.000000\n",
            "4  [2023-05, 2023-06, 2023-07, 2023-08]            4      0.000000\n",
            "5  [2023-06, 2023-07, 2023-08, 2023-09]            4      0.000000\n",
            "6  [2023-07, 2023-08, 2023-09, 2023-10]            4      0.000000\n",
            "7  [2023-08, 2023-09, 2023-10, 2023-11]            4      0.000000\n",
            "8  [2023-09, 2023-10, 2023-11, 2023-12]            4      0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = df[(df[\"timestamp\"] >= train_start) & (df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  val_data = df[~df[\"timestamp\"].isin(train_data[\"timestamp\"])]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(val_data[features])\n",
        "\n",
        "  vae = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "  vae.build(input_shape=(None, X_train.shape[1]))\n",
        "\n",
        "  vae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "  vae.fit(\n",
        "      X_train,\n",
        "      X_train,\n",
        "      epochs = 50,\n",
        "      batch_size = 64,\n",
        "      verbose = 0\n",
        "  )\n",
        "\n",
        "  vae.save_weights(f\"/content/drive/MyDrive/VAE_no_temp_6month_inclinometro_{m}.weights.h5\")\n",
        "\n",
        "  X_pred = vae.predict(X_val)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  mean_mse = np.mean(mse)\n",
        "  std_mse = np.std(mse)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "#  anomaly_rate = np.mean(anomalies)*100\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_VAE = pd.DataFrame(results)\n",
        "print(results_df_6m_VAE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ByAArFeSdJn",
        "outputId": "5d56f5cf-5b63-433f-bd2c-acd5b5b00ed8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "                                        train_months  window_size  \\\n",
            "0  [2023-01, 2023-02, 2023-03, 2023-04, 2023-05, ...            6   \n",
            "1  [2023-02, 2023-03, 2023-04, 2023-05, 2023-06, ...            6   \n",
            "2  [2023-03, 2023-04, 2023-05, 2023-06, 2023-07, ...            6   \n",
            "3  [2023-04, 2023-05, 2023-06, 2023-07, 2023-08, ...            6   \n",
            "4  [2023-05, 2023-06, 2023-07, 2023-08, 2023-09, ...            6   \n",
            "5  [2023-06, 2023-07, 2023-08, 2023-09, 2023-10, ...            6   \n",
            "6  [2023-07, 2023-08, 2023-09, 2023-10, 2023-11, ...            6   \n",
            "\n",
            "   anomaly rate  \n",
            "0      0.020358  \n",
            "1      0.000000  \n",
            "2      0.000000  \n",
            "3      0.002507  \n",
            "4      0.000000  \n",
            "5      0.000000  \n",
            "6      0.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results_1m_fake = []\n",
        "train_df, valid_df = create_fake_month(df_inc, frac_per_month=0.05, random_state=42)\n",
        "\n",
        "print(\"Giorni training:\", train_df[\"timestamp\"].dt.date.nunique())\n",
        "print(\"Giorni validation:\", valid_df[\"timestamp\"].dt.date.nunique())\n",
        "\n",
        "scaler_X = StandardScaler()\n",
        "\n",
        "X_train = scaler_X.fit_transform(train_df[features])\n",
        "\n",
        "X_val = scaler_X.transform(valid_df[features])\n",
        "\n",
        "vae = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "vae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "vae.fit(\n",
        "    X_train,\n",
        "    X_train,\n",
        "    epochs = 50,\n",
        "    batch_size = 64,\n",
        "    verbose = 0\n",
        "  )\n",
        "\n",
        "X_pred = vae.predict(X_val)\n",
        "mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "mean_mse = np.mean(mse)\n",
        "std_mse = np.std(mse)\n",
        "threshold = mean_mse + 3 * std_mse\n",
        "anomalies = mse > threshold\n",
        "anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "\n",
        "results_1m_fake.append({\"window_size\": 1, \"anomaly\": anomaly_rate})\n",
        "\n",
        "results_df_1m_fake_VAE = pd.DataFrame(results_1m_fake)\n",
        "print(results_df_1m_fake_VAE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Udr4EY4HSkzD",
        "outputId": "561038c2-9064-454e-daa5-135a8a2443e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Giorni training: 32\n",
            "Giorni validation: 887\n",
            "\u001b[1m734/734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "   window_size   anomaly\n",
            "0            1  0.017685\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results_2m_fake = []\n",
        "train_df, valid_df = create_fake_month(df_inc, frac_per_month=0.1, random_state=42)\n",
        "\n",
        "print(\"Giorni training:\", train_df[\"timestamp\"].dt.date.nunique())\n",
        "print(\"Giorni validation:\", valid_df[\"timestamp\"].dt.date.nunique())\n",
        "\n",
        "scaler_X = StandardScaler()\n",
        "\n",
        "X_train = scaler_X.fit_transform(train_df[features])\n",
        "\n",
        "X_val = scaler_X.transform(valid_df[features])\n",
        "\n",
        "vae = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "vae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "vae.fit(\n",
        "    X_train,\n",
        "    X_train,\n",
        "    epochs = 50,\n",
        "    batch_size = 64,\n",
        "    verbose = 0\n",
        "  )\n",
        "\n",
        "X_pred = vae.predict(X_val)\n",
        "mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "mean_mse = np.mean(mse)\n",
        "std_mse = np.std(mse)\n",
        "threshold = mean_mse + 3 * std_mse\n",
        "anomalies = mse > threshold\n",
        "anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "\n",
        "results_2m_fake.append({\"window_size\": 2, \"anomaly\": anomaly_rate})\n",
        "\n",
        "results_df_2m_fake_VAE = pd.DataFrame(results_2m_fake)\n",
        "print(results_df_2m_fake_VAE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5vV-j2WSuM1",
        "outputId": "f4a73b59-ade8-4ec5-9a5b-41b092dec358"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Giorni training: 86\n",
            "Giorni validation: 833\n",
            "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "   window_size  anomaly\n",
            "0            2  0.02201\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results_4m_fake = []\n",
        "train_df, valid_df = create_fake_month(df_inc, frac_per_month=0.2, random_state=42)\n",
        "\n",
        "print(\"Giorni training:\", train_df[\"timestamp\"].dt.date.nunique())\n",
        "print(\"Giorni validation:\", valid_df[\"timestamp\"].dt.date.nunique())\n",
        "\n",
        "scaler_X = StandardScaler()\n",
        "\n",
        "X_train = scaler_X.fit_transform(train_df[features])\n",
        "\n",
        "X_val = scaler_X.transform(valid_df[features])\n",
        "\n",
        "vae = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "vae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "vae.fit(\n",
        "    X_train,\n",
        "    X_train,\n",
        "    epochs = 50,\n",
        "    batch_size = 64,\n",
        "    verbose = 0\n",
        "  )\n",
        "\n",
        "X_pred = vae.predict(X_val)\n",
        "mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "mean_mse = np.mean(mse)\n",
        "std_mse = np.std(mse)\n",
        "threshold = mean_mse + 3 * std_mse\n",
        "anomalies = mse > threshold\n",
        "anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "\n",
        "results_4m_fake.append({\"window_size\": 4, \"anomaly\": anomaly_rate})\n",
        "\n",
        "results_df_4m_fake_VAE = pd.DataFrame(results_4m_fake)\n",
        "print(results_df_4m_fake_VAE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RttlIETXS-OK",
        "outputId": "67d82f32-fb9d-4bb9-c6c8-7048ff0146fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Giorni training: 177\n",
            "Giorni validation: 742\n",
            "\u001b[1m615/615\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "   window_size   anomaly\n",
            "0            4  0.014029\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results_6m_fake = []\n",
        "train_df, valid_df = create_fake_month(df_inc, frac_per_month=0.3, random_state=42)\n",
        "\n",
        "print(\"Giorni training:\", train_df[\"timestamp\"].dt.date.nunique())\n",
        "print(\"Giorni validation:\", valid_df[\"timestamp\"].dt.date.nunique())\n",
        "\n",
        "scaler_X = StandardScaler()\n",
        "\n",
        "X_train = scaler_X.fit_transform(train_df[features])\n",
        "\n",
        "X_val = scaler_X.transform(valid_df[features])\n",
        "\n",
        "vae = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "vae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "vae.fit(\n",
        "    X_train,\n",
        "    X_train,\n",
        "    epochs = 50,\n",
        "    batch_size = 64,\n",
        "    verbose = 0\n",
        "  )\n",
        "\n",
        "X_pred = vae.predict(X_val)\n",
        "mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "mean_mse = np.mean(mse)\n",
        "std_mse = np.std(mse)\n",
        "threshold = mean_mse + 3 * std_mse\n",
        "anomalies = mse > threshold\n",
        "anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "\n",
        "results_6m_fake.append({\"window_size\": 6, \"anomaly\": anomaly_rate})\n",
        "\n",
        "results_df_6m_fake_VAE = pd.DataFrame(results_6m_fake)\n",
        "print(results_df_6m_fake_VAE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dT-dbIVTJ3l",
        "outputId": "096e898f-e2ca-40d3-b329-a6a2c6411a39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Giorni training: 268\n",
            "Giorni validation: 651\n",
            "\u001b[1m539/539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "   window_size   anomaly\n",
            "0            6  0.019095\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# salvataggio dei risultati VAE (no temperatura)\n",
        "real_results_df_VAE = pd.concat([results_df_1m_VAE, results_df_2m_VAE, results_df_4m_VAE, results_df_6m_VAE])\n",
        "real_results_df_VAE.to_csv(\"/content/drive/MyDrive/real_inclinometri_VAE.csv\", index=False)\n",
        "\n",
        "fake_results_df_VAE = pd.concat([results_df_1m_fake_VAE, results_df_2m_fake_VAE, results_df_4m_fake_VAE, results_df_6m_fake_VAE])\n",
        "fake_results_df_VAE.to_csv(\"/content/drive/MyDrive/fake_inclinometri_VAE.csv\", index=False)"
      ],
      "metadata": {
        "id": "C5ZvvLZwTV4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AE senza temperatura"
      ],
      "metadata": {
        "id": "YJGgC8NcT6fT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_ae(input_dim, latent_dim=2):\n",
        "  #encoder\n",
        "  input_enc = layers.Input(shape=(input_dim,))\n",
        "  x = layers.Dense(64, activation=\"relu\")(input_enc)\n",
        "  x = layers.Dense(32, activation=\"relu\")(x)\n",
        "  x = layers.Dense(16, activation=\"relu\")(x)\n",
        "  z = layers.Dense(latent_dim, activation=\"relu\", name=\"latent\")(x)\n",
        "\n",
        "  #decoder\n",
        "  x = layers.Dense(16, activation=\"relu\")(z)\n",
        "  x = layers.Dense(32, activation=\"relu\")(x)\n",
        "  x = layers.Dense(64, activation=\"relu\")(x)\n",
        "  output_dec = layers.Dense(input_dim, activation=\"linear\")(x)\n",
        "\n",
        "  #autoencoder\n",
        "  ae = keras.Model(input_enc, output_dec, name=\"autoencoder\")\n",
        "  ae.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "  return ae"
      ],
      "metadata": {
        "id": "nsZlJFvdT-lr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = df[(df[\"timestamp\"] >= train_start) & (df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  val_data = df[~df[\"timestamp\"].isin(train_data[\"timestamp\"])]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(val_data[features])\n",
        "\n",
        "  ae = build_ae(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  ae.fit(\n",
        "      X_train,\n",
        "      X_train,\n",
        "      epochs = 50,\n",
        "      batch_size = 64,\n",
        "      verbose = 0\n",
        "  )\n",
        "\n",
        "  ae.save_weights(f\"/content/drive/MyDrive/AE_no_temp_1month_inclinometro_{m}.weights.h5\")\n",
        "\n",
        "  X_pred = ae.predict(X_val)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  mean_mse = np.mean(mse)\n",
        "  std_mse = np.std(mse)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_AE = pd.DataFrame(results)\n",
        "print(results_df_1m_AE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIt5i_uWUJ4p",
        "outputId": "339832f7-0c24-475e-9fa8-32f06109c3c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m538/538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m532/532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m538/538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m539/539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m558/558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m539/539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m538/538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m539/539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m558/558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m555/555\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m539/539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m538/538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "   train_months  window_size  anomaly rate\n",
            "0     [2023-01]            1      0.000000\n",
            "1     [2023-02]            1      0.000000\n",
            "2     [2023-03]            1      0.000000\n",
            "3     [2023-04]            1      0.000000\n",
            "4     [2023-05]            1      0.000505\n",
            "5     [2023-06]            1      0.000000\n",
            "6     [2023-07]            1      0.000000\n",
            "7     [2023-08]            1      0.000000\n",
            "8     [2023-09]            1      0.000000\n",
            "9     [2023-10]            1      0.000000\n",
            "10    [2023-11]            1      0.000000\n",
            "11    [2023-12]            1      0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = df[(df[\"timestamp\"] >= train_start) & (df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  val_data = df[~df[\"timestamp\"].isin(train_data[\"timestamp\"])]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(val_data[features])\n",
        "\n",
        "  ae = build_ae(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  ae.fit(\n",
        "      X_train,\n",
        "      X_train,\n",
        "      epochs = 50,\n",
        "      batch_size = 64,\n",
        "      verbose = 0\n",
        "  )\n",
        "\n",
        "\n",
        "  ae.save_weights(f\"/content/drive/MyDrive/AE_no_temp_2month_inclinometro_{m}.weights.h5\")\n",
        "\n",
        "  X_pred = ae.predict(X_val)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  mean_mse = np.mean(mse)\n",
        "  std_mse = np.std(mse)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "#  anomaly_rate = np.mean(anomalies)*100\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_AE = pd.DataFrame(results)\n",
        "print(results_df_2m_AE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Soz2jz05UYE-",
        "outputId": "5c8a1a03-419d-48b6-a7a6-64f37d955836"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m505/505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m506/506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m533/533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m533/533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m532/532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "          train_months  window_size  anomaly rate\n",
            "0   [2023-01, 2023-02]            2      0.000000\n",
            "1   [2023-02, 2023-03]            2      0.000000\n",
            "2   [2023-03, 2023-04]            2      0.000000\n",
            "3   [2023-04, 2023-05]            2      0.000000\n",
            "4   [2023-05, 2023-06]            2      0.000939\n",
            "5   [2023-06, 2023-07]            2      0.000000\n",
            "6   [2023-07, 2023-08]            2      0.003418\n",
            "7   [2023-08, 2023-09]            2      0.029692\n",
            "8   [2023-09, 2023-10]            2      0.000000\n",
            "9   [2023-10, 2023-11]            2      0.000000\n",
            "10  [2023-11, 2023-12]            2      0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = df[(df[\"timestamp\"] >= train_start) & (df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  val_data = df[~df[\"timestamp\"].isin(train_data[\"timestamp\"])]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(val_data[features])\n",
        "\n",
        "  ae = build_ae(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  ae.fit(\n",
        "      X_train,\n",
        "      X_train,\n",
        "      epochs = 50,\n",
        "      batch_size = 64,\n",
        "      verbose = 0\n",
        "  )\n",
        "\n",
        "  ae.save_weights(f\"/content/drive/MyDrive/AE_no_temp_4month_inclinometro_{m}.weights.h5\")\n",
        "\n",
        "  X_pred = ae.predict(X_val)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  mean_mse = np.mean(mse)\n",
        "  std_mse = np.std(mse)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_AE = pd.DataFrame(results)\n",
        "print(results_df_4m_AE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIQ8ql0TUghf",
        "outputId": "2723b33c-9c44-419a-9e00-84ce932e9657"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m481/481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m481/481\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "                           train_months  window_size  anomaly rate\n",
            "0  [2023-01, 2023-02, 2023-03, 2023-04]            4      0.000000\n",
            "1  [2023-02, 2023-03, 2023-04, 2023-05]            4      0.010364\n",
            "2  [2023-03, 2023-04, 2023-05, 2023-06]            4      0.001169\n",
            "3  [2023-04, 2023-05, 2023-06, 2023-07]            4      0.000000\n",
            "4  [2023-05, 2023-06, 2023-07, 2023-08]            4      0.000000\n",
            "5  [2023-06, 2023-07, 2023-08, 2023-09]            4      0.002406\n",
            "6  [2023-07, 2023-08, 2023-09, 2023-10]            4      0.000000\n",
            "7  [2023-08, 2023-09, 2023-10, 2023-11]            4      0.000000\n",
            "8  [2023-09, 2023-10, 2023-11, 2023-12]            4      0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = df[(df[\"timestamp\"] >= train_start) & (df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  val_data = df[~df[\"timestamp\"].isin(train_data[\"timestamp\"])]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(val_data[features])\n",
        "\n",
        "  ae = build_ae(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  ae.fit(\n",
        "      X_train,\n",
        "      X_train,\n",
        "      epochs = 50,\n",
        "      batch_size = 64,\n",
        "      verbose = 0\n",
        "  )\n",
        "\n",
        "  ae.save_weights(f\"/content/drive/MyDrive/AE_no_temp_6month_inclinometro_{m}.weights.h5\")\n",
        "\n",
        "  X_pred = ae.predict(X_val)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  mean_mse = np.mean(mse)\n",
        "  std_mse = np.std(mse)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "#  anomaly_rate = np.mean(anomalies)*100\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_AE = pd.DataFrame(results)\n",
        "print(results_df_6m_AE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtMXSWmtUtDD",
        "outputId": "6a22f898-20fe-4673-d84d-6e7a445a7849"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "                                        train_months  window_size  \\\n",
            "0  [2023-01, 2023-02, 2023-03, 2023-04, 2023-05, ...            6   \n",
            "1  [2023-02, 2023-03, 2023-04, 2023-05, 2023-06, ...            6   \n",
            "2  [2023-03, 2023-04, 2023-05, 2023-06, 2023-07, ...            6   \n",
            "3  [2023-04, 2023-05, 2023-06, 2023-07, 2023-08, ...            6   \n",
            "4  [2023-05, 2023-06, 2023-07, 2023-08, 2023-09, ...            6   \n",
            "5  [2023-06, 2023-07, 2023-08, 2023-09, 2023-10, ...            6   \n",
            "6  [2023-07, 2023-08, 2023-09, 2023-10, 2023-11, ...            6   \n",
            "\n",
            "   anomaly rate  \n",
            "0      0.002147  \n",
            "1      0.000000  \n",
            "2      0.000000  \n",
            "3      0.000000  \n",
            "4      0.001480  \n",
            "5      0.000000  \n",
            "6      0.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results_1m_fake = []\n",
        "train_df, valid_df = create_fake_month(df_inc, frac_per_month=0.05, random_state=42)\n",
        "\n",
        "print(\"Giorni training:\", train_df[\"timestamp\"].dt.date.nunique())\n",
        "print(\"Giorni validation:\", valid_df[\"timestamp\"].dt.date.nunique())\n",
        "\n",
        "scaler_X = StandardScaler()\n",
        "\n",
        "X_train = scaler_X.fit_transform(train_df[features])\n",
        "\n",
        "X_val = scaler_X.transform(valid_df[features])\n",
        "\n",
        "ae = build_ae(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "ae.fit(\n",
        "    X_train,\n",
        "    X_train,\n",
        "    epochs = 50,\n",
        "    batch_size = 64,\n",
        "    verbose = 0\n",
        "  )\n",
        "\n",
        "X_pred = ae.predict(X_val)\n",
        "mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "mean_mse = np.mean(mse)\n",
        "std_mse = np.std(mse)\n",
        "threshold = mean_mse + 3 * std_mse\n",
        "anomalies = mse > threshold\n",
        "anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "\n",
        "results_1m_fake.append({\"window_size\": 1, \"anomaly\": anomaly_rate})\n",
        "\n",
        "results_df_1m_fake_AE = pd.DataFrame(results_1m_fake)\n",
        "print(results_df_1m_fake_AE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvS__vkQU8BJ",
        "outputId": "30f094fe-798c-4fb8-c229-f7c5a0de7696"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Giorni training: 32\n",
            "Giorni validation: 887\n",
            "\u001b[1m734/734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "   window_size   anomaly\n",
            "0            1  0.028893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results_2m_fake = []\n",
        "train_df, valid_df = create_fake_month(df_inc, frac_per_month=0.1, random_state=42)\n",
        "\n",
        "print(\"Giorni training:\", train_df[\"timestamp\"].dt.date.nunique())\n",
        "print(\"Giorni validation:\", valid_df[\"timestamp\"].dt.date.nunique())\n",
        "\n",
        "scaler_X = StandardScaler()\n",
        "\n",
        "X_train = scaler_X.fit_transform(train_df[features])\n",
        "\n",
        "X_val = scaler_X.transform(valid_df[features])\n",
        "\n",
        "ae = build_ae(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "ae.fit(\n",
        "    X_train,\n",
        "    X_train,\n",
        "    epochs = 50,\n",
        "    batch_size = 64,\n",
        "    verbose = 0\n",
        "  )\n",
        "\n",
        "X_pred = ae.predict(X_val)\n",
        "mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "mean_mse = np.mean(mse)\n",
        "std_mse = np.std(mse)\n",
        "threshold = mean_mse + 3 * std_mse\n",
        "anomalies = mse > threshold\n",
        "anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "\n",
        "results_2m_fake.append({\"window_size\": 2, \"anomaly\": anomaly_rate})\n",
        "\n",
        "results_df_2m_fake_AE = pd.DataFrame(results_2m_fake)\n",
        "print(results_df_2m_fake_AE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPUMtc2PVH0_",
        "outputId": "cfe281dd-f85c-40be-db2f-0edc00a3993c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Giorni training: 86\n",
            "Giorni validation: 833\n",
            "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "   window_size   anomaly\n",
            "0            2  0.019918\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results_4m_fake = []\n",
        "train_df, valid_df = create_fake_month(df_inc, frac_per_month=0.2, random_state=42)\n",
        "\n",
        "print(\"Giorni training:\", train_df[\"timestamp\"].dt.date.nunique())\n",
        "print(\"Giorni validation:\", valid_df[\"timestamp\"].dt.date.nunique())\n",
        "\n",
        "scaler_X = StandardScaler()\n",
        "\n",
        "X_train = scaler_X.fit_transform(train_df[features])\n",
        "\n",
        "X_val = scaler_X.transform(valid_df[features])\n",
        "\n",
        "ae = build_ae(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "ae.fit(\n",
        "    X_train,\n",
        "    X_train,\n",
        "    epochs = 50,\n",
        "    batch_size = 64,\n",
        "    verbose = 0\n",
        "  )\n",
        "\n",
        "X_pred = ae.predict(X_val)\n",
        "mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "mean_mse = np.mean(mse)\n",
        "std_mse = np.std(mse)\n",
        "threshold = mean_mse + 3 * std_mse\n",
        "anomalies = mse > threshold\n",
        "anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "\n",
        "results_4m_fake.append({\"window_size\": 4, \"anomaly\": anomaly_rate})\n",
        "\n",
        "results_df_4m_fake_AE = pd.DataFrame(results_4m_fake)\n",
        "print(results_df_4m_fake_AE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLZPpWJLVQJy",
        "outputId": "52145c3e-0f8b-4e79-b721-643155c33e67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Giorni training: 177\n",
            "Giorni validation: 742\n",
            "\u001b[1m615/615\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "   window_size   anomaly\n",
            "0            4  0.018247\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results_6m_fake = []\n",
        "train_df, valid_df = create_fake_month(df_inc, frac_per_month=0.3, random_state=42)\n",
        "\n",
        "print(\"Giorni training:\", train_df[\"timestamp\"].dt.date.nunique())\n",
        "print(\"Giorni validation:\", valid_df[\"timestamp\"].dt.date.nunique())\n",
        "\n",
        "scaler_X = StandardScaler()\n",
        "\n",
        "X_train = scaler_X.fit_transform(train_df[features])\n",
        "\n",
        "X_val = scaler_X.transform(valid_df[features])\n",
        "\n",
        "ae = build_ae(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "ae.fit(\n",
        "    X_train,\n",
        "    X_train,\n",
        "    epochs = 50,\n",
        "    batch_size = 64,\n",
        "    verbose = 0\n",
        "  )\n",
        "\n",
        "X_pred = ae.predict(X_val)\n",
        "mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "mean_mse = np.mean(mse)\n",
        "std_mse = np.std(mse)\n",
        "threshold = mean_mse + 3 * std_mse\n",
        "anomalies = mse > threshold\n",
        "anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "\n",
        "results_6m_fake.append({\"window_size\": 6, \"anomaly\": anomaly_rate})\n",
        "\n",
        "results_df_6m_fake_AE = pd.DataFrame(results_6m_fake)\n",
        "print(results_df_6m_fake_AE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w127tthRVV_B",
        "outputId": "de08396c-198d-4c87-db85-3755bbce5535"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Giorni training: 268\n",
            "Giorni validation: 651\n",
            "\u001b[1m539/539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "   window_size   anomaly\n",
            "0            6  0.015786\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# salvataggio dei risultati AE (no temperatura)\n",
        "real_results_df_AE = pd.concat([results_df_1m_AE, results_df_2m_AE, results_df_4m_AE, results_df_6m_AE])\n",
        "real_results_df_AE.to_csv(\"/content/drive/MyDrive/real_inclinometri_AE.csv\", index=False)\n",
        "\n",
        "fake_results_df_AE = pd.concat([results_df_1m_fake_AE, results_df_2m_fake_AE, results_df_4m_fake_AE, results_df_6m_fake_AE])\n",
        "fake_results_df_AE.to_csv(\"/content/drive/MyDrive/fake_inclinometri_AE.csv\", index=False)"
      ],
      "metadata": {
        "id": "iDofH2d8Vi3x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
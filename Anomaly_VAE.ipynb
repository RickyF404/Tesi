{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "NPl5C0pgknMc",
        "LmE44JTACOhu",
        "Kd1vDDteSf4u"
      ],
      "mount_file_id": "1-w3-M_qsf65DHQSth64nkG7iFg6_JnzE",
      "authorship_tag": "ABX9TyMUMeQx0REgSuJHygzH/lQG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RickyF404/Tesi/blob/main/Anomaly_VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fhb2ZKVjj_hP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import gdown\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Layer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url_no_temp = \"https://drive.google.com/uc?id=1jerpsOqjogEnnriBkHOrDDEeh1wJry_o\"\n",
        "output_no_temp = \"data_no_temperature.csv\"\n",
        "gdown.download(url_no_temp, output_no_temp)\n",
        "\n",
        "url_temp = \" https://drive.google.com/uc?id=1RofjUHZS_UAnbF6Xe74jTp9z4Mmk7swH\"\n",
        "output_temp = \"data_temperature.csv\"\n",
        "gdown.download(url_temp, output_temp)\n",
        "\n",
        "\n",
        "url_anomaly = \"https://drive.google.com/uc?id=1onDmjfJio6nVRaaQSOgd6wW_XyuyyCra\"\n",
        "output_anomaly = \"data_anomaly.csv\"\n",
        "gdown.download(url_anomaly, output_anomaly)\n",
        "\n",
        "df_anomaly = pd.read_csv(\"/content/data_anomaly.csv\", encoding = \"utf-8\")\n",
        "\n",
        "mapping = {\n",
        "    \"F1\": \"Mode 1\",\n",
        "    \"F2\": \"Mode 2\",\n",
        "    \"F3\": \"Mode 3\",\n",
        "    \"F4\": \"Mode 4\",\n",
        "    \"F5\": \"Mode 5\",\n",
        "    \"F6\": \"Mode 6\",\n",
        "    \"Temperature\": \"temperatura\"\n",
        "}\n",
        "\n",
        "df_anomaly = df_anomaly.rename(columns=mapping)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFR_nb_IkPPE",
        "outputId": "fe51049c-ae59-4756-af12-318619d17025"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1jerpsOqjogEnnriBkHOrDDEeh1wJry_o\n",
            "To: /content/data_no_temperature.csv\n",
            "100%|██████████| 1.44M/1.44M [00:00<00:00, 15.1MB/s]\n",
            "Downloading...\n",
            "From:  https://drive.google.com/uc?id=1RofjUHZS_UAnbF6Xe74jTp9z4Mmk7swH\n",
            "To: /content/data_temperature.csv\n",
            "100%|██████████| 1.66M/1.66M [00:00<00:00, 80.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1onDmjfJio6nVRaaQSOgd6wW_XyuyyCra\n",
            "To: /content/data_anomaly.csv\n",
            "100%|██████████| 990k/990k [00:00<00:00, 35.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CVAE beta = 1"
      ],
      "metadata": {
        "id": "NPl5C0pgknMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"keras\")\n",
        "\n",
        "df_temp = pd.read_csv(\"/content/data_temperature.csv\", encoding = \"utf-8\")\n",
        "df_temp[\"timestamp\"] = pd.to_datetime(df_temp[\"timestamp\"])\n",
        "df_temp[\"timestamp\"] = df_temp[\"timestamp\"].dt.tz_localize(None)\n",
        "df_temp = df_temp.sort_values(\"timestamp\")\n",
        "\n",
        "end = \"2025-01-01\"\n",
        "new_df = df_temp[(df_temp[\"timestamp\"] < end)]\n",
        "\n",
        "class Sampling(Layer):\n",
        "  def call(self, inputs):\n",
        "    z_mean, z_log_var = inputs\n",
        "    epsilon = tf.random.normal(shape=tf.shape(z_mean))\n",
        "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "\n",
        "class CVAE(keras.Model):\n",
        "  def __init__(self, input_dim, cond_dim = 1, latent_dim = 2, beta = 1, **kwargs):\n",
        "    super(CVAE, self).__init__(**kwargs)\n",
        "    self.beta = beta\n",
        "\n",
        "    #encoder\n",
        "    x_input = keras.Input(shape=(input_dim,))\n",
        "    cond_input = keras.Input(shape=(cond_dim,))\n",
        "    x = layers.Concatenate()([x_input, cond_input])\n",
        "    x = layers.Dense(32, activation=\"relu\")(x)\n",
        "    x = layers.Dense(16, activation=\"relu\")(x)\n",
        "    x = layers.Dense(8, activation=\"relu\")(x)\n",
        "    z_mean = layers.Dense(latent_dim)(x)\n",
        "    z_log_var = layers.Dense(latent_dim)(x)\n",
        "\n",
        "    z = Sampling()([z_mean, z_log_var])\n",
        "    self.encoder = keras.Model([x_input, cond_input], [z_mean, z_log_var, z], name=\"encoder\")\n",
        "\n",
        "    #decoder\n",
        "    latent_inputs = keras.Input(shape=(latent_dim,))\n",
        "    cond_inputs_dec = keras.Input(shape=(cond_dim,))\n",
        "    x = layers.Concatenate()([latent_inputs, cond_inputs_dec])\n",
        "    x = layers.Dense(8, activation=\"relu\")(x)\n",
        "    x = layers.Dense(16, activation=\"relu\")(x)\n",
        "    x = layers.Dense(32, activation=\"relu\")(x)\n",
        "    outputs = layers.Dense(input_dim, activation=\"linear\")(x)\n",
        "\n",
        "    self.decoder = keras.Model([latent_inputs, cond_inputs_dec], outputs, name=\"decoder\")\n",
        "\n",
        "  def train_step(self, data):\n",
        "    (x, cond), y = data\n",
        "\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "      z_mean, z_log_var, z = self.encoder([x, cond], training = True)\n",
        "      reconstruction = self.decoder([z, cond], training = True)\n",
        "\n",
        "      reconstruction_loss = tf.reduce_mean(tf.square(x - reconstruction))\n",
        "      kl_loss = -0.5 * tf.reduce_mean(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
        "      total_loss = reconstruction_loss + self.beta * kl_loss\n",
        "\n",
        "    grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "    self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "\n",
        "    return {\"loss\": total_loss, \"recon_loss\": reconstruction_loss, \"kl_loss\": kl_loss}\n",
        "\n",
        "  def call(self, x, cond=None):\n",
        "    # supporta sia call([x, cond]) che call(x, cond)\n",
        "    if cond is None:\n",
        "        # caso in cui arriva [x, cond] come lista\n",
        "        x, cond = x\n",
        "    z_mean, _, z = self.encoder([x, cond])\n",
        "    return self.decoder([z, cond])\n"
      ],
      "metadata": {
        "id": "-nXAtc20kTKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS1, 1 mese di dati"
      ],
      "metadata": {
        "id": "vpWjx8Gaz61p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS1_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_20[features])\n",
        "  T_val = scaler_T.transform(df_DS1_20[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS1_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS1_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_40[features])\n",
        "  T_val = scaler_T.transform(df_DS1_40[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":40,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS1_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS1_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_60[features])\n",
        "  T_val = scaler_T.transform(df_DS1_60[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":60,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS1_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS1_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_80[features])\n",
        "  T_val = scaler_T.transform(df_DS1_80[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":80,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS1_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS1_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_100[features])\n",
        "  T_val = scaler_T.transform(df_DS1_100[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":100,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS1_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS1_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mZd82ULo6Gh",
        "outputId": "d822fad0-187a-4828-a6b6-1ce21d460872"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           20           1.0\n",
            "1     [2024-02]            1           20           1.0\n",
            "2     [2024-03]            1           20           1.0\n",
            "3     [2024-04]            1           20           1.0\n",
            "4     [2024-05]            1           20           1.0\n",
            "5     [2024-06]            1           20           1.0\n",
            "6     [2024-07]            1           20           1.0\n",
            "7     [2024-08]            1           20           1.0\n",
            "8     [2024-09]            1           20           1.0\n",
            "9     [2024-10]            1           20           1.0\n",
            "10    [2024-11]            1           20           1.0\n",
            "11    [2024-12]            1           20           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           40           1.0\n",
            "1     [2024-02]            1           40           1.0\n",
            "2     [2024-03]            1           40           1.0\n",
            "3     [2024-04]            1           40           1.0\n",
            "4     [2024-05]            1           40           1.0\n",
            "5     [2024-06]            1           40           1.0\n",
            "6     [2024-07]            1           40           1.0\n",
            "7     [2024-08]            1           40           1.0\n",
            "8     [2024-09]            1           40           1.0\n",
            "9     [2024-10]            1           40           1.0\n",
            "10    [2024-11]            1           40           1.0\n",
            "11    [2024-12]            1           40           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           60           1.0\n",
            "1     [2024-02]            1           60           1.0\n",
            "2     [2024-03]            1           60           1.0\n",
            "3     [2024-04]            1           60           1.0\n",
            "4     [2024-05]            1           60           1.0\n",
            "5     [2024-06]            1           60           1.0\n",
            "6     [2024-07]            1           60           1.0\n",
            "7     [2024-08]            1           60           1.0\n",
            "8     [2024-09]            1           60           1.0\n",
            "9     [2024-10]            1           60           1.0\n",
            "10    [2024-11]            1           60           1.0\n",
            "11    [2024-12]            1           60           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           80           1.0\n",
            "1     [2024-02]            1           80           1.0\n",
            "2     [2024-03]            1           80           1.0\n",
            "3     [2024-04]            1           80           1.0\n",
            "4     [2024-05]            1           80           1.0\n",
            "5     [2024-06]            1           80           1.0\n",
            "6     [2024-07]            1           80           1.0\n",
            "7     [2024-08]            1           80           1.0\n",
            "8     [2024-09]            1           80           1.0\n",
            "9     [2024-10]            1           80           1.0\n",
            "10    [2024-11]            1           80           1.0\n",
            "11    [2024-12]            1           80           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1          100           1.0\n",
            "1     [2024-02]            1          100           1.0\n",
            "2     [2024-03]            1          100           1.0\n",
            "3     [2024-04]            1          100           1.0\n",
            "4     [2024-05]            1          100           1.0\n",
            "5     [2024-06]            1          100           1.0\n",
            "6     [2024-07]            1          100           1.0\n",
            "7     [2024-08]            1          100           1.0\n",
            "8     [2024-09]            1          100           1.0\n",
            "9     [2024-10]            1          100           1.0\n",
            "10    [2024-11]            1          100           1.0\n",
            "11    [2024-12]            1          100           1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS1, 2 mesi di dati"
      ],
      "metadata": {
        "id": "ZJj5He25ztwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS1_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_20[features])\n",
        "  T_val = scaler_T.transform(df_DS1_20[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS1_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS1_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_40[features])\n",
        "  T_val = scaler_T.transform(df_DS1_40[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":40,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS1_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS1_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_60[features])\n",
        "  T_val = scaler_T.transform(df_DS1_60[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":60,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS1_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS1_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_80[features])\n",
        "  T_val = scaler_T.transform(df_DS1_80[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":80,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS1_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS1_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_100[features])\n",
        "  T_val = scaler_T.transform(df_DS1_100[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":100,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS1_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS1_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-czB8iqzyBU",
        "outputId": "1ded79d8-11bf-4ff7-930e-0061adbd090d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           20           1.0\n",
            "1   [2024-02, 2024-03]            2           20           1.0\n",
            "2   [2024-03, 2024-04]            2           20           1.0\n",
            "3   [2024-04, 2024-05]            2           20           1.0\n",
            "4   [2024-05, 2024-06]            2           20           1.0\n",
            "5   [2024-06, 2024-07]            2           20           1.0\n",
            "6   [2024-07, 2024-08]            2           20           1.0\n",
            "7   [2024-08, 2024-09]            2           20           1.0\n",
            "8   [2024-09, 2024-10]            2           20           1.0\n",
            "9   [2024-10, 2024-11]            2           20           1.0\n",
            "10  [2024-11, 2024-12]            2           20           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           40           1.0\n",
            "1   [2024-02, 2024-03]            2           40           1.0\n",
            "2   [2024-03, 2024-04]            2           40           1.0\n",
            "3   [2024-04, 2024-05]            2           40           1.0\n",
            "4   [2024-05, 2024-06]            2           40           1.0\n",
            "5   [2024-06, 2024-07]            2           40           1.0\n",
            "6   [2024-07, 2024-08]            2           40           1.0\n",
            "7   [2024-08, 2024-09]            2           40           1.0\n",
            "8   [2024-09, 2024-10]            2           40           1.0\n",
            "9   [2024-10, 2024-11]            2           40           1.0\n",
            "10  [2024-11, 2024-12]            2           40           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           60           1.0\n",
            "1   [2024-02, 2024-03]            2           60           1.0\n",
            "2   [2024-03, 2024-04]            2           60           1.0\n",
            "3   [2024-04, 2024-05]            2           60           1.0\n",
            "4   [2024-05, 2024-06]            2           60           1.0\n",
            "5   [2024-06, 2024-07]            2           60           1.0\n",
            "6   [2024-07, 2024-08]            2           60           1.0\n",
            "7   [2024-08, 2024-09]            2           60           1.0\n",
            "8   [2024-09, 2024-10]            2           60           1.0\n",
            "9   [2024-10, 2024-11]            2           60           1.0\n",
            "10  [2024-11, 2024-12]            2           60           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           80           1.0\n",
            "1   [2024-02, 2024-03]            2           80           1.0\n",
            "2   [2024-03, 2024-04]            2           80           1.0\n",
            "3   [2024-04, 2024-05]            2           80           1.0\n",
            "4   [2024-05, 2024-06]            2           80           1.0\n",
            "5   [2024-06, 2024-07]            2           80           1.0\n",
            "6   [2024-07, 2024-08]            2           80           1.0\n",
            "7   [2024-08, 2024-09]            2           80           1.0\n",
            "8   [2024-09, 2024-10]            2           80           1.0\n",
            "9   [2024-10, 2024-11]            2           80           1.0\n",
            "10  [2024-11, 2024-12]            2           80           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2          100           1.0\n",
            "1   [2024-02, 2024-03]            2          100           1.0\n",
            "2   [2024-03, 2024-04]            2          100           1.0\n",
            "3   [2024-04, 2024-05]            2          100           1.0\n",
            "4   [2024-05, 2024-06]            2          100           1.0\n",
            "5   [2024-06, 2024-07]            2          100           1.0\n",
            "6   [2024-07, 2024-08]            2          100           1.0\n",
            "7   [2024-08, 2024-09]            2          100           1.0\n",
            "8   [2024-09, 2024-10]            2          100           1.0\n",
            "9   [2024-10, 2024-11]            2          100           1.0\n",
            "10  [2024-11, 2024-12]            2          100           1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS1, 4 mesi di dati"
      ],
      "metadata": {
        "id": "8sllDoYrzuNP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS1_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_20[features])\n",
        "  T_val = scaler_T.transform(df_DS1_20[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS1_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS1_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_40[features])\n",
        "  T_val = scaler_T.transform(df_DS1_40[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":40,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS1_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS1_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_60[features])\n",
        "  T_val = scaler_T.transform(df_DS1_60[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":60,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS1_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS1_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_80[features])\n",
        "  T_val = scaler_T.transform(df_DS1_80[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":80,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS1_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS1_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_100[features])\n",
        "  T_val = scaler_T.transform(df_DS1_100[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":100,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS1_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS1_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k234p7XC0zGm",
        "outputId": "45836223-db80-4a99-98ce-85d40dbbc76f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           20   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           20   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           20   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           20   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           20   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           20   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           20   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           20   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           20   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           40   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           40   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           40   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           40   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           40   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           40   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           40   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           40   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           40   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           60   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           60   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           60   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           60   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           60   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           60   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           60   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           60   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           60   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           80   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           80   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           80   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           80   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           80   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           80   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           80   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           80   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           80   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4          100   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4          100   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4          100   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4          100   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4          100   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4          100   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4          100   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4          100   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4          100   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS1, 6 mesi di dati"
      ],
      "metadata": {
        "id": "6hdL4PA2zuSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS1_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_20[features])\n",
        "  T_val = scaler_T.transform(df_DS1_20[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS1_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS1_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_40[features])\n",
        "  T_val = scaler_T.transform(df_DS1_40[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":40,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS1_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS1_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_60[features])\n",
        "  T_val = scaler_T.transform(df_DS1_60[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":60,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS1_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS1_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_80[features])\n",
        "  T_val = scaler_T.transform(df_DS1_80[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":80,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS1_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS1_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_100[features])\n",
        "  T_val = scaler_T.transform(df_DS1_100[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":100,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS1_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS1_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZkRWUYD1JnD",
        "outputId": "b3c9d6c5-2c64-4618-da30-ccc054556ba5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           20           1.0  \n",
            "1           20           1.0  \n",
            "2           20           1.0  \n",
            "3           20           1.0  \n",
            "4           20           1.0  \n",
            "5           20           1.0  \n",
            "6           20           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           40           1.0  \n",
            "1           40           1.0  \n",
            "2           40           1.0  \n",
            "3           40           1.0  \n",
            "4           40           1.0  \n",
            "5           40           1.0  \n",
            "6           40           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           60           1.0  \n",
            "1           60           1.0  \n",
            "2           60           1.0  \n",
            "3           60           1.0  \n",
            "4           60           1.0  \n",
            "5           60           1.0  \n",
            "6           60           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           80           1.0  \n",
            "1           80           1.0  \n",
            "2           80           1.0  \n",
            "3           80           1.0  \n",
            "4           80           1.0  \n",
            "5           80           1.0  \n",
            "6           80           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0          100           1.0  \n",
            "1          100           1.0  \n",
            "2          100           1.0  \n",
            "3          100           1.0  \n",
            "4          100           1.0  \n",
            "5          100           1.0  \n",
            "6          100           1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS2, 1 mese di dati"
      ],
      "metadata": {
        "id": "Yqqy4EUYzuWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS2_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_20[features])\n",
        "  T_val = scaler_T.transform(df_DS2_20[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS2_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS2_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_40[features])\n",
        "  T_val = scaler_T.transform(df_DS2_40[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":40,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS2_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS2_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_60[features])\n",
        "  T_val = scaler_T.transform(df_DS2_60[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":60,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS2_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS2_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_80[features])\n",
        "  T_val = scaler_T.transform(df_DS2_80[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":80,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS2_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS2_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_100[features])\n",
        "  T_val = scaler_T.transform(df_DS2_100[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":100,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS2_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS2_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nG9oao9N1djq",
        "outputId": "bf533a2b-7c43-44e1-ee8b-1dc70b87cf66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           20           1.0\n",
            "1     [2024-02]            1           20           1.0\n",
            "2     [2024-03]            1           20           1.0\n",
            "3     [2024-04]            1           20           1.0\n",
            "4     [2024-05]            1           20           1.0\n",
            "5     [2024-06]            1           20           1.0\n",
            "6     [2024-07]            1           20           1.0\n",
            "7     [2024-08]            1           20           1.0\n",
            "8     [2024-09]            1           20           1.0\n",
            "9     [2024-10]            1           20           1.0\n",
            "10    [2024-11]            1           20           1.0\n",
            "11    [2024-12]            1           20           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           40           1.0\n",
            "1     [2024-02]            1           40           1.0\n",
            "2     [2024-03]            1           40           1.0\n",
            "3     [2024-04]            1           40           1.0\n",
            "4     [2024-05]            1           40           1.0\n",
            "5     [2024-06]            1           40           1.0\n",
            "6     [2024-07]            1           40           1.0\n",
            "7     [2024-08]            1           40           1.0\n",
            "8     [2024-09]            1           40           1.0\n",
            "9     [2024-10]            1           40           1.0\n",
            "10    [2024-11]            1           40           1.0\n",
            "11    [2024-12]            1           40           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           60           1.0\n",
            "1     [2024-02]            1           60           1.0\n",
            "2     [2024-03]            1           60           1.0\n",
            "3     [2024-04]            1           60           1.0\n",
            "4     [2024-05]            1           60           1.0\n",
            "5     [2024-06]            1           60           1.0\n",
            "6     [2024-07]            1           60           1.0\n",
            "7     [2024-08]            1           60           1.0\n",
            "8     [2024-09]            1           60           1.0\n",
            "9     [2024-10]            1           60           1.0\n",
            "10    [2024-11]            1           60           1.0\n",
            "11    [2024-12]            1           60           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           80           1.0\n",
            "1     [2024-02]            1           80           1.0\n",
            "2     [2024-03]            1           80           1.0\n",
            "3     [2024-04]            1           80           1.0\n",
            "4     [2024-05]            1           80           1.0\n",
            "5     [2024-06]            1           80           1.0\n",
            "6     [2024-07]            1           80           1.0\n",
            "7     [2024-08]            1           80           1.0\n",
            "8     [2024-09]            1           80           1.0\n",
            "9     [2024-10]            1           80           1.0\n",
            "10    [2024-11]            1           80           1.0\n",
            "11    [2024-12]            1           80           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1          100           1.0\n",
            "1     [2024-02]            1          100           1.0\n",
            "2     [2024-03]            1          100           1.0\n",
            "3     [2024-04]            1          100           1.0\n",
            "4     [2024-05]            1          100           1.0\n",
            "5     [2024-06]            1          100           1.0\n",
            "6     [2024-07]            1          100           1.0\n",
            "7     [2024-08]            1          100           1.0\n",
            "8     [2024-09]            1          100           1.0\n",
            "9     [2024-10]            1          100           1.0\n",
            "10    [2024-11]            1          100           1.0\n",
            "11    [2024-12]            1          100           1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS2, 2 mesi di dati"
      ],
      "metadata": {
        "id": "FqrTZvQhzuaz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS2_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_20[features])\n",
        "  T_val = scaler_T.transform(df_DS2_20[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS2_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS2_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_40[features])\n",
        "  T_val = scaler_T.transform(df_DS2_40[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":40,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS2_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS2_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_60[features])\n",
        "  T_val = scaler_T.transform(df_DS2_60[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":60,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS2_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS2_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_80[features])\n",
        "  T_val = scaler_T.transform(df_DS2_80[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":80,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS2_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS2_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_100[features])\n",
        "  T_val = scaler_T.transform(df_DS2_100[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":100,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS2_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS2_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-SjJBy31-4s",
        "outputId": "0a2e3089-29e5-4acd-f850-214fb1f57679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           20           1.0\n",
            "1   [2024-02, 2024-03]            2           20           1.0\n",
            "2   [2024-03, 2024-04]            2           20           1.0\n",
            "3   [2024-04, 2024-05]            2           20           1.0\n",
            "4   [2024-05, 2024-06]            2           20           1.0\n",
            "5   [2024-06, 2024-07]            2           20           1.0\n",
            "6   [2024-07, 2024-08]            2           20           1.0\n",
            "7   [2024-08, 2024-09]            2           20           1.0\n",
            "8   [2024-09, 2024-10]            2           20           1.0\n",
            "9   [2024-10, 2024-11]            2           20           1.0\n",
            "10  [2024-11, 2024-12]            2           20           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           40           1.0\n",
            "1   [2024-02, 2024-03]            2           40           1.0\n",
            "2   [2024-03, 2024-04]            2           40           1.0\n",
            "3   [2024-04, 2024-05]            2           40           1.0\n",
            "4   [2024-05, 2024-06]            2           40           1.0\n",
            "5   [2024-06, 2024-07]            2           40           1.0\n",
            "6   [2024-07, 2024-08]            2           40           1.0\n",
            "7   [2024-08, 2024-09]            2           40           1.0\n",
            "8   [2024-09, 2024-10]            2           40           1.0\n",
            "9   [2024-10, 2024-11]            2           40           1.0\n",
            "10  [2024-11, 2024-12]            2           40           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           60           1.0\n",
            "1   [2024-02, 2024-03]            2           60           1.0\n",
            "2   [2024-03, 2024-04]            2           60           1.0\n",
            "3   [2024-04, 2024-05]            2           60           1.0\n",
            "4   [2024-05, 2024-06]            2           60           1.0\n",
            "5   [2024-06, 2024-07]            2           60           1.0\n",
            "6   [2024-07, 2024-08]            2           60           1.0\n",
            "7   [2024-08, 2024-09]            2           60           1.0\n",
            "8   [2024-09, 2024-10]            2           60           1.0\n",
            "9   [2024-10, 2024-11]            2           60           1.0\n",
            "10  [2024-11, 2024-12]            2           60           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           80           1.0\n",
            "1   [2024-02, 2024-03]            2           80           1.0\n",
            "2   [2024-03, 2024-04]            2           80           1.0\n",
            "3   [2024-04, 2024-05]            2           80           1.0\n",
            "4   [2024-05, 2024-06]            2           80           1.0\n",
            "5   [2024-06, 2024-07]            2           80           1.0\n",
            "6   [2024-07, 2024-08]            2           80           1.0\n",
            "7   [2024-08, 2024-09]            2           80           1.0\n",
            "8   [2024-09, 2024-10]            2           80           1.0\n",
            "9   [2024-10, 2024-11]            2           80           1.0\n",
            "10  [2024-11, 2024-12]            2           80           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2          100           1.0\n",
            "1   [2024-02, 2024-03]            2          100           1.0\n",
            "2   [2024-03, 2024-04]            2          100           1.0\n",
            "3   [2024-04, 2024-05]            2          100           1.0\n",
            "4   [2024-05, 2024-06]            2          100           1.0\n",
            "5   [2024-06, 2024-07]            2          100           1.0\n",
            "6   [2024-07, 2024-08]            2          100           1.0\n",
            "7   [2024-08, 2024-09]            2          100           1.0\n",
            "8   [2024-09, 2024-10]            2          100           1.0\n",
            "9   [2024-10, 2024-11]            2          100           1.0\n",
            "10  [2024-11, 2024-12]            2          100           1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS2, 4 mesi di dati"
      ],
      "metadata": {
        "id": "_aw5Tq5-zuch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS2_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_20[features])\n",
        "  T_val = scaler_T.transform(df_DS2_20[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS2_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS2_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_40[features])\n",
        "  T_val = scaler_T.transform(df_DS2_40[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":40,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS2_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS2_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_60[features])\n",
        "  T_val = scaler_T.transform(df_DS2_60[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":60,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS2_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS2_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_80[features])\n",
        "  T_val = scaler_T.transform(df_DS2_80[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":80,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS2_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS2_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_100[features])\n",
        "  T_val = scaler_T.transform(df_DS2_100[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":100,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS2_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS2_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDoAH2D120vU",
        "outputId": "87eda9ec-89f4-41f5-8af7-c61f8622044c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           20   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           20   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           20   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           20   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           20   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           20   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           20   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           20   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           20   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           40   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           40   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           40   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           40   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           40   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           40   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           40   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           40   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           40   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           60   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           60   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           60   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           60   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           60   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           60   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           60   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           60   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           60   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           80   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           80   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           80   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           80   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           80   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           80   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           80   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           80   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           80   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4          100   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4          100   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4          100   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4          100   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4          100   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4          100   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4          100   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4          100   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4          100   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS2, 6 mesi di dati"
      ],
      "metadata": {
        "id": "bVvkKsODzueF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS2_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_20[features])\n",
        "  T_val = scaler_T.transform(df_DS2_20[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS2_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS2_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_40[features])\n",
        "  T_val = scaler_T.transform(df_DS2_40[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":40,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS2_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS2_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_60[features])\n",
        "  T_val = scaler_T.transform(df_DS2_60[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":60,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS2_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS2_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_80[features])\n",
        "  T_val = scaler_T.transform(df_DS2_80[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":80,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS2_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS2_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_100[features])\n",
        "  T_val = scaler_T.transform(df_DS2_100[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":100,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS2_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS2_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rmxguc3F3Elv",
        "outputId": "70702468-4e09-4cc8-e186-43ed31c2a952"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           20           1.0  \n",
            "1           20           1.0  \n",
            "2           20           1.0  \n",
            "3           20           1.0  \n",
            "4           20           1.0  \n",
            "5           20           1.0  \n",
            "6           20           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           40           1.0  \n",
            "1           40           1.0  \n",
            "2           40           1.0  \n",
            "3           40           1.0  \n",
            "4           40           1.0  \n",
            "5           40           1.0  \n",
            "6           40           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           60           1.0  \n",
            "1           60           1.0  \n",
            "2           60           1.0  \n",
            "3           60           1.0  \n",
            "4           60           1.0  \n",
            "5           60           1.0  \n",
            "6           60           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           80           1.0  \n",
            "1           80           1.0  \n",
            "2           80           1.0  \n",
            "3           80           1.0  \n",
            "4           80           1.0  \n",
            "5           80           1.0  \n",
            "6           80           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0          100           1.0  \n",
            "1          100           1.0  \n",
            "2          100           1.0  \n",
            "3          100           1.0  \n",
            "4          100           1.0  \n",
            "5          100           1.0  \n",
            "6          100           1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS3, 1 mese di dati"
      ],
      "metadata": {
        "id": "6ohvVx3Gzufj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS3_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_20[features])\n",
        "  T_val = scaler_T.transform(df_DS3_20[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS3_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS3_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_40[features])\n",
        "  T_val = scaler_T.transform(df_DS3_40[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":40,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS3_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS3_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_60[features])\n",
        "  T_val = scaler_T.transform(df_DS3_60[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":60,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS3_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS3_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_80[features])\n",
        "  T_val = scaler_T.transform(df_DS3_80[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":80,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS3_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS3_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_100[features])\n",
        "  T_val = scaler_T.transform(df_DS3_100[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":100,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS3_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS3_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sM5zlil64SuM",
        "outputId": "fb840df9-dac9-4e25-9d4a-970a24c63190"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           20           1.0\n",
            "1     [2024-02]            1           20           1.0\n",
            "2     [2024-03]            1           20           1.0\n",
            "3     [2024-04]            1           20           1.0\n",
            "4     [2024-05]            1           20           1.0\n",
            "5     [2024-06]            1           20           1.0\n",
            "6     [2024-07]            1           20           1.0\n",
            "7     [2024-08]            1           20           1.0\n",
            "8     [2024-09]            1           20           1.0\n",
            "9     [2024-10]            1           20           1.0\n",
            "10    [2024-11]            1           20           1.0\n",
            "11    [2024-12]            1           20           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           40           1.0\n",
            "1     [2024-02]            1           40           1.0\n",
            "2     [2024-03]            1           40           1.0\n",
            "3     [2024-04]            1           40           1.0\n",
            "4     [2024-05]            1           40           1.0\n",
            "5     [2024-06]            1           40           1.0\n",
            "6     [2024-07]            1           40           1.0\n",
            "7     [2024-08]            1           40           1.0\n",
            "8     [2024-09]            1           40           1.0\n",
            "9     [2024-10]            1           40           1.0\n",
            "10    [2024-11]            1           40           1.0\n",
            "11    [2024-12]            1           40           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           60           1.0\n",
            "1     [2024-02]            1           60           1.0\n",
            "2     [2024-03]            1           60           1.0\n",
            "3     [2024-04]            1           60           1.0\n",
            "4     [2024-05]            1           60           1.0\n",
            "5     [2024-06]            1           60           1.0\n",
            "6     [2024-07]            1           60           1.0\n",
            "7     [2024-08]            1           60           1.0\n",
            "8     [2024-09]            1           60           1.0\n",
            "9     [2024-10]            1           60           1.0\n",
            "10    [2024-11]            1           60           1.0\n",
            "11    [2024-12]            1           60           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           80           1.0\n",
            "1     [2024-02]            1           80           1.0\n",
            "2     [2024-03]            1           80           1.0\n",
            "3     [2024-04]            1           80           1.0\n",
            "4     [2024-05]            1           80           1.0\n",
            "5     [2024-06]            1           80           1.0\n",
            "6     [2024-07]            1           80           1.0\n",
            "7     [2024-08]            1           80           1.0\n",
            "8     [2024-09]            1           80           1.0\n",
            "9     [2024-10]            1           80           1.0\n",
            "10    [2024-11]            1           80           1.0\n",
            "11    [2024-12]            1           80           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1          100           1.0\n",
            "1     [2024-02]            1          100           1.0\n",
            "2     [2024-03]            1          100           1.0\n",
            "3     [2024-04]            1          100           1.0\n",
            "4     [2024-05]            1          100           1.0\n",
            "5     [2024-06]            1          100           1.0\n",
            "6     [2024-07]            1          100           1.0\n",
            "7     [2024-08]            1          100           1.0\n",
            "8     [2024-09]            1          100           1.0\n",
            "9     [2024-10]            1          100           1.0\n",
            "10    [2024-11]            1          100           1.0\n",
            "11    [2024-12]            1          100           1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS3, 2 mesi di dati"
      ],
      "metadata": {
        "id": "-ChSFxTAzuhb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS3_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_20[features])\n",
        "  T_val = scaler_T.transform(df_DS3_20[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS3_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS3_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_40[features])\n",
        "  T_val = scaler_T.transform(df_DS3_40[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":40,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS3_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS3_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_60[features])\n",
        "  T_val = scaler_T.transform(df_DS3_60[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":60,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS3_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS3_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_80[features])\n",
        "  T_val = scaler_T.transform(df_DS3_80[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":80,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS3_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS3_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_100[features])\n",
        "  T_val = scaler_T.transform(df_DS3_100[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":100,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS3_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS3_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fr-dfMq04uCO",
        "outputId": "a20e0077-2036-47c2-ae53-408921c71a3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           20           1.0\n",
            "1   [2024-02, 2024-03]            2           20           1.0\n",
            "2   [2024-03, 2024-04]            2           20           1.0\n",
            "3   [2024-04, 2024-05]            2           20           1.0\n",
            "4   [2024-05, 2024-06]            2           20           1.0\n",
            "5   [2024-06, 2024-07]            2           20           1.0\n",
            "6   [2024-07, 2024-08]            2           20           1.0\n",
            "7   [2024-08, 2024-09]            2           20           1.0\n",
            "8   [2024-09, 2024-10]            2           20           1.0\n",
            "9   [2024-10, 2024-11]            2           20           1.0\n",
            "10  [2024-11, 2024-12]            2           20           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           40           1.0\n",
            "1   [2024-02, 2024-03]            2           40           1.0\n",
            "2   [2024-03, 2024-04]            2           40           1.0\n",
            "3   [2024-04, 2024-05]            2           40           1.0\n",
            "4   [2024-05, 2024-06]            2           40           1.0\n",
            "5   [2024-06, 2024-07]            2           40           1.0\n",
            "6   [2024-07, 2024-08]            2           40           1.0\n",
            "7   [2024-08, 2024-09]            2           40           1.0\n",
            "8   [2024-09, 2024-10]            2           40           1.0\n",
            "9   [2024-10, 2024-11]            2           40           1.0\n",
            "10  [2024-11, 2024-12]            2           40           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           60           1.0\n",
            "1   [2024-02, 2024-03]            2           60           1.0\n",
            "2   [2024-03, 2024-04]            2           60           1.0\n",
            "3   [2024-04, 2024-05]            2           60           1.0\n",
            "4   [2024-05, 2024-06]            2           60           1.0\n",
            "5   [2024-06, 2024-07]            2           60           1.0\n",
            "6   [2024-07, 2024-08]            2           60           1.0\n",
            "7   [2024-08, 2024-09]            2           60           1.0\n",
            "8   [2024-09, 2024-10]            2           60           1.0\n",
            "9   [2024-10, 2024-11]            2           60           1.0\n",
            "10  [2024-11, 2024-12]            2           60           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           80           1.0\n",
            "1   [2024-02, 2024-03]            2           80           1.0\n",
            "2   [2024-03, 2024-04]            2           80           1.0\n",
            "3   [2024-04, 2024-05]            2           80           1.0\n",
            "4   [2024-05, 2024-06]            2           80           1.0\n",
            "5   [2024-06, 2024-07]            2           80           1.0\n",
            "6   [2024-07, 2024-08]            2           80           1.0\n",
            "7   [2024-08, 2024-09]            2           80           1.0\n",
            "8   [2024-09, 2024-10]            2           80           1.0\n",
            "9   [2024-10, 2024-11]            2           80           1.0\n",
            "10  [2024-11, 2024-12]            2           80           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2          100           1.0\n",
            "1   [2024-02, 2024-03]            2          100           1.0\n",
            "2   [2024-03, 2024-04]            2          100           1.0\n",
            "3   [2024-04, 2024-05]            2          100           1.0\n",
            "4   [2024-05, 2024-06]            2          100           1.0\n",
            "5   [2024-06, 2024-07]            2          100           1.0\n",
            "6   [2024-07, 2024-08]            2          100           1.0\n",
            "7   [2024-08, 2024-09]            2          100           1.0\n",
            "8   [2024-09, 2024-10]            2          100           1.0\n",
            "9   [2024-10, 2024-11]            2          100           1.0\n",
            "10  [2024-11, 2024-12]            2          100           1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS3, 4 mesi di dati"
      ],
      "metadata": {
        "id": "3pmF4M-JzujR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS3_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_20[features])\n",
        "  T_val = scaler_T.transform(df_DS3_20[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS3_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS3_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_40[features])\n",
        "  T_val = scaler_T.transform(df_DS3_40[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":40,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS3_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS3_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_60[features])\n",
        "  T_val = scaler_T.transform(df_DS3_60[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":60,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS3_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS3_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_80[features])\n",
        "  T_val = scaler_T.transform(df_DS3_80[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":80,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS3_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS3_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_100[features])\n",
        "  T_val = scaler_T.transform(df_DS3_100[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":100,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS3_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS3_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoXM_DyO6gbT",
        "outputId": "152a6f13-5348-4fb9-d276-fc835670905f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           20   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           20   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           20   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           20   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           20   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           20   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           20   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           20   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           20   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           40   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           40   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           40   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           40   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           40   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           40   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           40   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           40   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           40   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           60   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           60   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           60   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           60   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           60   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           60   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           60   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           60   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           60   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           80   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           80   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           80   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           80   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           80   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           80   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           80   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           80   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           80   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4          100   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4          100   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4          100   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4          100   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4          100   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4          100   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4          100   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4          100   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4          100   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS3, 6 mesi di dati"
      ],
      "metadata": {
        "id": "4X0f3Tmyzula"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS3_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_20[features])\n",
        "  T_val = scaler_T.transform(df_DS3_20[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS3_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS3_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_40[features])\n",
        "  T_val = scaler_T.transform(df_DS3_40[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":40,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS3_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS3_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_60[features])\n",
        "  T_val = scaler_T.transform(df_DS3_60[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":60,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS3_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS3_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_80[features])\n",
        "  T_val = scaler_T.transform(df_DS3_80[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":80,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS3_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS3_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_100[features])\n",
        "  T_val = scaler_T.transform(df_DS3_100[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":100,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS3_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS3_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TJNA8cR6vrp",
        "outputId": "505a9a63-d6b3-4b68-901f-0922d3f8cda0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           20           1.0  \n",
            "1           20           1.0  \n",
            "2           20           1.0  \n",
            "3           20           1.0  \n",
            "4           20           1.0  \n",
            "5           20           1.0  \n",
            "6           20           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           40           1.0  \n",
            "1           40           1.0  \n",
            "2           40           1.0  \n",
            "3           40           1.0  \n",
            "4           40           1.0  \n",
            "5           40           1.0  \n",
            "6           40           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           60           1.0  \n",
            "1           60           1.0  \n",
            "2           60           1.0  \n",
            "3           60           1.0  \n",
            "4           60           1.0  \n",
            "5           60           1.0  \n",
            "6           60           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           80           1.0  \n",
            "1           80           1.0  \n",
            "2           80           1.0  \n",
            "3           80           1.0  \n",
            "4           80           1.0  \n",
            "5           80           1.0  \n",
            "6           80           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0          100           1.0  \n",
            "1          100           1.0  \n",
            "2          100           1.0  \n",
            "3          100           1.0  \n",
            "4          100           1.0  \n",
            "5          100           1.0  \n",
            "6          100           1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS4, 1 mese di dati"
      ],
      "metadata": {
        "id": "HfV4fT5Izu06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS4_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_20[features])\n",
        "  T_val = scaler_T.transform(df_DS4_20[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS4_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS4_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_40[features])\n",
        "  T_val = scaler_T.transform(df_DS4_40[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":40,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS4_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS4_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_60[features])\n",
        "  T_val = scaler_T.transform(df_DS4_60[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":60,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS4_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS4_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_80[features])\n",
        "  T_val = scaler_T.transform(df_DS4_80[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":80,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS4_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS4_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_100[features])\n",
        "  T_val = scaler_T.transform(df_DS4_100[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":100,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS4_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS4_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcRPpY5Z7GGB",
        "outputId": "97d087b7-2258-4ada-d0b3-df78561949f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           20           1.0\n",
            "1     [2024-02]            1           20           1.0\n",
            "2     [2024-03]            1           20           1.0\n",
            "3     [2024-04]            1           20           1.0\n",
            "4     [2024-05]            1           20           1.0\n",
            "5     [2024-06]            1           20           1.0\n",
            "6     [2024-07]            1           20           1.0\n",
            "7     [2024-08]            1           20           1.0\n",
            "8     [2024-09]            1           20           1.0\n",
            "9     [2024-10]            1           20           1.0\n",
            "10    [2024-11]            1           20           1.0\n",
            "11    [2024-12]            1           20           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           40           1.0\n",
            "1     [2024-02]            1           40           1.0\n",
            "2     [2024-03]            1           40           1.0\n",
            "3     [2024-04]            1           40           1.0\n",
            "4     [2024-05]            1           40           1.0\n",
            "5     [2024-06]            1           40           1.0\n",
            "6     [2024-07]            1           40           1.0\n",
            "7     [2024-08]            1           40           1.0\n",
            "8     [2024-09]            1           40           1.0\n",
            "9     [2024-10]            1           40           1.0\n",
            "10    [2024-11]            1           40           1.0\n",
            "11    [2024-12]            1           40           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           60           1.0\n",
            "1     [2024-02]            1           60           1.0\n",
            "2     [2024-03]            1           60           1.0\n",
            "3     [2024-04]            1           60           1.0\n",
            "4     [2024-05]            1           60           1.0\n",
            "5     [2024-06]            1           60           1.0\n",
            "6     [2024-07]            1           60           1.0\n",
            "7     [2024-08]            1           60           1.0\n",
            "8     [2024-09]            1           60           1.0\n",
            "9     [2024-10]            1           60           1.0\n",
            "10    [2024-11]            1           60           1.0\n",
            "11    [2024-12]            1           60           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           80           1.0\n",
            "1     [2024-02]            1           80           1.0\n",
            "2     [2024-03]            1           80           1.0\n",
            "3     [2024-04]            1           80           1.0\n",
            "4     [2024-05]            1           80           1.0\n",
            "5     [2024-06]            1           80           1.0\n",
            "6     [2024-07]            1           80           1.0\n",
            "7     [2024-08]            1           80           1.0\n",
            "8     [2024-09]            1           80           1.0\n",
            "9     [2024-10]            1           80           1.0\n",
            "10    [2024-11]            1           80           1.0\n",
            "11    [2024-12]            1           80           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1          100           1.0\n",
            "1     [2024-02]            1          100           1.0\n",
            "2     [2024-03]            1          100           1.0\n",
            "3     [2024-04]            1          100           1.0\n",
            "4     [2024-05]            1          100           1.0\n",
            "5     [2024-06]            1          100           1.0\n",
            "6     [2024-07]            1          100           1.0\n",
            "7     [2024-08]            1          100           1.0\n",
            "8     [2024-09]            1          100           1.0\n",
            "9     [2024-10]            1          100           1.0\n",
            "10    [2024-11]            1          100           1.0\n",
            "11    [2024-12]            1          100           1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS4, 2 mesi di dati"
      ],
      "metadata": {
        "id": "WpXq9eIazu44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS4_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_20[features])\n",
        "  T_val = scaler_T.transform(df_DS4_20[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS4_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS4_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_40[features])\n",
        "  T_val = scaler_T.transform(df_DS4_40[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":40,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS4_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS4_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_60[features])\n",
        "  T_val = scaler_T.transform(df_DS4_60[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":60,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS4_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS4_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_80[features])\n",
        "  T_val = scaler_T.transform(df_DS4_80[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":80,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS4_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS4_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_100[features])\n",
        "  T_val = scaler_T.transform(df_DS4_100[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":100,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS4_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS4_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Av54M2Jz7wMH",
        "outputId": "2237fad0-44e0-4235-90ec-7cfe2a67c465"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           20           1.0\n",
            "1   [2024-02, 2024-03]            2           20           1.0\n",
            "2   [2024-03, 2024-04]            2           20           1.0\n",
            "3   [2024-04, 2024-05]            2           20           1.0\n",
            "4   [2024-05, 2024-06]            2           20           1.0\n",
            "5   [2024-06, 2024-07]            2           20           1.0\n",
            "6   [2024-07, 2024-08]            2           20           1.0\n",
            "7   [2024-08, 2024-09]            2           20           1.0\n",
            "8   [2024-09, 2024-10]            2           20           1.0\n",
            "9   [2024-10, 2024-11]            2           20           1.0\n",
            "10  [2024-11, 2024-12]            2           20           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           40           1.0\n",
            "1   [2024-02, 2024-03]            2           40           1.0\n",
            "2   [2024-03, 2024-04]            2           40           1.0\n",
            "3   [2024-04, 2024-05]            2           40           1.0\n",
            "4   [2024-05, 2024-06]            2           40           1.0\n",
            "5   [2024-06, 2024-07]            2           40           1.0\n",
            "6   [2024-07, 2024-08]            2           40           1.0\n",
            "7   [2024-08, 2024-09]            2           40           1.0\n",
            "8   [2024-09, 2024-10]            2           40           1.0\n",
            "9   [2024-10, 2024-11]            2           40           1.0\n",
            "10  [2024-11, 2024-12]            2           40           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           60           1.0\n",
            "1   [2024-02, 2024-03]            2           60           1.0\n",
            "2   [2024-03, 2024-04]            2           60           1.0\n",
            "3   [2024-04, 2024-05]            2           60           1.0\n",
            "4   [2024-05, 2024-06]            2           60           1.0\n",
            "5   [2024-06, 2024-07]            2           60           1.0\n",
            "6   [2024-07, 2024-08]            2           60           1.0\n",
            "7   [2024-08, 2024-09]            2           60           1.0\n",
            "8   [2024-09, 2024-10]            2           60           1.0\n",
            "9   [2024-10, 2024-11]            2           60           1.0\n",
            "10  [2024-11, 2024-12]            2           60           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           80           1.0\n",
            "1   [2024-02, 2024-03]            2           80           1.0\n",
            "2   [2024-03, 2024-04]            2           80           1.0\n",
            "3   [2024-04, 2024-05]            2           80           1.0\n",
            "4   [2024-05, 2024-06]            2           80           1.0\n",
            "5   [2024-06, 2024-07]            2           80           1.0\n",
            "6   [2024-07, 2024-08]            2           80           1.0\n",
            "7   [2024-08, 2024-09]            2           80           1.0\n",
            "8   [2024-09, 2024-10]            2           80           1.0\n",
            "9   [2024-10, 2024-11]            2           80           1.0\n",
            "10  [2024-11, 2024-12]            2           80           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2          100           1.0\n",
            "1   [2024-02, 2024-03]            2          100           1.0\n",
            "2   [2024-03, 2024-04]            2          100           1.0\n",
            "3   [2024-04, 2024-05]            2          100           1.0\n",
            "4   [2024-05, 2024-06]            2          100           1.0\n",
            "5   [2024-06, 2024-07]            2          100           1.0\n",
            "6   [2024-07, 2024-08]            2          100           1.0\n",
            "7   [2024-08, 2024-09]            2          100           1.0\n",
            "8   [2024-09, 2024-10]            2          100           1.0\n",
            "9   [2024-10, 2024-11]            2          100           1.0\n",
            "10  [2024-11, 2024-12]            2          100           1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS4, 4 mesi di dati"
      ],
      "metadata": {
        "id": "Ysbj4r_szu7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS4_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_20[features])\n",
        "  T_val = scaler_T.transform(df_DS4_20[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS4_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS4_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_40[features])\n",
        "  T_val = scaler_T.transform(df_DS4_40[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":40,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS4_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS4_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_60[features])\n",
        "  T_val = scaler_T.transform(df_DS4_60[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":60,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS4_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS4_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_80[features])\n",
        "  T_val = scaler_T.transform(df_DS4_80[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":80,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS4_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS4_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_100[features])\n",
        "  T_val = scaler_T.transform(df_DS4_100[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":100,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS4_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS4_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XImh2Xn98Cms",
        "outputId": "09de30de-7bf4-4c0c-e4e9-fa3faea0ecb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           20   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           20   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           20   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           20   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           20   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           20   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           20   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           20   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           20   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           40   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           40   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           40   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           40   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           40   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           40   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           40   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           40   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           40   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           60   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           60   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           60   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           60   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           60   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           60   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           60   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           60   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           60   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           80   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           80   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           80   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           80   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           80   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           80   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           80   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           80   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           80   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4          100   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4          100   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4          100   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4          100   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4          100   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4          100   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4          100   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4          100   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4          100   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS4, 6 mesi di dati"
      ],
      "metadata": {
        "id": "jHqfbadVzu9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS4_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_20[features])\n",
        "  T_val = scaler_T.transform(df_DS4_20[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS4_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS4_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_40[features])\n",
        "  T_val = scaler_T.transform(df_DS4_40[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":40,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS4_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS4_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_60[features])\n",
        "  T_val = scaler_T.transform(df_DS4_60[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":60,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS4_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS4_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_80[features])\n",
        "  T_val = scaler_T.transform(df_DS4_80[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":80,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS4_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS4_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_100[features])\n",
        "  T_val = scaler_T.transform(df_DS4_100[cond])\n",
        "\n",
        "  cvae = CVAE(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae.load_weights(f\"/content/drive/MyDrive/CVAE_beta_1_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months), \"damage size\":100,  \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS4_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS4_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSaxglCi8aE_",
        "outputId": "7900d9fd-5cd8-4602-f25f-b23de4cc66d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           20           1.0  \n",
            "1           20           1.0  \n",
            "2           20           1.0  \n",
            "3           20           1.0  \n",
            "4           20           1.0  \n",
            "5           20           1.0  \n",
            "6           20           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           40           1.0  \n",
            "1           40           1.0  \n",
            "2           40           1.0  \n",
            "3           40           1.0  \n",
            "4           40           1.0  \n",
            "5           40           1.0  \n",
            "6           40           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           60           1.0  \n",
            "1           60           1.0  \n",
            "2           60           1.0  \n",
            "3           60           1.0  \n",
            "4           60           1.0  \n",
            "5           60           1.0  \n",
            "6           60           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           80           1.0  \n",
            "1           80           1.0  \n",
            "2           80           1.0  \n",
            "3           80           1.0  \n",
            "4           80           1.0  \n",
            "5           80           1.0  \n",
            "6           80           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0          100           1.0  \n",
            "1          100           1.0  \n",
            "2          100           1.0  \n",
            "3          100           1.0  \n",
            "4          100           1.0  \n",
            "5          100           1.0  \n",
            "6          100           1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CVAE beta 0.01"
      ],
      "metadata": {
        "id": "LmE44JTACOhu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"keras\")\n",
        "\n",
        "df_temp = pd.read_csv(\"/content/data_temperature.csv\", encoding = \"utf-8\")\n",
        "df_temp[\"timestamp\"] = pd.to_datetime(df_temp[\"timestamp\"])\n",
        "df_temp[\"timestamp\"] = df_temp[\"timestamp\"].dt.tz_localize(None)\n",
        "df_temp = df_temp.sort_values(\"timestamp\")\n",
        "\n",
        "end = \"2025-01-01\"\n",
        "new_df = df_temp[(df_temp[\"timestamp\"] < end)]\n",
        "\n",
        "class Sampling(Layer):\n",
        "  def call(self, inputs):\n",
        "    z_mean, z_log_var = inputs\n",
        "    epsilon = tf.random.normal(shape=tf.shape(z_mean))\n",
        "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "\n",
        "class CVAE_beta001(keras.Model):\n",
        "  def __init__(self, input_dim, cond_dim = 1, latent_dim = 2, beta = 0.01, **kwargs):\n",
        "    super(CVAE_beta001, self).__init__(**kwargs)\n",
        "    self.beta = beta\n",
        "\n",
        "    #encoder\n",
        "    x_input = keras.Input(shape=(input_dim,))\n",
        "    cond_input = keras.Input(shape=(cond_dim,))\n",
        "    x = layers.Concatenate()([x_input, cond_input])\n",
        "    x = layers.Dense(32, activation=\"relu\")(x)\n",
        "    x = layers.Dense(16, activation=\"relu\")(x)\n",
        "    x = layers.Dense(8, activation=\"relu\")(x)\n",
        "    z_mean = layers.Dense(latent_dim)(x)\n",
        "    z_log_var = layers.Dense(latent_dim)(x)\n",
        "\n",
        "    z = Sampling()([z_mean, z_log_var])\n",
        "    self.encoder = keras.Model([x_input, cond_input], [z_mean, z_log_var, z], name=\"encoder\")\n",
        "\n",
        "    #decoder\n",
        "    latent_inputs = keras.Input(shape=(latent_dim,))\n",
        "    cond_inputs_dec = keras.Input(shape=(cond_dim,))\n",
        "    x = layers.Concatenate()([latent_inputs, cond_inputs_dec])\n",
        "    x = layers.Dense(8, activation=\"relu\")(x)\n",
        "    x = layers.Dense(16, activation=\"relu\")(x)\n",
        "    x = layers.Dense(32, activation=\"relu\")(x)\n",
        "    outputs = layers.Dense(input_dim, activation=\"linear\")(x)\n",
        "\n",
        "    self.decoder = keras.Model([latent_inputs, cond_inputs_dec], outputs, name=\"decoder\")\n",
        "\n",
        "  def train_step(self, data):\n",
        "    (x, cond), y = data\n",
        "\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "      z_mean, z_log_var, z = self.encoder([x, cond], training = True)\n",
        "      reconstruction = self.decoder([z, cond], training = True)\n",
        "\n",
        "      reconstruction_loss = tf.reduce_mean(tf.square(x - reconstruction))\n",
        "      kl_loss = -0.5 * tf.reduce_mean(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
        "      total_loss = reconstruction_loss + self.beta * kl_loss\n",
        "\n",
        "    grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "    self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "\n",
        "    return {\"loss\": total_loss, \"recon_loss\": reconstruction_loss, \"kl_loss\": kl_loss}\n",
        "\n",
        "  def call(self, x, cond=None):\n",
        "    # supporta sia call([x, cond]) che call(x, cond)\n",
        "    if cond is None:\n",
        "        # caso in cui arriva [x, cond] come lista\n",
        "        x, cond = x\n",
        "    z_mean, _, z = self.encoder([x, cond])\n",
        "    return self.decoder([z, cond])\n"
      ],
      "metadata": {
        "id": "b_RGoyOoCSfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS1, 1 mese di dati"
      ],
      "metadata": {
        "id": "8qgBiXnSCjo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS1_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_20[features])\n",
        "  T_val = scaler_T.transform(df_DS1_20[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS1_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS1_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_40[features])\n",
        "  T_val = scaler_T.transform(df_DS1_40[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS1_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS1_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_60[features])\n",
        "  T_val = scaler_T.transform(df_DS1_60[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS1_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS1_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_80[features])\n",
        "  T_val = scaler_T.transform(df_DS1_80[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS1_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS1_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_100[features])\n",
        "  T_val = scaler_T.transform(df_DS1_100[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS1_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS1_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZrrVxWgDPLh",
        "outputId": "13eee638-b283-4252-b7da-36e622c299bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           20           1.0\n",
            "1     [2024-02]            1           20           1.0\n",
            "2     [2024-03]            1           20           1.0\n",
            "3     [2024-04]            1           20           1.0\n",
            "4     [2024-05]            1           20           1.0\n",
            "5     [2024-06]            1           20           1.0\n",
            "6     [2024-07]            1           20           1.0\n",
            "7     [2024-08]            1           20           1.0\n",
            "8     [2024-09]            1           20           1.0\n",
            "9     [2024-10]            1           20           1.0\n",
            "10    [2024-11]            1           20           1.0\n",
            "11    [2024-12]            1           20           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           40           1.0\n",
            "1     [2024-02]            1           40           1.0\n",
            "2     [2024-03]            1           40           1.0\n",
            "3     [2024-04]            1           40           1.0\n",
            "4     [2024-05]            1           40           1.0\n",
            "5     [2024-06]            1           40           1.0\n",
            "6     [2024-07]            1           40           1.0\n",
            "7     [2024-08]            1           40           1.0\n",
            "8     [2024-09]            1           40           1.0\n",
            "9     [2024-10]            1           40           1.0\n",
            "10    [2024-11]            1           40           1.0\n",
            "11    [2024-12]            1           40           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           60           1.0\n",
            "1     [2024-02]            1           60           1.0\n",
            "2     [2024-03]            1           60           1.0\n",
            "3     [2024-04]            1           60           1.0\n",
            "4     [2024-05]            1           60           1.0\n",
            "5     [2024-06]            1           60           1.0\n",
            "6     [2024-07]            1           60           1.0\n",
            "7     [2024-08]            1           60           1.0\n",
            "8     [2024-09]            1           60           1.0\n",
            "9     [2024-10]            1           60           1.0\n",
            "10    [2024-11]            1           60           1.0\n",
            "11    [2024-12]            1           60           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           80           1.0\n",
            "1     [2024-02]            1           80           1.0\n",
            "2     [2024-03]            1           80           1.0\n",
            "3     [2024-04]            1           80           1.0\n",
            "4     [2024-05]            1           80           1.0\n",
            "5     [2024-06]            1           80           1.0\n",
            "6     [2024-07]            1           80           1.0\n",
            "7     [2024-08]            1           80           1.0\n",
            "8     [2024-09]            1           80           1.0\n",
            "9     [2024-10]            1           80           1.0\n",
            "10    [2024-11]            1           80           1.0\n",
            "11    [2024-12]            1           80           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1          100           1.0\n",
            "1     [2024-02]            1          100           1.0\n",
            "2     [2024-03]            1          100           1.0\n",
            "3     [2024-04]            1          100           1.0\n",
            "4     [2024-05]            1          100           1.0\n",
            "5     [2024-06]            1          100           1.0\n",
            "6     [2024-07]            1          100           1.0\n",
            "7     [2024-08]            1          100           1.0\n",
            "8     [2024-09]            1          100           1.0\n",
            "9     [2024-10]            1          100           1.0\n",
            "10    [2024-11]            1          100           1.0\n",
            "11    [2024-12]            1          100           1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS1, 2 mesi di dati"
      ],
      "metadata": {
        "id": "yqYDV4TLCkRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS1_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_20[features])\n",
        "  T_val = scaler_T.transform(df_DS1_20[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS1_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS1_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_40[features])\n",
        "  T_val = scaler_T.transform(df_DS1_40[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS1_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS1_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_60[features])\n",
        "  T_val = scaler_T.transform(df_DS1_60[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS1_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS1_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_80[features])\n",
        "  T_val = scaler_T.transform(df_DS1_80[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS1_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS1_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_100[features])\n",
        "  T_val = scaler_T.transform(df_DS1_100[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS1_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS1_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISVazQ1eG591",
        "outputId": "11e38851-c87a-49ec-85b0-b5ff0b295be8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           20           1.0\n",
            "1   [2024-02, 2024-03]            2           20           1.0\n",
            "2   [2024-03, 2024-04]            2           20           1.0\n",
            "3   [2024-04, 2024-05]            2           20           1.0\n",
            "4   [2024-05, 2024-06]            2           20           1.0\n",
            "5   [2024-06, 2024-07]            2           20           1.0\n",
            "6   [2024-07, 2024-08]            2           20           1.0\n",
            "7   [2024-08, 2024-09]            2           20           1.0\n",
            "8   [2024-09, 2024-10]            2           20           1.0\n",
            "9   [2024-10, 2024-11]            2           20           1.0\n",
            "10  [2024-11, 2024-12]            2           20           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           40           1.0\n",
            "1   [2024-02, 2024-03]            2           40           1.0\n",
            "2   [2024-03, 2024-04]            2           40           1.0\n",
            "3   [2024-04, 2024-05]            2           40           1.0\n",
            "4   [2024-05, 2024-06]            2           40           1.0\n",
            "5   [2024-06, 2024-07]            2           40           1.0\n",
            "6   [2024-07, 2024-08]            2           40           1.0\n",
            "7   [2024-08, 2024-09]            2           40           1.0\n",
            "8   [2024-09, 2024-10]            2           40           1.0\n",
            "9   [2024-10, 2024-11]            2           40           1.0\n",
            "10  [2024-11, 2024-12]            2           40           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           60           1.0\n",
            "1   [2024-02, 2024-03]            2           60           1.0\n",
            "2   [2024-03, 2024-04]            2           60           1.0\n",
            "3   [2024-04, 2024-05]            2           60           1.0\n",
            "4   [2024-05, 2024-06]            2           60           1.0\n",
            "5   [2024-06, 2024-07]            2           60           1.0\n",
            "6   [2024-07, 2024-08]            2           60           1.0\n",
            "7   [2024-08, 2024-09]            2           60           1.0\n",
            "8   [2024-09, 2024-10]            2           60           1.0\n",
            "9   [2024-10, 2024-11]            2           60           1.0\n",
            "10  [2024-11, 2024-12]            2           60           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           80           1.0\n",
            "1   [2024-02, 2024-03]            2           80           1.0\n",
            "2   [2024-03, 2024-04]            2           80           1.0\n",
            "3   [2024-04, 2024-05]            2           80           1.0\n",
            "4   [2024-05, 2024-06]            2           80           1.0\n",
            "5   [2024-06, 2024-07]            2           80           1.0\n",
            "6   [2024-07, 2024-08]            2           80           1.0\n",
            "7   [2024-08, 2024-09]            2           80           1.0\n",
            "8   [2024-09, 2024-10]            2           80           1.0\n",
            "9   [2024-10, 2024-11]            2           80           1.0\n",
            "10  [2024-11, 2024-12]            2           80           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2          100           1.0\n",
            "1   [2024-02, 2024-03]            2          100           1.0\n",
            "2   [2024-03, 2024-04]            2          100           1.0\n",
            "3   [2024-04, 2024-05]            2          100           1.0\n",
            "4   [2024-05, 2024-06]            2          100           1.0\n",
            "5   [2024-06, 2024-07]            2          100           1.0\n",
            "6   [2024-07, 2024-08]            2          100           1.0\n",
            "7   [2024-08, 2024-09]            2          100           1.0\n",
            "8   [2024-09, 2024-10]            2          100           1.0\n",
            "9   [2024-10, 2024-11]            2          100           1.0\n",
            "10  [2024-11, 2024-12]            2          100           1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS1, 4 mesi di dati"
      ],
      "metadata": {
        "id": "QxROD8jiCkfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS1_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_20[features])\n",
        "  T_val = scaler_T.transform(df_DS1_20[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS1_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS1_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_40[features])\n",
        "  T_val = scaler_T.transform(df_DS1_40[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS1_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS1_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_60[features])\n",
        "  T_val = scaler_T.transform(df_DS1_60[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS1_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS1_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_80[features])\n",
        "  T_val = scaler_T.transform(df_DS1_80[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS1_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS1_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_100[features])\n",
        "  T_val = scaler_T.transform(df_DS1_100[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS1_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS1_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwxL5B1_HP5F",
        "outputId": "82daeb41-9bf6-420d-99a6-30e4ec7e5649"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           20   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           20   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           20   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           20   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           20   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           20   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           20   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           20   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           20   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           40   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           40   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           40   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           40   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           40   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           40   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           40   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           40   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           40   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           60   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           60   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           60   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           60   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           60   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           60   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           60   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           60   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           60   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           80   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           80   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           80   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           80   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           80   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           80   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           80   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           80   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           80   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4          100   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4          100   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4          100   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4          100   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4          100   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4          100   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4          100   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4          100   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4          100   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS1, 6 mesi di dati"
      ],
      "metadata": {
        "id": "1poT0XLVCkn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS1_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_20[features])\n",
        "  T_val = scaler_T.transform(df_DS1_20[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS1_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS1_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_40[features])\n",
        "  T_val = scaler_T.transform(df_DS1_40[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS1_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS1_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_60[features])\n",
        "  T_val = scaler_T.transform(df_DS1_60[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS1_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS1_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_80[features])\n",
        "  T_val = scaler_T.transform(df_DS1_80[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS1_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS1_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_100[features])\n",
        "  T_val = scaler_T.transform(df_DS1_100[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS1_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS1_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUm1WfcfHlbD",
        "outputId": "adcead19-326f-4c6d-b662-c9fef8708588"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           20           1.0  \n",
            "1           20           1.0  \n",
            "2           20           1.0  \n",
            "3           20           1.0  \n",
            "4           20           1.0  \n",
            "5           20           1.0  \n",
            "6           20           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           40           1.0  \n",
            "1           40           1.0  \n",
            "2           40           1.0  \n",
            "3           40           1.0  \n",
            "4           40           1.0  \n",
            "5           40           1.0  \n",
            "6           40           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           60           1.0  \n",
            "1           60           1.0  \n",
            "2           60           1.0  \n",
            "3           60           1.0  \n",
            "4           60           1.0  \n",
            "5           60           1.0  \n",
            "6           60           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           80           1.0  \n",
            "1           80           1.0  \n",
            "2           80           1.0  \n",
            "3           80           1.0  \n",
            "4           80           1.0  \n",
            "5           80           1.0  \n",
            "6           80           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0          100           1.0  \n",
            "1          100           1.0  \n",
            "2          100           1.0  \n",
            "3          100           1.0  \n",
            "4          100           1.0  \n",
            "5          100           1.0  \n",
            "6          100           1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS2, 1 mese di dati"
      ],
      "metadata": {
        "id": "UHChqtqiCkww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS2_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_20[features])\n",
        "  T_val = scaler_T.transform(df_DS2_20[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS2_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS2_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_40[features])\n",
        "  T_val = scaler_T.transform(df_DS2_40[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS2_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS2_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_60[features])\n",
        "  T_val = scaler_T.transform(df_DS2_60[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS2_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS2_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_80[features])\n",
        "  T_val = scaler_T.transform(df_DS2_80[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS2_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS2_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_100[features])\n",
        "  T_val = scaler_T.transform(df_DS2_100[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS2_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS2_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuT3fHIVH6DZ",
        "outputId": "ad4e52a0-388b-481c-e952-2a0ebaf5a0f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           20           1.0\n",
            "1     [2024-02]            1           20           1.0\n",
            "2     [2024-03]            1           20           1.0\n",
            "3     [2024-04]            1           20           1.0\n",
            "4     [2024-05]            1           20           1.0\n",
            "5     [2024-06]            1           20           1.0\n",
            "6     [2024-07]            1           20           1.0\n",
            "7     [2024-08]            1           20           1.0\n",
            "8     [2024-09]            1           20           1.0\n",
            "9     [2024-10]            1           20           1.0\n",
            "10    [2024-11]            1           20           1.0\n",
            "11    [2024-12]            1           20           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           40           1.0\n",
            "1     [2024-02]            1           40           1.0\n",
            "2     [2024-03]            1           40           1.0\n",
            "3     [2024-04]            1           40           1.0\n",
            "4     [2024-05]            1           40           1.0\n",
            "5     [2024-06]            1           40           1.0\n",
            "6     [2024-07]            1           40           1.0\n",
            "7     [2024-08]            1           40           1.0\n",
            "8     [2024-09]            1           40           1.0\n",
            "9     [2024-10]            1           40           1.0\n",
            "10    [2024-11]            1           40           1.0\n",
            "11    [2024-12]            1           40           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           60           1.0\n",
            "1     [2024-02]            1           60           1.0\n",
            "2     [2024-03]            1           60           1.0\n",
            "3     [2024-04]            1           60           1.0\n",
            "4     [2024-05]            1           60           1.0\n",
            "5     [2024-06]            1           60           1.0\n",
            "6     [2024-07]            1           60           1.0\n",
            "7     [2024-08]            1           60           1.0\n",
            "8     [2024-09]            1           60           1.0\n",
            "9     [2024-10]            1           60           1.0\n",
            "10    [2024-11]            1           60           1.0\n",
            "11    [2024-12]            1           60           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           80           1.0\n",
            "1     [2024-02]            1           80           1.0\n",
            "2     [2024-03]            1           80           1.0\n",
            "3     [2024-04]            1           80           1.0\n",
            "4     [2024-05]            1           80           1.0\n",
            "5     [2024-06]            1           80           1.0\n",
            "6     [2024-07]            1           80           1.0\n",
            "7     [2024-08]            1           80           1.0\n",
            "8     [2024-09]            1           80           1.0\n",
            "9     [2024-10]            1           80           1.0\n",
            "10    [2024-11]            1           80           1.0\n",
            "11    [2024-12]            1           80           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1          100           1.0\n",
            "1     [2024-02]            1          100           1.0\n",
            "2     [2024-03]            1          100           1.0\n",
            "3     [2024-04]            1          100           1.0\n",
            "4     [2024-05]            1          100           1.0\n",
            "5     [2024-06]            1          100           1.0\n",
            "6     [2024-07]            1          100           1.0\n",
            "7     [2024-08]            1          100           1.0\n",
            "8     [2024-09]            1          100           1.0\n",
            "9     [2024-10]            1          100           1.0\n",
            "10    [2024-11]            1          100           1.0\n",
            "11    [2024-12]            1          100           1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS2, 2 mesi di dati"
      ],
      "metadata": {
        "id": "hCdogx_gCk3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS2_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_20[features])\n",
        "  T_val = scaler_T.transform(df_DS2_20[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS2_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS2_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_40[features])\n",
        "  T_val = scaler_T.transform(df_DS2_40[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS2_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS2_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_60[features])\n",
        "  T_val = scaler_T.transform(df_DS2_60[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS2_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS2_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_80[features])\n",
        "  T_val = scaler_T.transform(df_DS2_80[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS2_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS2_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_100[features])\n",
        "  T_val = scaler_T.transform(df_DS2_100[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS2_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS2_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMfPDxyzIZyx",
        "outputId": "67ad821f-11cf-406f-bb19-1d7107772867"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           20           1.0\n",
            "1   [2024-02, 2024-03]            2           20           1.0\n",
            "2   [2024-03, 2024-04]            2           20           1.0\n",
            "3   [2024-04, 2024-05]            2           20           1.0\n",
            "4   [2024-05, 2024-06]            2           20           1.0\n",
            "5   [2024-06, 2024-07]            2           20           1.0\n",
            "6   [2024-07, 2024-08]            2           20           1.0\n",
            "7   [2024-08, 2024-09]            2           20           1.0\n",
            "8   [2024-09, 2024-10]            2           20           1.0\n",
            "9   [2024-10, 2024-11]            2           20           1.0\n",
            "10  [2024-11, 2024-12]            2           20           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           40           1.0\n",
            "1   [2024-02, 2024-03]            2           40           1.0\n",
            "2   [2024-03, 2024-04]            2           40           1.0\n",
            "3   [2024-04, 2024-05]            2           40           1.0\n",
            "4   [2024-05, 2024-06]            2           40           1.0\n",
            "5   [2024-06, 2024-07]            2           40           1.0\n",
            "6   [2024-07, 2024-08]            2           40           1.0\n",
            "7   [2024-08, 2024-09]            2           40           1.0\n",
            "8   [2024-09, 2024-10]            2           40           1.0\n",
            "9   [2024-10, 2024-11]            2           40           1.0\n",
            "10  [2024-11, 2024-12]            2           40           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           60           1.0\n",
            "1   [2024-02, 2024-03]            2           60           1.0\n",
            "2   [2024-03, 2024-04]            2           60           1.0\n",
            "3   [2024-04, 2024-05]            2           60           1.0\n",
            "4   [2024-05, 2024-06]            2           60           1.0\n",
            "5   [2024-06, 2024-07]            2           60           1.0\n",
            "6   [2024-07, 2024-08]            2           60           1.0\n",
            "7   [2024-08, 2024-09]            2           60           1.0\n",
            "8   [2024-09, 2024-10]            2           60           1.0\n",
            "9   [2024-10, 2024-11]            2           60           1.0\n",
            "10  [2024-11, 2024-12]            2           60           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           80           1.0\n",
            "1   [2024-02, 2024-03]            2           80           1.0\n",
            "2   [2024-03, 2024-04]            2           80           1.0\n",
            "3   [2024-04, 2024-05]            2           80           1.0\n",
            "4   [2024-05, 2024-06]            2           80           1.0\n",
            "5   [2024-06, 2024-07]            2           80           1.0\n",
            "6   [2024-07, 2024-08]            2           80           1.0\n",
            "7   [2024-08, 2024-09]            2           80           1.0\n",
            "8   [2024-09, 2024-10]            2           80           1.0\n",
            "9   [2024-10, 2024-11]            2           80           1.0\n",
            "10  [2024-11, 2024-12]            2           80           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2          100           1.0\n",
            "1   [2024-02, 2024-03]            2          100           1.0\n",
            "2   [2024-03, 2024-04]            2          100           1.0\n",
            "3   [2024-04, 2024-05]            2          100           1.0\n",
            "4   [2024-05, 2024-06]            2          100           1.0\n",
            "5   [2024-06, 2024-07]            2          100           1.0\n",
            "6   [2024-07, 2024-08]            2          100           1.0\n",
            "7   [2024-08, 2024-09]            2          100           1.0\n",
            "8   [2024-09, 2024-10]            2          100           1.0\n",
            "9   [2024-10, 2024-11]            2          100           1.0\n",
            "10  [2024-11, 2024-12]            2          100           1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS2, 4 mesi di dati"
      ],
      "metadata": {
        "id": "IsartAGzCk86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS2_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_20[features])\n",
        "  T_val = scaler_T.transform(df_DS2_20[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS2_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS2_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_40[features])\n",
        "  T_val = scaler_T.transform(df_DS2_40[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS2_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS2_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_60[features])\n",
        "  T_val = scaler_T.transform(df_DS2_60[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS2_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS2_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_80[features])\n",
        "  T_val = scaler_T.transform(df_DS2_80[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS2_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS2_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_100[features])\n",
        "  T_val = scaler_T.transform(df_DS2_100[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS2_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS2_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_pJ-M2vIuwF",
        "outputId": "fbf0998c-c80c-46e7-9f0b-0f986c433935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           20   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           20   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           20   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           20   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           20   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           20   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           20   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           20   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           20   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           40   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           40   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           40   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           40   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           40   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           40   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           40   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           40   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           40   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           60   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           60   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           60   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           60   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           60   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           60   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           60   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           60   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           60   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           80   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           80   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           80   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           80   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           80   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           80   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           80   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           80   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           80   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4          100   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4          100   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4          100   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4          100   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4          100   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4          100   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4          100   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4          100   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4          100   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS2, 6 mesi di dati"
      ],
      "metadata": {
        "id": "GoLvrhL2ClC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS2_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_20[features])\n",
        "  T_val = scaler_T.transform(df_DS2_20[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS2_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS2_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_40[features])\n",
        "  T_val = scaler_T.transform(df_DS2_40[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS2_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS2_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_60[features])\n",
        "  T_val = scaler_T.transform(df_DS2_60[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS2_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS2_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_80[features])\n",
        "  T_val = scaler_T.transform(df_DS2_80[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS2_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS2_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_100[features])\n",
        "  T_val = scaler_T.transform(df_DS2_100[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS2_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS2_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3y3WgV5QJI__",
        "outputId": "28cfb739-7c81-4f07-de96-f3c2f6fc306a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           20           1.0  \n",
            "1           20           1.0  \n",
            "2           20           1.0  \n",
            "3           20           1.0  \n",
            "4           20           1.0  \n",
            "5           20           1.0  \n",
            "6           20           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           40           1.0  \n",
            "1           40           1.0  \n",
            "2           40           1.0  \n",
            "3           40           1.0  \n",
            "4           40           1.0  \n",
            "5           40           1.0  \n",
            "6           40           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           60           1.0  \n",
            "1           60           1.0  \n",
            "2           60           1.0  \n",
            "3           60           1.0  \n",
            "4           60           1.0  \n",
            "5           60           1.0  \n",
            "6           60           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           80           1.0  \n",
            "1           80           1.0  \n",
            "2           80           1.0  \n",
            "3           80           1.0  \n",
            "4           80           1.0  \n",
            "5           80           1.0  \n",
            "6           80           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0          100           1.0  \n",
            "1          100           1.0  \n",
            "2          100           1.0  \n",
            "3          100           1.0  \n",
            "4          100           1.0  \n",
            "5          100           1.0  \n",
            "6          100           1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS3, 1 mese di dati"
      ],
      "metadata": {
        "id": "qvC97dLMClI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS3_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_20[features])\n",
        "  T_val = scaler_T.transform(df_DS3_20[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS3_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS3_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_40[features])\n",
        "  T_val = scaler_T.transform(df_DS3_40[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS3_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS3_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_60[features])\n",
        "  T_val = scaler_T.transform(df_DS3_60[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS3_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS3_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_80[features])\n",
        "  T_val = scaler_T.transform(df_DS3_80[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS3_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS3_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_100[features])\n",
        "  T_val = scaler_T.transform(df_DS3_100[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS3_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS3_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOKl52vrJYNn",
        "outputId": "20a33418-e015-4257-f4f2-50b23c90213e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           20           1.0\n",
            "1     [2024-02]            1           20           1.0\n",
            "2     [2024-03]            1           20           1.0\n",
            "3     [2024-04]            1           20           1.0\n",
            "4     [2024-05]            1           20           1.0\n",
            "5     [2024-06]            1           20           1.0\n",
            "6     [2024-07]            1           20           1.0\n",
            "7     [2024-08]            1           20           1.0\n",
            "8     [2024-09]            1           20           1.0\n",
            "9     [2024-10]            1           20           1.0\n",
            "10    [2024-11]            1           20           1.0\n",
            "11    [2024-12]            1           20           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           40           1.0\n",
            "1     [2024-02]            1           40           1.0\n",
            "2     [2024-03]            1           40           1.0\n",
            "3     [2024-04]            1           40           1.0\n",
            "4     [2024-05]            1           40           1.0\n",
            "5     [2024-06]            1           40           1.0\n",
            "6     [2024-07]            1           40           1.0\n",
            "7     [2024-08]            1           40           1.0\n",
            "8     [2024-09]            1           40           1.0\n",
            "9     [2024-10]            1           40           1.0\n",
            "10    [2024-11]            1           40           1.0\n",
            "11    [2024-12]            1           40           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           60           1.0\n",
            "1     [2024-02]            1           60           1.0\n",
            "2     [2024-03]            1           60           1.0\n",
            "3     [2024-04]            1           60           1.0\n",
            "4     [2024-05]            1           60           1.0\n",
            "5     [2024-06]            1           60           1.0\n",
            "6     [2024-07]            1           60           1.0\n",
            "7     [2024-08]            1           60           1.0\n",
            "8     [2024-09]            1           60           1.0\n",
            "9     [2024-10]            1           60           1.0\n",
            "10    [2024-11]            1           60           1.0\n",
            "11    [2024-12]            1           60           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           80           1.0\n",
            "1     [2024-02]            1           80           1.0\n",
            "2     [2024-03]            1           80           1.0\n",
            "3     [2024-04]            1           80           1.0\n",
            "4     [2024-05]            1           80           1.0\n",
            "5     [2024-06]            1           80           1.0\n",
            "6     [2024-07]            1           80           1.0\n",
            "7     [2024-08]            1           80           1.0\n",
            "8     [2024-09]            1           80           1.0\n",
            "9     [2024-10]            1           80           1.0\n",
            "10    [2024-11]            1           80           1.0\n",
            "11    [2024-12]            1           80           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1          100           1.0\n",
            "1     [2024-02]            1          100           1.0\n",
            "2     [2024-03]            1          100           1.0\n",
            "3     [2024-04]            1          100           1.0\n",
            "4     [2024-05]            1          100           1.0\n",
            "5     [2024-06]            1          100           1.0\n",
            "6     [2024-07]            1          100           1.0\n",
            "7     [2024-08]            1          100           1.0\n",
            "8     [2024-09]            1          100           1.0\n",
            "9     [2024-10]            1          100           1.0\n",
            "10    [2024-11]            1          100           1.0\n",
            "11    [2024-12]            1          100           1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS3, 2 mesi di dati"
      ],
      "metadata": {
        "id": "il0fhuhNClN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS3_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_20[features])\n",
        "  T_val = scaler_T.transform(df_DS3_20[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS3_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS3_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_40[features])\n",
        "  T_val = scaler_T.transform(df_DS3_40[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS3_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS3_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_60[features])\n",
        "  T_val = scaler_T.transform(df_DS3_60[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS3_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS3_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_80[features])\n",
        "  T_val = scaler_T.transform(df_DS3_80[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS3_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS3_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_100[features])\n",
        "  T_val = scaler_T.transform(df_DS3_100[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS3_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS3_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqyCUqFvJ6A5",
        "outputId": "0bfd2e9d-4f5a-4475-e888-3f2c628e61cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           20           1.0\n",
            "1   [2024-02, 2024-03]            2           20           1.0\n",
            "2   [2024-03, 2024-04]            2           20           1.0\n",
            "3   [2024-04, 2024-05]            2           20           1.0\n",
            "4   [2024-05, 2024-06]            2           20           1.0\n",
            "5   [2024-06, 2024-07]            2           20           1.0\n",
            "6   [2024-07, 2024-08]            2           20           1.0\n",
            "7   [2024-08, 2024-09]            2           20           1.0\n",
            "8   [2024-09, 2024-10]            2           20           1.0\n",
            "9   [2024-10, 2024-11]            2           20           1.0\n",
            "10  [2024-11, 2024-12]            2           20           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           40           1.0\n",
            "1   [2024-02, 2024-03]            2           40           1.0\n",
            "2   [2024-03, 2024-04]            2           40           1.0\n",
            "3   [2024-04, 2024-05]            2           40           1.0\n",
            "4   [2024-05, 2024-06]            2           40           1.0\n",
            "5   [2024-06, 2024-07]            2           40           1.0\n",
            "6   [2024-07, 2024-08]            2           40           1.0\n",
            "7   [2024-08, 2024-09]            2           40           1.0\n",
            "8   [2024-09, 2024-10]            2           40           1.0\n",
            "9   [2024-10, 2024-11]            2           40           1.0\n",
            "10  [2024-11, 2024-12]            2           40           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           60           1.0\n",
            "1   [2024-02, 2024-03]            2           60           1.0\n",
            "2   [2024-03, 2024-04]            2           60           1.0\n",
            "3   [2024-04, 2024-05]            2           60           1.0\n",
            "4   [2024-05, 2024-06]            2           60           1.0\n",
            "5   [2024-06, 2024-07]            2           60           1.0\n",
            "6   [2024-07, 2024-08]            2           60           1.0\n",
            "7   [2024-08, 2024-09]            2           60           1.0\n",
            "8   [2024-09, 2024-10]            2           60           1.0\n",
            "9   [2024-10, 2024-11]            2           60           1.0\n",
            "10  [2024-11, 2024-12]            2           60           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           80           1.0\n",
            "1   [2024-02, 2024-03]            2           80           1.0\n",
            "2   [2024-03, 2024-04]            2           80           1.0\n",
            "3   [2024-04, 2024-05]            2           80           1.0\n",
            "4   [2024-05, 2024-06]            2           80           1.0\n",
            "5   [2024-06, 2024-07]            2           80           1.0\n",
            "6   [2024-07, 2024-08]            2           80           1.0\n",
            "7   [2024-08, 2024-09]            2           80           1.0\n",
            "8   [2024-09, 2024-10]            2           80           1.0\n",
            "9   [2024-10, 2024-11]            2           80           1.0\n",
            "10  [2024-11, 2024-12]            2           80           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2          100           1.0\n",
            "1   [2024-02, 2024-03]            2          100           1.0\n",
            "2   [2024-03, 2024-04]            2          100           1.0\n",
            "3   [2024-04, 2024-05]            2          100           1.0\n",
            "4   [2024-05, 2024-06]            2          100           1.0\n",
            "5   [2024-06, 2024-07]            2          100           1.0\n",
            "6   [2024-07, 2024-08]            2          100           1.0\n",
            "7   [2024-08, 2024-09]            2          100           1.0\n",
            "8   [2024-09, 2024-10]            2          100           1.0\n",
            "9   [2024-10, 2024-11]            2          100           1.0\n",
            "10  [2024-11, 2024-12]            2          100           1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS3, 4 mesi di dati"
      ],
      "metadata": {
        "id": "ggn20BJ0ClTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS3_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_20[features])\n",
        "  T_val = scaler_T.transform(df_DS3_20[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS3_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS3_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_40[features])\n",
        "  T_val = scaler_T.transform(df_DS3_40[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS3_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS3_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_60[features])\n",
        "  T_val = scaler_T.transform(df_DS3_60[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS3_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS3_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_80[features])\n",
        "  T_val = scaler_T.transform(df_DS3_80[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS3_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS3_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_100[features])\n",
        "  T_val = scaler_T.transform(df_DS3_100[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS3_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS3_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbCnFvSuKSLp",
        "outputId": "e4179eff-d6cf-4603-be24-46a95b0399ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           20   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           20   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           20   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           20   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           20   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           20   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           20   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           20   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           20   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           40   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           40   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           40   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           40   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           40   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           40   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           40   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           40   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           40   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           60   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           60   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           60   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           60   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           60   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           60   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           60   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           60   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           60   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           80   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           80   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           80   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           80   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           80   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           80   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           80   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           80   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           80   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4          100   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4          100   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4          100   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4          100   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4          100   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4          100   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4          100   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4          100   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4          100   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS3, 6 mesi di dati"
      ],
      "metadata": {
        "id": "l-1KVCntClXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS3_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_20[features])\n",
        "  T_val = scaler_T.transform(df_DS3_20[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS3_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS3_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_40[features])\n",
        "  T_val = scaler_T.transform(df_DS3_40[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS3_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS3_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_60[features])\n",
        "  T_val = scaler_T.transform(df_DS3_60[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS3_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS3_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_80[features])\n",
        "  T_val = scaler_T.transform(df_DS3_80[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS3_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS3_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_100[features])\n",
        "  T_val = scaler_T.transform(df_DS3_100[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS3_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS3_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8Usf1xYK14I",
        "outputId": "c2541061-7d3f-42d7-af25-d7be6612f660"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           20           1.0  \n",
            "1           20           1.0  \n",
            "2           20           1.0  \n",
            "3           20           1.0  \n",
            "4           20           1.0  \n",
            "5           20           1.0  \n",
            "6           20           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           40           1.0  \n",
            "1           40           1.0  \n",
            "2           40           1.0  \n",
            "3           40           1.0  \n",
            "4           40           1.0  \n",
            "5           40           1.0  \n",
            "6           40           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           60           1.0  \n",
            "1           60           1.0  \n",
            "2           60           1.0  \n",
            "3           60           1.0  \n",
            "4           60           1.0  \n",
            "5           60           1.0  \n",
            "6           60           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           80           1.0  \n",
            "1           80           1.0  \n",
            "2           80           1.0  \n",
            "3           80           1.0  \n",
            "4           80           1.0  \n",
            "5           80           1.0  \n",
            "6           80           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0          100           1.0  \n",
            "1          100           1.0  \n",
            "2          100           1.0  \n",
            "3          100           1.0  \n",
            "4          100           1.0  \n",
            "5          100           1.0  \n",
            "6          100           1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS4, 1 mesi di dati"
      ],
      "metadata": {
        "id": "DxATTUKSClcz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS4_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_20[features])\n",
        "  T_val = scaler_T.transform(df_DS4_20[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS4_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS4_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_40[features])\n",
        "  T_val = scaler_T.transform(df_DS4_40[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS4_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS4_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_60[features])\n",
        "  T_val = scaler_T.transform(df_DS4_60[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS4_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS4_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_80[features])\n",
        "  T_val = scaler_T.transform(df_DS4_80[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS4_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS4_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_100[features])\n",
        "  T_val = scaler_T.transform(df_DS4_100[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS4_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS4_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYdSxkV-LGyi",
        "outputId": "8f91f7dd-6677-4e27-cfde-6f4a0c768d1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           20           1.0\n",
            "1     [2024-02]            1           20           1.0\n",
            "2     [2024-03]            1           20           1.0\n",
            "3     [2024-04]            1           20           1.0\n",
            "4     [2024-05]            1           20           1.0\n",
            "5     [2024-06]            1           20           1.0\n",
            "6     [2024-07]            1           20           1.0\n",
            "7     [2024-08]            1           20           1.0\n",
            "8     [2024-09]            1           20           1.0\n",
            "9     [2024-10]            1           20           1.0\n",
            "10    [2024-11]            1           20           1.0\n",
            "11    [2024-12]            1           20           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           40           1.0\n",
            "1     [2024-02]            1           40           1.0\n",
            "2     [2024-03]            1           40           1.0\n",
            "3     [2024-04]            1           40           1.0\n",
            "4     [2024-05]            1           40           1.0\n",
            "5     [2024-06]            1           40           1.0\n",
            "6     [2024-07]            1           40           1.0\n",
            "7     [2024-08]            1           40           1.0\n",
            "8     [2024-09]            1           40           1.0\n",
            "9     [2024-10]            1           40           1.0\n",
            "10    [2024-11]            1           40           1.0\n",
            "11    [2024-12]            1           40           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           60           1.0\n",
            "1     [2024-02]            1           60           1.0\n",
            "2     [2024-03]            1           60           1.0\n",
            "3     [2024-04]            1           60           1.0\n",
            "4     [2024-05]            1           60           1.0\n",
            "5     [2024-06]            1           60           1.0\n",
            "6     [2024-07]            1           60           1.0\n",
            "7     [2024-08]            1           60           1.0\n",
            "8     [2024-09]            1           60           1.0\n",
            "9     [2024-10]            1           60           1.0\n",
            "10    [2024-11]            1           60           1.0\n",
            "11    [2024-12]            1           60           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           80           1.0\n",
            "1     [2024-02]            1           80           1.0\n",
            "2     [2024-03]            1           80           1.0\n",
            "3     [2024-04]            1           80           1.0\n",
            "4     [2024-05]            1           80           1.0\n",
            "5     [2024-06]            1           80           1.0\n",
            "6     [2024-07]            1           80           1.0\n",
            "7     [2024-08]            1           80           1.0\n",
            "8     [2024-09]            1           80           1.0\n",
            "9     [2024-10]            1           80           1.0\n",
            "10    [2024-11]            1           80           1.0\n",
            "11    [2024-12]            1           80           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1          100           1.0\n",
            "1     [2024-02]            1          100           1.0\n",
            "2     [2024-03]            1          100           1.0\n",
            "3     [2024-04]            1          100           1.0\n",
            "4     [2024-05]            1          100           1.0\n",
            "5     [2024-06]            1          100           1.0\n",
            "6     [2024-07]            1          100           1.0\n",
            "7     [2024-08]            1          100           1.0\n",
            "8     [2024-09]            1          100           1.0\n",
            "9     [2024-10]            1          100           1.0\n",
            "10    [2024-11]            1          100           1.0\n",
            "11    [2024-12]            1          100           1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS4, 2 mesi di dati"
      ],
      "metadata": {
        "id": "tamHY1eQClhd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS4_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_20[features])\n",
        "  T_val = scaler_T.transform(df_DS4_20[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS4_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS4_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_40[features])\n",
        "  T_val = scaler_T.transform(df_DS4_40[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS4_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS4_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_60[features])\n",
        "  T_val = scaler_T.transform(df_DS4_60[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS4_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS4_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_80[features])\n",
        "  T_val = scaler_T.transform(df_DS4_80[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS4_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS4_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_100[features])\n",
        "  T_val = scaler_T.transform(df_DS4_100[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS4_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS4_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLxBCgFmLlov",
        "outputId": "5c9b50bc-5fea-43e4-e629-9dfeed7fc78c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           20           1.0\n",
            "1   [2024-02, 2024-03]            2           20           1.0\n",
            "2   [2024-03, 2024-04]            2           20           1.0\n",
            "3   [2024-04, 2024-05]            2           20           1.0\n",
            "4   [2024-05, 2024-06]            2           20           1.0\n",
            "5   [2024-06, 2024-07]            2           20           1.0\n",
            "6   [2024-07, 2024-08]            2           20           1.0\n",
            "7   [2024-08, 2024-09]            2           20           1.0\n",
            "8   [2024-09, 2024-10]            2           20           1.0\n",
            "9   [2024-10, 2024-11]            2           20           1.0\n",
            "10  [2024-11, 2024-12]            2           20           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           40           1.0\n",
            "1   [2024-02, 2024-03]            2           40           1.0\n",
            "2   [2024-03, 2024-04]            2           40           1.0\n",
            "3   [2024-04, 2024-05]            2           40           1.0\n",
            "4   [2024-05, 2024-06]            2           40           1.0\n",
            "5   [2024-06, 2024-07]            2           40           1.0\n",
            "6   [2024-07, 2024-08]            2           40           1.0\n",
            "7   [2024-08, 2024-09]            2           40           1.0\n",
            "8   [2024-09, 2024-10]            2           40           1.0\n",
            "9   [2024-10, 2024-11]            2           40           1.0\n",
            "10  [2024-11, 2024-12]            2           40           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           60           1.0\n",
            "1   [2024-02, 2024-03]            2           60           1.0\n",
            "2   [2024-03, 2024-04]            2           60           1.0\n",
            "3   [2024-04, 2024-05]            2           60           1.0\n",
            "4   [2024-05, 2024-06]            2           60           1.0\n",
            "5   [2024-06, 2024-07]            2           60           1.0\n",
            "6   [2024-07, 2024-08]            2           60           1.0\n",
            "7   [2024-08, 2024-09]            2           60           1.0\n",
            "8   [2024-09, 2024-10]            2           60           1.0\n",
            "9   [2024-10, 2024-11]            2           60           1.0\n",
            "10  [2024-11, 2024-12]            2           60           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           80           1.0\n",
            "1   [2024-02, 2024-03]            2           80           1.0\n",
            "2   [2024-03, 2024-04]            2           80           1.0\n",
            "3   [2024-04, 2024-05]            2           80           1.0\n",
            "4   [2024-05, 2024-06]            2           80           1.0\n",
            "5   [2024-06, 2024-07]            2           80           1.0\n",
            "6   [2024-07, 2024-08]            2           80           1.0\n",
            "7   [2024-08, 2024-09]            2           80           1.0\n",
            "8   [2024-09, 2024-10]            2           80           1.0\n",
            "9   [2024-10, 2024-11]            2           80           1.0\n",
            "10  [2024-11, 2024-12]            2           80           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2          100           1.0\n",
            "1   [2024-02, 2024-03]            2          100           1.0\n",
            "2   [2024-03, 2024-04]            2          100           1.0\n",
            "3   [2024-04, 2024-05]            2          100           1.0\n",
            "4   [2024-05, 2024-06]            2          100           1.0\n",
            "5   [2024-06, 2024-07]            2          100           1.0\n",
            "6   [2024-07, 2024-08]            2          100           1.0\n",
            "7   [2024-08, 2024-09]            2          100           1.0\n",
            "8   [2024-09, 2024-10]            2          100           1.0\n",
            "9   [2024-10, 2024-11]            2          100           1.0\n",
            "10  [2024-11, 2024-12]            2          100           1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS4, 4 mesi di dati"
      ],
      "metadata": {
        "id": "M5RVjUf7ClmJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS4_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_20[features])\n",
        "  T_val = scaler_T.transform(df_DS4_20[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS4_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS4_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_40[features])\n",
        "  T_val = scaler_T.transform(df_DS4_40[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS4_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS4_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_60[features])\n",
        "  T_val = scaler_T.transform(df_DS4_60[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS4_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS4_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_80[features])\n",
        "  T_val = scaler_T.transform(df_DS4_80[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS4_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS4_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_100[features])\n",
        "  T_val = scaler_T.transform(df_DS4_100[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS4_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS4_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxrfkP2TL6g4",
        "outputId": "df9b18eb-a9fb-41c0-e1fd-6ac0edb2b76a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           20   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           20   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           20   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           20   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           20   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           20   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           20   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           20   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           20   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           40   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           40   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           40   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           40   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           40   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           40   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           40   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           40   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           40   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           60   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           60   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           60   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           60   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           60   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           60   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           60   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           60   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           60   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           80   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           80   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           80   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           80   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           80   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           80   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           80   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           80   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           80   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4          100   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4          100   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4          100   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4          100   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4          100   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4          100   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4          100   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4          100   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4          100   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS4, 6 mesi di dati"
      ],
      "metadata": {
        "id": "nNzk-IU2ClpT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS4_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_20[features])\n",
        "  T_val = scaler_T.transform(df_DS4_20[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS4_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS4_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_40[features])\n",
        "  T_val = scaler_T.transform(df_DS4_40[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS4_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS4_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_60[features])\n",
        "  T_val = scaler_T.transform(df_DS4_60[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS4_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS4_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_80[features])\n",
        "  T_val = scaler_T.transform(df_DS4_80[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS4_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS4_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "cond = [\"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "  scaler_T = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  T_train = scaler_T.fit_transform(train_data[cond])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_100[features])\n",
        "  T_val = scaler_T.transform(df_DS4_100[cond])\n",
        "\n",
        "  cvae_beta001 = CVAE_beta001(input_dim=X_train.shape[1], cond_dim=T_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  dummy_cond = tf.zeros((1, T_train.shape[1]))\n",
        "  _ = cvae_beta001(dummy_x, dummy_cond)\n",
        "\n",
        "  cvae_beta001.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  cvae_beta001.load_weights(f\"/content/drive/MyDrive/CVAE_beta_001_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = cvae_beta001.predict([X_train, T_train], verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = cvae_beta001.predict([X_val, T_val], verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS4_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS4_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OA8_V4lQMTWV",
        "outputId": "7777f9e0-5df8-4be7-ff1b-24530041eee5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           20           1.0  \n",
            "1           20           1.0  \n",
            "2           20           1.0  \n",
            "3           20           1.0  \n",
            "4           20           1.0  \n",
            "5           20           1.0  \n",
            "6           20           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           40           1.0  \n",
            "1           40           1.0  \n",
            "2           40           1.0  \n",
            "3           40           1.0  \n",
            "4           40           1.0  \n",
            "5           40           1.0  \n",
            "6           40           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           60           1.0  \n",
            "1           60           1.0  \n",
            "2           60           1.0  \n",
            "3           60           1.0  \n",
            "4           60           1.0  \n",
            "5           60           1.0  \n",
            "6           60           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           80           1.0  \n",
            "1           80           1.0  \n",
            "2           80           1.0  \n",
            "3           80           1.0  \n",
            "4           80           1.0  \n",
            "5           80           1.0  \n",
            "6           80           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0          100           1.0  \n",
            "1          100           1.0  \n",
            "2          100           1.0  \n",
            "3          100           1.0  \n",
            "4          100           1.0  \n",
            "5          100           1.0  \n",
            "6          100           1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VAE senza temperatura"
      ],
      "metadata": {
        "id": "Kd1vDDteSf4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"keras\")\n",
        "\n",
        "df_temp = pd.read_csv(\"/content/data_temperature.csv\", encoding = \"utf-8\")\n",
        "df_temp[\"timestamp\"] = pd.to_datetime(df_temp[\"timestamp\"])\n",
        "df_temp[\"timestamp\"] = df_temp[\"timestamp\"].dt.tz_localize(None)\n",
        "df_temp = df_temp.sort_values(\"timestamp\")\n",
        "\n",
        "end = \"2025-01-01\"\n",
        "new_df = df_temp[(df_temp[\"timestamp\"] < end)]\n",
        "\n",
        "\n",
        "\n",
        "class Sampling(Layer):\n",
        "  def call(self, inputs):\n",
        "    z_mean, z_log_var = inputs\n",
        "    epsilon = tf.random.normal(shape=tf.shape(z_mean))\n",
        "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "\n",
        "\n",
        "class VAE(keras.Model):\n",
        "  def __init__(self, input_dim, latent_dim = 2, beta = 0.01, **kwargs):\n",
        "    super(VAE, self).__init__(**kwargs)\n",
        "    self.beta = beta\n",
        "\n",
        "    #encoder\n",
        "    x_input = keras.Input(shape=(input_dim,))\n",
        "    x = layers.Dense(48, activation=\"relu\")(x_input)\n",
        "    x = layers.Dense(24, activation=\"relu\")(x)\n",
        "    x = layers.Dense(12, activation=\"relu\")(x)\n",
        "    z_mean = layers.Dense(latent_dim)(x)\n",
        "    z_log_var = layers.Dense(latent_dim)(x)\n",
        "\n",
        "    z = Sampling()([z_mean, z_log_var])\n",
        "    self.encoder = keras.Model(x_input, [z_mean, z_log_var, z])\n",
        "\n",
        "    #decoder\n",
        "    latent_inputs = keras.Input(shape=(latent_dim,))\n",
        "    x = layers.Dense(12, activation=\"relu\")(latent_inputs)\n",
        "    x = layers.Dense(24, activation=\"relu\")(x)\n",
        "    x = layers.Dense(48, activation=\"relu\")(x)\n",
        "    outputs = layers.Dense(input_dim, activation=\"linear\")(x)\n",
        "\n",
        "    self.decoder = keras.Model(latent_inputs, outputs)\n",
        "\n",
        "  def train_step(self, data):\n",
        "    x, y = data\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "      z_mean, z_log_var, z = self.encoder(x, training = True)\n",
        "      reconstruction = self.decoder(z, training = True)\n",
        "\n",
        "      reconstruction_loss = tf.reduce_mean(tf.square(x - reconstruction))\n",
        "      kl_loss = -0.5 * tf.reduce_mean(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
        "      total_loss = reconstruction_loss + self.beta * kl_loss\n",
        "\n",
        "    grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "    self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "\n",
        "    return {\"loss\": total_loss, \"recon_loss\": reconstruction_loss, \"kl_loss\": kl_loss}\n",
        "\n",
        "  def call(self, inputs):\n",
        "    z_mean, _,  z = self.encoder(inputs)\n",
        "    return self.decoder(z)"
      ],
      "metadata": {
        "id": "0LECjb4eSjBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS1, 1 mese di dati"
      ],
      "metadata": {
        "id": "WLOVUuimVvA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS1_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_20[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS1_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS1_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_40[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS1_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS1_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_60[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS1_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS1_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_80[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS1_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS1_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_100[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS1_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS1_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEbdU6jITCmw",
        "outputId": "9277fd15-047b-4d39-8956-0f2f624281b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           20           1.0\n",
            "1     [2024-02]            1           20           1.0\n",
            "2     [2024-03]            1           20           1.0\n",
            "3     [2024-04]            1           20           1.0\n",
            "4     [2024-05]            1           20           1.0\n",
            "5     [2024-06]            1           20           1.0\n",
            "6     [2024-07]            1           20           1.0\n",
            "7     [2024-08]            1           20           1.0\n",
            "8     [2024-09]            1           20           1.0\n",
            "9     [2024-10]            1           20           1.0\n",
            "10    [2024-11]            1           20           1.0\n",
            "11    [2024-12]            1           20           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           40           1.0\n",
            "1     [2024-02]            1           40           1.0\n",
            "2     [2024-03]            1           40           1.0\n",
            "3     [2024-04]            1           40           1.0\n",
            "4     [2024-05]            1           40           1.0\n",
            "5     [2024-06]            1           40           1.0\n",
            "6     [2024-07]            1           40           1.0\n",
            "7     [2024-08]            1           40           1.0\n",
            "8     [2024-09]            1           40           1.0\n",
            "9     [2024-10]            1           40           1.0\n",
            "10    [2024-11]            1           40           1.0\n",
            "11    [2024-12]            1           40           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           60           1.0\n",
            "1     [2024-02]            1           60           1.0\n",
            "2     [2024-03]            1           60           1.0\n",
            "3     [2024-04]            1           60           1.0\n",
            "4     [2024-05]            1           60           1.0\n",
            "5     [2024-06]            1           60           1.0\n",
            "6     [2024-07]            1           60           1.0\n",
            "7     [2024-08]            1           60           1.0\n",
            "8     [2024-09]            1           60           1.0\n",
            "9     [2024-10]            1           60           1.0\n",
            "10    [2024-11]            1           60           1.0\n",
            "11    [2024-12]            1           60           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           80           1.0\n",
            "1     [2024-02]            1           80           1.0\n",
            "2     [2024-03]            1           80           1.0\n",
            "3     [2024-04]            1           80           1.0\n",
            "4     [2024-05]            1           80           1.0\n",
            "5     [2024-06]            1           80           1.0\n",
            "6     [2024-07]            1           80           1.0\n",
            "7     [2024-08]            1           80           1.0\n",
            "8     [2024-09]            1           80           1.0\n",
            "9     [2024-10]            1           80           1.0\n",
            "10    [2024-11]            1           80           1.0\n",
            "11    [2024-12]            1           80           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1          100           1.0\n",
            "1     [2024-02]            1          100           1.0\n",
            "2     [2024-03]            1          100           1.0\n",
            "3     [2024-04]            1          100           1.0\n",
            "4     [2024-05]            1          100           1.0\n",
            "5     [2024-06]            1          100           1.0\n",
            "6     [2024-07]            1          100           1.0\n",
            "7     [2024-08]            1          100           1.0\n",
            "8     [2024-09]            1          100           1.0\n",
            "9     [2024-10]            1          100           1.0\n",
            "10    [2024-11]            1          100           1.0\n",
            "11    [2024-12]            1          100           1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS1, 2 mesi di dati"
      ],
      "metadata": {
        "id": "wgJ7qt-aV4hm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS1_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_20[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS1_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS1_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_40[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS1_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS1_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_60[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS1_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS1_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_80[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS1_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS1_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_100[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS1_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS1_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eF-GdfU9WZX3",
        "outputId": "a6013f00-3586-47cb-b1a1-5f3d146a4289"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           20           1.0\n",
            "1   [2024-02, 2024-03]            2           20           1.0\n",
            "2   [2024-03, 2024-04]            2           20           1.0\n",
            "3   [2024-04, 2024-05]            2           20           1.0\n",
            "4   [2024-05, 2024-06]            2           20           1.0\n",
            "5   [2024-06, 2024-07]            2           20           1.0\n",
            "6   [2024-07, 2024-08]            2           20           1.0\n",
            "7   [2024-08, 2024-09]            2           20           1.0\n",
            "8   [2024-09, 2024-10]            2           20           1.0\n",
            "9   [2024-10, 2024-11]            2           20           1.0\n",
            "10  [2024-11, 2024-12]            2           20           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           40           1.0\n",
            "1   [2024-02, 2024-03]            2           40           1.0\n",
            "2   [2024-03, 2024-04]            2           40           1.0\n",
            "3   [2024-04, 2024-05]            2           40           1.0\n",
            "4   [2024-05, 2024-06]            2           40           1.0\n",
            "5   [2024-06, 2024-07]            2           40           1.0\n",
            "6   [2024-07, 2024-08]            2           40           1.0\n",
            "7   [2024-08, 2024-09]            2           40           1.0\n",
            "8   [2024-09, 2024-10]            2           40           1.0\n",
            "9   [2024-10, 2024-11]            2           40           1.0\n",
            "10  [2024-11, 2024-12]            2           40           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           60           1.0\n",
            "1   [2024-02, 2024-03]            2           60           1.0\n",
            "2   [2024-03, 2024-04]            2           60           1.0\n",
            "3   [2024-04, 2024-05]            2           60           1.0\n",
            "4   [2024-05, 2024-06]            2           60           1.0\n",
            "5   [2024-06, 2024-07]            2           60           1.0\n",
            "6   [2024-07, 2024-08]            2           60           1.0\n",
            "7   [2024-08, 2024-09]            2           60           1.0\n",
            "8   [2024-09, 2024-10]            2           60           1.0\n",
            "9   [2024-10, 2024-11]            2           60           1.0\n",
            "10  [2024-11, 2024-12]            2           60           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           80           1.0\n",
            "1   [2024-02, 2024-03]            2           80           1.0\n",
            "2   [2024-03, 2024-04]            2           80           1.0\n",
            "3   [2024-04, 2024-05]            2           80           1.0\n",
            "4   [2024-05, 2024-06]            2           80           1.0\n",
            "5   [2024-06, 2024-07]            2           80           1.0\n",
            "6   [2024-07, 2024-08]            2           80           1.0\n",
            "7   [2024-08, 2024-09]            2           80           1.0\n",
            "8   [2024-09, 2024-10]            2           80           1.0\n",
            "9   [2024-10, 2024-11]            2           80           1.0\n",
            "10  [2024-11, 2024-12]            2           80           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2          100           1.0\n",
            "1   [2024-02, 2024-03]            2          100           1.0\n",
            "2   [2024-03, 2024-04]            2          100           1.0\n",
            "3   [2024-04, 2024-05]            2          100           1.0\n",
            "4   [2024-05, 2024-06]            2          100           1.0\n",
            "5   [2024-06, 2024-07]            2          100           1.0\n",
            "6   [2024-07, 2024-08]            2          100           1.0\n",
            "7   [2024-08, 2024-09]            2          100           1.0\n",
            "8   [2024-09, 2024-10]            2          100           1.0\n",
            "9   [2024-10, 2024-11]            2          100           1.0\n",
            "10  [2024-11, 2024-12]            2          100           1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS1, 4 mesi di dati"
      ],
      "metadata": {
        "id": "xgugltm-V4wL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS1_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_20[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS1_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS1_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_40[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS1_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS1_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_60[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS1_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS1_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_80[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS1_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS1_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_100[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS1_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS1_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SD8g3y4oWo6e",
        "outputId": "04982cfe-b5ab-4d29-a992-c8e29fd90a5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           20   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           20   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           20   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           20   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           20   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           20   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           20   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           20   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           20   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           40   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           40   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           40   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           40   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           40   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           40   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           40   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           40   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           40   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           60   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           60   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           60   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           60   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           60   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           60   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           60   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           60   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           60   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           80   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           80   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           80   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           80   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           80   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           80   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           80   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           80   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           80   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4          100   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4          100   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4          100   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4          100   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4          100   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4          100   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4          100   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4          100   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4          100   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS1, 6 mesi di dati"
      ],
      "metadata": {
        "id": "p-VWOcAxV46X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS1_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_20[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS1_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS1_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_40[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS1_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS1_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_60[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS1_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS1_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_80[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS1_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS1_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS1_100[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS1_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS1_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFgtEHe5W6ls",
        "outputId": "81f26814-c6a1-4631-9bf2-32421e00f48f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           20           1.0  \n",
            "1           20           1.0  \n",
            "2           20           1.0  \n",
            "3           20           1.0  \n",
            "4           20           1.0  \n",
            "5           20           1.0  \n",
            "6           20           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           40           1.0  \n",
            "1           40           1.0  \n",
            "2           40           1.0  \n",
            "3           40           1.0  \n",
            "4           40           1.0  \n",
            "5           40           1.0  \n",
            "6           40           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           60           1.0  \n",
            "1           60           1.0  \n",
            "2           60           1.0  \n",
            "3           60           1.0  \n",
            "4           60           1.0  \n",
            "5           60           1.0  \n",
            "6           60           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           80           1.0  \n",
            "1           80           1.0  \n",
            "2           80           1.0  \n",
            "3           80           1.0  \n",
            "4           80           1.0  \n",
            "5           80           1.0  \n",
            "6           80           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0          100           1.0  \n",
            "1          100           1.0  \n",
            "2          100           1.0  \n",
            "3          100           1.0  \n",
            "4          100           1.0  \n",
            "5          100           1.0  \n",
            "6          100           1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS2, 1 mese di dati"
      ],
      "metadata": {
        "id": "VXcncI57V4-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS2_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_20[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS2_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS2_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_40[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS2_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS2_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_60[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS2_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS2_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_80[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS2_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS2_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_100[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS2_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS2_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsqcY5KyXMSs",
        "outputId": "edc3a8da-d2dc-488a-b36f-ad23364ecb46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           20           1.0\n",
            "1     [2024-02]            1           20           1.0\n",
            "2     [2024-03]            1           20           1.0\n",
            "3     [2024-04]            1           20           1.0\n",
            "4     [2024-05]            1           20           1.0\n",
            "5     [2024-06]            1           20           1.0\n",
            "6     [2024-07]            1           20           1.0\n",
            "7     [2024-08]            1           20           1.0\n",
            "8     [2024-09]            1           20           1.0\n",
            "9     [2024-10]            1           20           1.0\n",
            "10    [2024-11]            1           20           1.0\n",
            "11    [2024-12]            1           20           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           40           1.0\n",
            "1     [2024-02]            1           40           1.0\n",
            "2     [2024-03]            1           40           1.0\n",
            "3     [2024-04]            1           40           1.0\n",
            "4     [2024-05]            1           40           1.0\n",
            "5     [2024-06]            1           40           1.0\n",
            "6     [2024-07]            1           40           1.0\n",
            "7     [2024-08]            1           40           1.0\n",
            "8     [2024-09]            1           40           1.0\n",
            "9     [2024-10]            1           40           1.0\n",
            "10    [2024-11]            1           40           1.0\n",
            "11    [2024-12]            1           40           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           60           1.0\n",
            "1     [2024-02]            1           60           1.0\n",
            "2     [2024-03]            1           60           1.0\n",
            "3     [2024-04]            1           60           1.0\n",
            "4     [2024-05]            1           60           1.0\n",
            "5     [2024-06]            1           60           1.0\n",
            "6     [2024-07]            1           60           1.0\n",
            "7     [2024-08]            1           60           1.0\n",
            "8     [2024-09]            1           60           1.0\n",
            "9     [2024-10]            1           60           1.0\n",
            "10    [2024-11]            1           60           1.0\n",
            "11    [2024-12]            1           60           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           80           1.0\n",
            "1     [2024-02]            1           80           1.0\n",
            "2     [2024-03]            1           80           1.0\n",
            "3     [2024-04]            1           80           1.0\n",
            "4     [2024-05]            1           80           1.0\n",
            "5     [2024-06]            1           80           1.0\n",
            "6     [2024-07]            1           80           1.0\n",
            "7     [2024-08]            1           80           1.0\n",
            "8     [2024-09]            1           80           1.0\n",
            "9     [2024-10]            1           80           1.0\n",
            "10    [2024-11]            1           80           1.0\n",
            "11    [2024-12]            1           80           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1          100           1.0\n",
            "1     [2024-02]            1          100           1.0\n",
            "2     [2024-03]            1          100           1.0\n",
            "3     [2024-04]            1          100           1.0\n",
            "4     [2024-05]            1          100           1.0\n",
            "5     [2024-06]            1          100           1.0\n",
            "6     [2024-07]            1          100           1.0\n",
            "7     [2024-08]            1          100           1.0\n",
            "8     [2024-09]            1          100           1.0\n",
            "9     [2024-10]            1          100           1.0\n",
            "10    [2024-11]            1          100           1.0\n",
            "11    [2024-12]            1          100           1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS2, 2 mesi di dati"
      ],
      "metadata": {
        "id": "AJkhgec9V5Br"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS2_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_20[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS2_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS2_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_40[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS2_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS2_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_60[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS2_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS2_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_80[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS2_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS2_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_100[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS2_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS2_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXylyzqEXfrY",
        "outputId": "426152e0-91a2-4c2d-99a8-ae62d4d08ce6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           20           1.0\n",
            "1   [2024-02, 2024-03]            2           20           1.0\n",
            "2   [2024-03, 2024-04]            2           20           1.0\n",
            "3   [2024-04, 2024-05]            2           20           1.0\n",
            "4   [2024-05, 2024-06]            2           20           1.0\n",
            "5   [2024-06, 2024-07]            2           20           1.0\n",
            "6   [2024-07, 2024-08]            2           20           1.0\n",
            "7   [2024-08, 2024-09]            2           20           1.0\n",
            "8   [2024-09, 2024-10]            2           20           1.0\n",
            "9   [2024-10, 2024-11]            2           20           1.0\n",
            "10  [2024-11, 2024-12]            2           20           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           40           1.0\n",
            "1   [2024-02, 2024-03]            2           40           1.0\n",
            "2   [2024-03, 2024-04]            2           40           1.0\n",
            "3   [2024-04, 2024-05]            2           40           1.0\n",
            "4   [2024-05, 2024-06]            2           40           1.0\n",
            "5   [2024-06, 2024-07]            2           40           1.0\n",
            "6   [2024-07, 2024-08]            2           40           1.0\n",
            "7   [2024-08, 2024-09]            2           40           1.0\n",
            "8   [2024-09, 2024-10]            2           40           1.0\n",
            "9   [2024-10, 2024-11]            2           40           1.0\n",
            "10  [2024-11, 2024-12]            2           40           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           60           1.0\n",
            "1   [2024-02, 2024-03]            2           60           1.0\n",
            "2   [2024-03, 2024-04]            2           60           1.0\n",
            "3   [2024-04, 2024-05]            2           60           1.0\n",
            "4   [2024-05, 2024-06]            2           60           1.0\n",
            "5   [2024-06, 2024-07]            2           60           1.0\n",
            "6   [2024-07, 2024-08]            2           60           1.0\n",
            "7   [2024-08, 2024-09]            2           60           1.0\n",
            "8   [2024-09, 2024-10]            2           60           1.0\n",
            "9   [2024-10, 2024-11]            2           60           1.0\n",
            "10  [2024-11, 2024-12]            2           60           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           80           1.0\n",
            "1   [2024-02, 2024-03]            2           80           1.0\n",
            "2   [2024-03, 2024-04]            2           80           1.0\n",
            "3   [2024-04, 2024-05]            2           80           1.0\n",
            "4   [2024-05, 2024-06]            2           80           1.0\n",
            "5   [2024-06, 2024-07]            2           80           1.0\n",
            "6   [2024-07, 2024-08]            2           80           1.0\n",
            "7   [2024-08, 2024-09]            2           80           1.0\n",
            "8   [2024-09, 2024-10]            2           80           1.0\n",
            "9   [2024-10, 2024-11]            2           80           1.0\n",
            "10  [2024-11, 2024-12]            2           80           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2          100           1.0\n",
            "1   [2024-02, 2024-03]            2          100           1.0\n",
            "2   [2024-03, 2024-04]            2          100           1.0\n",
            "3   [2024-04, 2024-05]            2          100           1.0\n",
            "4   [2024-05, 2024-06]            2          100           1.0\n",
            "5   [2024-06, 2024-07]            2          100           1.0\n",
            "6   [2024-07, 2024-08]            2          100           1.0\n",
            "7   [2024-08, 2024-09]            2          100           1.0\n",
            "8   [2024-09, 2024-10]            2          100           1.0\n",
            "9   [2024-10, 2024-11]            2          100           1.0\n",
            "10  [2024-11, 2024-12]            2          100           1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS2, 4 mesi di dati"
      ],
      "metadata": {
        "id": "p1Uqtj6nV5Eh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS2_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_20[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS2_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS2_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_40[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS2_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS2_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_60[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS2_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS2_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_80[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS2_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS2_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_100[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS2_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS2_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5bY_T9IXtNS",
        "outputId": "e01abe2b-002d-4e35-98c5-8ece9bb09a70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           20   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           20   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           20   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           20   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           20   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           20   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           20   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           20   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           20   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           40   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           40   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           40   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           40   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           40   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           40   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           40   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           40   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           40   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           60   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           60   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           60   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           60   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           60   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           60   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           60   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           60   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           60   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           80   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           80   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           80   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           80   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           80   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           80   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           80   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           80   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           80   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4          100   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4          100   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4          100   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4          100   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4          100   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4          100   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4          100   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4          100   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4          100   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS2, 6 mesi di dati"
      ],
      "metadata": {
        "id": "umatrq7QV5Hc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS2_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_20[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS2_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS2_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_40[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS2_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS2_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_60[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS2_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS2_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_80[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS2_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS2_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS2_100[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS2_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS2_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzBXiMBCYPN6",
        "outputId": "c0d3a20c-92ba-4b74-da03-89e6b3a671af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           20           1.0  \n",
            "1           20           1.0  \n",
            "2           20           1.0  \n",
            "3           20           1.0  \n",
            "4           20           1.0  \n",
            "5           20           1.0  \n",
            "6           20           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           40           1.0  \n",
            "1           40           1.0  \n",
            "2           40           1.0  \n",
            "3           40           1.0  \n",
            "4           40           1.0  \n",
            "5           40           1.0  \n",
            "6           40           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           60           1.0  \n",
            "1           60           1.0  \n",
            "2           60           1.0  \n",
            "3           60           1.0  \n",
            "4           60           1.0  \n",
            "5           60           1.0  \n",
            "6           60           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           80           1.0  \n",
            "1           80           1.0  \n",
            "2           80           1.0  \n",
            "3           80           1.0  \n",
            "4           80           1.0  \n",
            "5           80           1.0  \n",
            "6           80           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0          100           1.0  \n",
            "1          100           1.0  \n",
            "2          100           1.0  \n",
            "3          100           1.0  \n",
            "4          100           1.0  \n",
            "5          100           1.0  \n",
            "6          100           1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS3, 1 mese di dati"
      ],
      "metadata": {
        "id": "tKf_mIHXV5Kb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS3_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_20[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS3_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS3_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_40[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS3_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS3_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_60[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS3_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS3_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_80[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS3_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS3_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_100[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS3_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS3_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTjLOFH1YcSi",
        "outputId": "096ca359-74fc-49da-cce1-b6968d2ce447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           20           1.0\n",
            "1     [2024-02]            1           20           1.0\n",
            "2     [2024-03]            1           20           1.0\n",
            "3     [2024-04]            1           20           1.0\n",
            "4     [2024-05]            1           20           1.0\n",
            "5     [2024-06]            1           20           1.0\n",
            "6     [2024-07]            1           20           1.0\n",
            "7     [2024-08]            1           20           1.0\n",
            "8     [2024-09]            1           20           1.0\n",
            "9     [2024-10]            1           20           1.0\n",
            "10    [2024-11]            1           20           1.0\n",
            "11    [2024-12]            1           20           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           40           1.0\n",
            "1     [2024-02]            1           40           1.0\n",
            "2     [2024-03]            1           40           1.0\n",
            "3     [2024-04]            1           40           1.0\n",
            "4     [2024-05]            1           40           1.0\n",
            "5     [2024-06]            1           40           1.0\n",
            "6     [2024-07]            1           40           1.0\n",
            "7     [2024-08]            1           40           1.0\n",
            "8     [2024-09]            1           40           1.0\n",
            "9     [2024-10]            1           40           1.0\n",
            "10    [2024-11]            1           40           1.0\n",
            "11    [2024-12]            1           40           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           60           1.0\n",
            "1     [2024-02]            1           60           1.0\n",
            "2     [2024-03]            1           60           1.0\n",
            "3     [2024-04]            1           60           1.0\n",
            "4     [2024-05]            1           60           1.0\n",
            "5     [2024-06]            1           60           1.0\n",
            "6     [2024-07]            1           60           1.0\n",
            "7     [2024-08]            1           60           1.0\n",
            "8     [2024-09]            1           60           1.0\n",
            "9     [2024-10]            1           60           1.0\n",
            "10    [2024-11]            1           60           1.0\n",
            "11    [2024-12]            1           60           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           80           1.0\n",
            "1     [2024-02]            1           80           1.0\n",
            "2     [2024-03]            1           80           1.0\n",
            "3     [2024-04]            1           80           1.0\n",
            "4     [2024-05]            1           80           1.0\n",
            "5     [2024-06]            1           80           1.0\n",
            "6     [2024-07]            1           80           1.0\n",
            "7     [2024-08]            1           80           1.0\n",
            "8     [2024-09]            1           80           1.0\n",
            "9     [2024-10]            1           80           1.0\n",
            "10    [2024-11]            1           80           1.0\n",
            "11    [2024-12]            1           80           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1          100           1.0\n",
            "1     [2024-02]            1          100           1.0\n",
            "2     [2024-03]            1          100           1.0\n",
            "3     [2024-04]            1          100           1.0\n",
            "4     [2024-05]            1          100           1.0\n",
            "5     [2024-06]            1          100           1.0\n",
            "6     [2024-07]            1          100           1.0\n",
            "7     [2024-08]            1          100           1.0\n",
            "8     [2024-09]            1          100           1.0\n",
            "9     [2024-10]            1          100           1.0\n",
            "10    [2024-11]            1          100           1.0\n",
            "11    [2024-12]            1          100           1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS3, 2 mesi di dati"
      ],
      "metadata": {
        "id": "6gzCvTZLV5Ni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS3_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_20[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS3_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS3_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_40[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS3_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS3_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_60[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS3_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS3_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_80[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS3_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS3_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_100[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS3_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS3_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_ZZAym0aw0b",
        "outputId": "41a3e319-c68c-4f57-cf3e-e09bf4a140ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           20           1.0\n",
            "1   [2024-02, 2024-03]            2           20           1.0\n",
            "2   [2024-03, 2024-04]            2           20           1.0\n",
            "3   [2024-04, 2024-05]            2           20           1.0\n",
            "4   [2024-05, 2024-06]            2           20           1.0\n",
            "5   [2024-06, 2024-07]            2           20           1.0\n",
            "6   [2024-07, 2024-08]            2           20           1.0\n",
            "7   [2024-08, 2024-09]            2           20           1.0\n",
            "8   [2024-09, 2024-10]            2           20           1.0\n",
            "9   [2024-10, 2024-11]            2           20           1.0\n",
            "10  [2024-11, 2024-12]            2           20           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           40           1.0\n",
            "1   [2024-02, 2024-03]            2           40           1.0\n",
            "2   [2024-03, 2024-04]            2           40           1.0\n",
            "3   [2024-04, 2024-05]            2           40           1.0\n",
            "4   [2024-05, 2024-06]            2           40           1.0\n",
            "5   [2024-06, 2024-07]            2           40           1.0\n",
            "6   [2024-07, 2024-08]            2           40           1.0\n",
            "7   [2024-08, 2024-09]            2           40           1.0\n",
            "8   [2024-09, 2024-10]            2           40           1.0\n",
            "9   [2024-10, 2024-11]            2           40           1.0\n",
            "10  [2024-11, 2024-12]            2           40           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           60           1.0\n",
            "1   [2024-02, 2024-03]            2           60           1.0\n",
            "2   [2024-03, 2024-04]            2           60           1.0\n",
            "3   [2024-04, 2024-05]            2           60           1.0\n",
            "4   [2024-05, 2024-06]            2           60           1.0\n",
            "5   [2024-06, 2024-07]            2           60           1.0\n",
            "6   [2024-07, 2024-08]            2           60           1.0\n",
            "7   [2024-08, 2024-09]            2           60           1.0\n",
            "8   [2024-09, 2024-10]            2           60           1.0\n",
            "9   [2024-10, 2024-11]            2           60           1.0\n",
            "10  [2024-11, 2024-12]            2           60           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           80           1.0\n",
            "1   [2024-02, 2024-03]            2           80           1.0\n",
            "2   [2024-03, 2024-04]            2           80           1.0\n",
            "3   [2024-04, 2024-05]            2           80           1.0\n",
            "4   [2024-05, 2024-06]            2           80           1.0\n",
            "5   [2024-06, 2024-07]            2           80           1.0\n",
            "6   [2024-07, 2024-08]            2           80           1.0\n",
            "7   [2024-08, 2024-09]            2           80           1.0\n",
            "8   [2024-09, 2024-10]            2           80           1.0\n",
            "9   [2024-10, 2024-11]            2           80           1.0\n",
            "10  [2024-11, 2024-12]            2           80           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2          100           1.0\n",
            "1   [2024-02, 2024-03]            2          100           1.0\n",
            "2   [2024-03, 2024-04]            2          100           1.0\n",
            "3   [2024-04, 2024-05]            2          100           1.0\n",
            "4   [2024-05, 2024-06]            2          100           1.0\n",
            "5   [2024-06, 2024-07]            2          100           1.0\n",
            "6   [2024-07, 2024-08]            2          100           1.0\n",
            "7   [2024-08, 2024-09]            2          100           1.0\n",
            "8   [2024-09, 2024-10]            2          100           1.0\n",
            "9   [2024-10, 2024-11]            2          100           1.0\n",
            "10  [2024-11, 2024-12]            2          100           1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS3, 4 mesi di dati"
      ],
      "metadata": {
        "id": "aWAPDAkFV5Qd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS3_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_20[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS3_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS3_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_40[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS3_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS3_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_60[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS3_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS3_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_80[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS3_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS3_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_100[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS3_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS3_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcbsIXHFbDJ6",
        "outputId": "373e3bb6-81fc-4a24-a174-c397f6d2534e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           20   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           20   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           20   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           20   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           20   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           20   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           20   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           20   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           20   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           40   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           40   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           40   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           40   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           40   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           40   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           40   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           40   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           40   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           60   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           60   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           60   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           60   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           60   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           60   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           60   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           60   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           60   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           80   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           80   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           80   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           80   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           80   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           80   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           80   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           80   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           80   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4          100   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4          100   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4          100   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4          100   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4          100   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4          100   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4          100   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4          100   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4          100   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS3, 6 mesi di dati"
      ],
      "metadata": {
        "id": "7zlmryn6V5Tq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS3_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_20[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS3_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS3_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_40[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS3_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS3_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_60[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS3_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS3_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_80[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS3_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS3_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS3_100[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS3_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS3_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgJvTtwJbSRL",
        "outputId": "20b73c24-50ce-4ca7-dc1a-3f906728a3af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           20           1.0  \n",
            "1           20           1.0  \n",
            "2           20           1.0  \n",
            "3           20           1.0  \n",
            "4           20           1.0  \n",
            "5           20           1.0  \n",
            "6           20           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           40           1.0  \n",
            "1           40           1.0  \n",
            "2           40           1.0  \n",
            "3           40           1.0  \n",
            "4           40           1.0  \n",
            "5           40           1.0  \n",
            "6           40           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           60           1.0  \n",
            "1           60           1.0  \n",
            "2           60           1.0  \n",
            "3           60           1.0  \n",
            "4           60           1.0  \n",
            "5           60           1.0  \n",
            "6           60           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           80           1.0  \n",
            "1           80           1.0  \n",
            "2           80           1.0  \n",
            "3           80           1.0  \n",
            "4           80           1.0  \n",
            "5           80           1.0  \n",
            "6           80           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0          100           1.0  \n",
            "1          100           1.0  \n",
            "2          100           1.0  \n",
            "3          100           1.0  \n",
            "4          100           1.0  \n",
            "5          100           1.0  \n",
            "6          100           1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS4, 1 mese di dati"
      ],
      "metadata": {
        "id": "9MdHsmozV5lF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS4_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_20[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS4_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS4_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_40[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS4_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS4_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_60[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS4_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS4_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_80[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS4_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS4_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_100[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS4_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS4_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6i_x7_Wbfoe",
        "outputId": "4f7e06be-2aad-4b77-aeee-dda4e66a3061"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           20           1.0\n",
            "1     [2024-02]            1           20           1.0\n",
            "2     [2024-03]            1           20           1.0\n",
            "3     [2024-04]            1           20           1.0\n",
            "4     [2024-05]            1           20           1.0\n",
            "5     [2024-06]            1           20           1.0\n",
            "6     [2024-07]            1           20           1.0\n",
            "7     [2024-08]            1           20           1.0\n",
            "8     [2024-09]            1           20           1.0\n",
            "9     [2024-10]            1           20           1.0\n",
            "10    [2024-11]            1           20           1.0\n",
            "11    [2024-12]            1           20           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           40           1.0\n",
            "1     [2024-02]            1           40           1.0\n",
            "2     [2024-03]            1           40           1.0\n",
            "3     [2024-04]            1           40           1.0\n",
            "4     [2024-05]            1           40           1.0\n",
            "5     [2024-06]            1           40           1.0\n",
            "6     [2024-07]            1           40           1.0\n",
            "7     [2024-08]            1           40           1.0\n",
            "8     [2024-09]            1           40           1.0\n",
            "9     [2024-10]            1           40           1.0\n",
            "10    [2024-11]            1           40           1.0\n",
            "11    [2024-12]            1           40           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           60           1.0\n",
            "1     [2024-02]            1           60           1.0\n",
            "2     [2024-03]            1           60           1.0\n",
            "3     [2024-04]            1           60           1.0\n",
            "4     [2024-05]            1           60           1.0\n",
            "5     [2024-06]            1           60           1.0\n",
            "6     [2024-07]            1           60           1.0\n",
            "7     [2024-08]            1           60           1.0\n",
            "8     [2024-09]            1           60           1.0\n",
            "9     [2024-10]            1           60           1.0\n",
            "10    [2024-11]            1           60           1.0\n",
            "11    [2024-12]            1           60           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           80           1.0\n",
            "1     [2024-02]            1           80           1.0\n",
            "2     [2024-03]            1           80           1.0\n",
            "3     [2024-04]            1           80           1.0\n",
            "4     [2024-05]            1           80           1.0\n",
            "5     [2024-06]            1           80           1.0\n",
            "6     [2024-07]            1           80           1.0\n",
            "7     [2024-08]            1           80           1.0\n",
            "8     [2024-09]            1           80           1.0\n",
            "9     [2024-10]            1           80           1.0\n",
            "10    [2024-11]            1           80           1.0\n",
            "11    [2024-12]            1           80           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1          100           1.0\n",
            "1     [2024-02]            1          100           1.0\n",
            "2     [2024-03]            1          100           1.0\n",
            "3     [2024-04]            1          100           1.0\n",
            "4     [2024-05]            1          100           1.0\n",
            "5     [2024-06]            1          100           1.0\n",
            "6     [2024-07]            1          100           1.0\n",
            "7     [2024-08]            1          100           1.0\n",
            "8     [2024-09]            1          100           1.0\n",
            "9     [2024-10]            1          100           1.0\n",
            "10    [2024-11]            1          100           1.0\n",
            "11    [2024-12]            1          100           1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS4, 2 mesi di dati"
      ],
      "metadata": {
        "id": "1WSnJlWkV5ow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS4_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_20[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS4_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS4_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_40[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS4_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS4_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_60[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS4_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS4_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_80[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS4_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS4_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_100[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS4_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS4_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-slHJSKcCJR",
        "outputId": "f8d55ea4-0e5e-45c1-c6ce-df53e6b5e379"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           20           1.0\n",
            "1   [2024-02, 2024-03]            2           20           1.0\n",
            "2   [2024-03, 2024-04]            2           20           1.0\n",
            "3   [2024-04, 2024-05]            2           20           1.0\n",
            "4   [2024-05, 2024-06]            2           20           1.0\n",
            "5   [2024-06, 2024-07]            2           20           1.0\n",
            "6   [2024-07, 2024-08]            2           20           1.0\n",
            "7   [2024-08, 2024-09]            2           20           1.0\n",
            "8   [2024-09, 2024-10]            2           20           1.0\n",
            "9   [2024-10, 2024-11]            2           20           1.0\n",
            "10  [2024-11, 2024-12]            2           20           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           40           1.0\n",
            "1   [2024-02, 2024-03]            2           40           1.0\n",
            "2   [2024-03, 2024-04]            2           40           1.0\n",
            "3   [2024-04, 2024-05]            2           40           1.0\n",
            "4   [2024-05, 2024-06]            2           40           1.0\n",
            "5   [2024-06, 2024-07]            2           40           1.0\n",
            "6   [2024-07, 2024-08]            2           40           1.0\n",
            "7   [2024-08, 2024-09]            2           40           1.0\n",
            "8   [2024-09, 2024-10]            2           40           1.0\n",
            "9   [2024-10, 2024-11]            2           40           1.0\n",
            "10  [2024-11, 2024-12]            2           40           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           60           1.0\n",
            "1   [2024-02, 2024-03]            2           60           1.0\n",
            "2   [2024-03, 2024-04]            2           60           1.0\n",
            "3   [2024-04, 2024-05]            2           60           1.0\n",
            "4   [2024-05, 2024-06]            2           60           1.0\n",
            "5   [2024-06, 2024-07]            2           60           1.0\n",
            "6   [2024-07, 2024-08]            2           60           1.0\n",
            "7   [2024-08, 2024-09]            2           60           1.0\n",
            "8   [2024-09, 2024-10]            2           60           1.0\n",
            "9   [2024-10, 2024-11]            2           60           1.0\n",
            "10  [2024-11, 2024-12]            2           60           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           80           1.0\n",
            "1   [2024-02, 2024-03]            2           80           1.0\n",
            "2   [2024-03, 2024-04]            2           80           1.0\n",
            "3   [2024-04, 2024-05]            2           80           1.0\n",
            "4   [2024-05, 2024-06]            2           80           1.0\n",
            "5   [2024-06, 2024-07]            2           80           1.0\n",
            "6   [2024-07, 2024-08]            2           80           1.0\n",
            "7   [2024-08, 2024-09]            2           80           1.0\n",
            "8   [2024-09, 2024-10]            2           80           1.0\n",
            "9   [2024-10, 2024-11]            2           80           1.0\n",
            "10  [2024-11, 2024-12]            2           80           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2          100           1.0\n",
            "1   [2024-02, 2024-03]            2          100           1.0\n",
            "2   [2024-03, 2024-04]            2          100           1.0\n",
            "3   [2024-04, 2024-05]            2          100           1.0\n",
            "4   [2024-05, 2024-06]            2          100           1.0\n",
            "5   [2024-06, 2024-07]            2          100           1.0\n",
            "6   [2024-07, 2024-08]            2          100           1.0\n",
            "7   [2024-08, 2024-09]            2          100           1.0\n",
            "8   [2024-09, 2024-10]            2          100           1.0\n",
            "9   [2024-10, 2024-11]            2          100           1.0\n",
            "10  [2024-11, 2024-12]            2          100           1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS4, 4 mesi di dati"
      ],
      "metadata": {
        "id": "LZUv02NzWSZq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS4_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_20[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS4_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS4_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_40[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS4_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS4_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_60[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS4_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS4_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_80[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS4_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS4_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_100[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS4_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS4_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBaAM0U_cTWK",
        "outputId": "29775ee3-fdae-4ec7-ff88-7acf9b41264b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           20   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           20   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           20   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           20   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           20   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           20   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           20   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           20   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           20   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           40   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           40   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           40   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           40   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           40   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           40   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           40   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           40   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           40   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           60   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           60   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           60   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           60   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           60   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           60   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           60   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           60   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           60   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           80   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           80   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           80   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           80   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           80   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           80   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           80   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           80   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           80   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4          100   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4          100   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4          100   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4          100   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4          100   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4          100   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4          100   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4          100   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4          100   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS4, 6 mesi di dati"
      ],
      "metadata": {
        "id": "HaOT3W90WTnb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS4_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_20[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS4_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS4_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_40[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS4_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS4_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_60[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS4_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS4_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_80[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS4_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS4_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "\n",
        "  X_val = scaler_X.transform(df_DS4_100[features])\n",
        "\n",
        "  vae_no_temp = VAE(input_dim=X_train.shape[1], latent_dim=2)\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_no_temp(dummy_x)\n",
        "\n",
        "  vae_no_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_no_temp.load_weights(f\"/content/drive/MyDrive/VAE_no_temp_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_no_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(X_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_no_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(X_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS4_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS4_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMxNmj-DckBp",
        "outputId": "5e530cfe-ae8c-4317-ffba-787f39526dea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           20           1.0  \n",
            "1           20           1.0  \n",
            "2           20           1.0  \n",
            "3           20           1.0  \n",
            "4           20           1.0  \n",
            "5           20           1.0  \n",
            "6           20           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           40           1.0  \n",
            "1           40           1.0  \n",
            "2           40           1.0  \n",
            "3           40           1.0  \n",
            "4           40           1.0  \n",
            "5           40           1.0  \n",
            "6           40           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           60           1.0  \n",
            "1           60           1.0  \n",
            "2           60           1.0  \n",
            "3           60           1.0  \n",
            "4           60           1.0  \n",
            "5           60           1.0  \n",
            "6           60           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           80           1.0  \n",
            "1           80           1.0  \n",
            "2           80           1.0  \n",
            "3           80           1.0  \n",
            "4           80           1.0  \n",
            "5           80           1.0  \n",
            "6           80           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0          100           1.0  \n",
            "1          100           1.0  \n",
            "2          100           1.0  \n",
            "3          100           1.0  \n",
            "4          100           1.0  \n",
            "5          100           1.0  \n",
            "6          100           1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VAE con temperatura"
      ],
      "metadata": {
        "id": "XLWTMb54dZhQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"keras\")\n",
        "\n",
        "df_temp = pd.read_csv(\"/content/data_temperature.csv\", encoding = \"utf-8\")\n",
        "df_temp[\"timestamp\"] = pd.to_datetime(df_temp[\"timestamp\"])\n",
        "df_temp[\"timestamp\"] = df_temp[\"timestamp\"].dt.tz_localize(None)\n",
        "df_temp = df_temp.sort_values(\"timestamp\")\n",
        "\n",
        "end = \"2025-01-01\"\n",
        "new_df = df_temp[(df_temp[\"timestamp\"] < end)]\n",
        "\n",
        "\n",
        "\n",
        "class Sampling(Layer):\n",
        "  def call(self, inputs):\n",
        "    z_mean, z_log_var = inputs\n",
        "    epsilon = tf.random.normal(shape=tf.shape(z_mean))\n",
        "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "\n",
        "\n",
        "class VAE_temp(keras.Model):\n",
        "  def __init__(self, input_dim, output_dim, latent_dim = 2, beta = 0.01, **kwargs):\n",
        "    super(VAE_temp, self).__init__(**kwargs)\n",
        "    self.beta = beta\n",
        "\n",
        "    #encoder\n",
        "    x_input = keras.Input(shape=(input_dim,))\n",
        "    x = layers.Dense(32, activation=\"relu\")(x_input)\n",
        "    x = layers.Dense(16, activation=\"relu\")(x)\n",
        "    x = layers.Dense(8, activation=\"relu\")(x)\n",
        "    z_mean = layers.Dense(latent_dim)(x)\n",
        "    z_log_var = layers.Dense(latent_dim)(x)\n",
        "\n",
        "    z = Sampling()([z_mean, z_log_var])\n",
        "    self.encoder = keras.Model(x_input, [z_mean, z_log_var, z])\n",
        "\n",
        "    #decoder\n",
        "    latent_inputs = keras.Input(shape=(latent_dim,))\n",
        "    x = layers.Dense(8, activation=\"relu\")(latent_inputs)\n",
        "    x = layers.Dense(16, activation=\"relu\")(x)\n",
        "    x = layers.Dense(32, activation=\"relu\")(x)\n",
        "    outputs = layers.Dense(output_dim, activation=\"linear\")(x)\n",
        "\n",
        "    self.decoder = keras.Model(latent_inputs, outputs)\n",
        "\n",
        "  def train_step(self, data):\n",
        "    x, y = data\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "      z_mean, z_log_var, z = self.encoder(x, training = True)\n",
        "      reconstruction = self.decoder(z, training = True)\n",
        "\n",
        "      reconstruction_loss = tf.reduce_mean(tf.square(x[:, :6] - reconstruction))\n",
        "      kl_loss = -0.5 * tf.reduce_mean(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
        "      total_loss = reconstruction_loss + self.beta * kl_loss\n",
        "\n",
        "    grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "    self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "\n",
        "    return {\"loss\": total_loss, \"recon_loss\": reconstruction_loss, \"kl_loss\": kl_loss}\n",
        "\n",
        "  def call(self, inputs):\n",
        "    z_mean, _,  z = self.encoder(inputs)\n",
        "    return self.decoder(z)\n"
      ],
      "metadata": {
        "id": "yFxjMrz6dlvp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS1, 1 mese di dati"
      ],
      "metadata": {
        "id": "pHTXpS5Hg7ys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS1_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS1_20[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS1_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS1_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS1_40[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS1_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS1_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS1_60[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS1_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS1_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS1_80[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS1_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS1_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS1_100[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS1_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS1_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToE1tSkbd1Qo",
        "outputId": "1e78b26b-787e-48ff-8691-effe1ab0109e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           20           1.0\n",
            "1     [2024-02]            1           20           1.0\n",
            "2     [2024-03]            1           20           1.0\n",
            "3     [2024-04]            1           20           1.0\n",
            "4     [2024-05]            1           20           1.0\n",
            "5     [2024-06]            1           20           1.0\n",
            "6     [2024-07]            1           20           1.0\n",
            "7     [2024-08]            1           20           1.0\n",
            "8     [2024-09]            1           20           1.0\n",
            "9     [2024-10]            1           20           1.0\n",
            "10    [2024-11]            1           20           1.0\n",
            "11    [2024-12]            1           20           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           40           1.0\n",
            "1     [2024-02]            1           40           1.0\n",
            "2     [2024-03]            1           40           1.0\n",
            "3     [2024-04]            1           40           1.0\n",
            "4     [2024-05]            1           40           1.0\n",
            "5     [2024-06]            1           40           1.0\n",
            "6     [2024-07]            1           40           1.0\n",
            "7     [2024-08]            1           40           1.0\n",
            "8     [2024-09]            1           40           1.0\n",
            "9     [2024-10]            1           40           1.0\n",
            "10    [2024-11]            1           40           1.0\n",
            "11    [2024-12]            1           40           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           60           1.0\n",
            "1     [2024-02]            1           60           1.0\n",
            "2     [2024-03]            1           60           1.0\n",
            "3     [2024-04]            1           60           1.0\n",
            "4     [2024-05]            1           60           1.0\n",
            "5     [2024-06]            1           60           1.0\n",
            "6     [2024-07]            1           60           1.0\n",
            "7     [2024-08]            1           60           1.0\n",
            "8     [2024-09]            1           60           1.0\n",
            "9     [2024-10]            1           60           1.0\n",
            "10    [2024-11]            1           60           1.0\n",
            "11    [2024-12]            1           60           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           80           1.0\n",
            "1     [2024-02]            1           80           1.0\n",
            "2     [2024-03]            1           80           1.0\n",
            "3     [2024-04]            1           80           1.0\n",
            "4     [2024-05]            1           80           1.0\n",
            "5     [2024-06]            1           80           1.0\n",
            "6     [2024-07]            1           80           1.0\n",
            "7     [2024-08]            1           80           1.0\n",
            "8     [2024-09]            1           80           1.0\n",
            "9     [2024-10]            1           80           1.0\n",
            "10    [2024-11]            1           80           1.0\n",
            "11    [2024-12]            1           80           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1          100           1.0\n",
            "1     [2024-02]            1          100           1.0\n",
            "2     [2024-03]            1          100           1.0\n",
            "3     [2024-04]            1          100           1.0\n",
            "4     [2024-05]            1          100           1.0\n",
            "5     [2024-06]            1          100           1.0\n",
            "6     [2024-07]            1          100           1.0\n",
            "7     [2024-08]            1          100           1.0\n",
            "8     [2024-09]            1          100           1.0\n",
            "9     [2024-10]            1          100           1.0\n",
            "10    [2024-11]            1          100           1.0\n",
            "11    [2024-12]            1          100           1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS1, 2 mesi di dati"
      ],
      "metadata": {
        "id": "2nnfLfFRgdvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS1_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS1_20[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS1_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS1_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS1_40[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS1_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS1_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS1_60[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS1_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS1_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS1_80[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS1_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS1_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS1_100[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS1_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS1_100)"
      ],
      "metadata": {
        "id": "-85RfNkvgd_k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e948d795-dd88-48d6-a44f-4e7f59b0cc7d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           20           1.0\n",
            "1   [2024-02, 2024-03]            2           20           1.0\n",
            "2   [2024-03, 2024-04]            2           20           1.0\n",
            "3   [2024-04, 2024-05]            2           20           1.0\n",
            "4   [2024-05, 2024-06]            2           20           1.0\n",
            "5   [2024-06, 2024-07]            2           20           1.0\n",
            "6   [2024-07, 2024-08]            2           20           1.0\n",
            "7   [2024-08, 2024-09]            2           20           1.0\n",
            "8   [2024-09, 2024-10]            2           20           1.0\n",
            "9   [2024-10, 2024-11]            2           20           1.0\n",
            "10  [2024-11, 2024-12]            2           20           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           40           1.0\n",
            "1   [2024-02, 2024-03]            2           40           1.0\n",
            "2   [2024-03, 2024-04]            2           40           1.0\n",
            "3   [2024-04, 2024-05]            2           40           1.0\n",
            "4   [2024-05, 2024-06]            2           40           1.0\n",
            "5   [2024-06, 2024-07]            2           40           1.0\n",
            "6   [2024-07, 2024-08]            2           40           1.0\n",
            "7   [2024-08, 2024-09]            2           40           1.0\n",
            "8   [2024-09, 2024-10]            2           40           1.0\n",
            "9   [2024-10, 2024-11]            2           40           1.0\n",
            "10  [2024-11, 2024-12]            2           40           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           60           1.0\n",
            "1   [2024-02, 2024-03]            2           60           1.0\n",
            "2   [2024-03, 2024-04]            2           60           1.0\n",
            "3   [2024-04, 2024-05]            2           60           1.0\n",
            "4   [2024-05, 2024-06]            2           60           1.0\n",
            "5   [2024-06, 2024-07]            2           60           1.0\n",
            "6   [2024-07, 2024-08]            2           60           1.0\n",
            "7   [2024-08, 2024-09]            2           60           1.0\n",
            "8   [2024-09, 2024-10]            2           60           1.0\n",
            "9   [2024-10, 2024-11]            2           60           1.0\n",
            "10  [2024-11, 2024-12]            2           60           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           80           1.0\n",
            "1   [2024-02, 2024-03]            2           80           1.0\n",
            "2   [2024-03, 2024-04]            2           80           1.0\n",
            "3   [2024-04, 2024-05]            2           80           1.0\n",
            "4   [2024-05, 2024-06]            2           80           1.0\n",
            "5   [2024-06, 2024-07]            2           80           1.0\n",
            "6   [2024-07, 2024-08]            2           80           1.0\n",
            "7   [2024-08, 2024-09]            2           80           1.0\n",
            "8   [2024-09, 2024-10]            2           80           1.0\n",
            "9   [2024-10, 2024-11]            2           80           1.0\n",
            "10  [2024-11, 2024-12]            2           80           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2          100           1.0\n",
            "1   [2024-02, 2024-03]            2          100           1.0\n",
            "2   [2024-03, 2024-04]            2          100           1.0\n",
            "3   [2024-04, 2024-05]            2          100           1.0\n",
            "4   [2024-05, 2024-06]            2          100           1.0\n",
            "5   [2024-06, 2024-07]            2          100           1.0\n",
            "6   [2024-07, 2024-08]            2          100           1.0\n",
            "7   [2024-08, 2024-09]            2          100           1.0\n",
            "8   [2024-09, 2024-10]            2          100           1.0\n",
            "9   [2024-10, 2024-11]            2          100           1.0\n",
            "10  [2024-11, 2024-12]            2          100           1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS1, 4 mesi di dati"
      ],
      "metadata": {
        "id": "yGGvyEQfhBIM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS1_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS1_20[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS1_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS1_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS1_40[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS1_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS1_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS1_60[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS1_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS1_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS1_80[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS1_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS1_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS1_100[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS1_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS1_100)"
      ],
      "metadata": {
        "id": "4uCfA2-xh0PL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e5a496d-ccb9-414a-85b9-d929b8b02c9e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           20   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           20   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           20   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           20   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           20   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           20   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           20   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           20   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           20   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           40   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           40   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           40   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           40   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           40   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           40   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           40   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           40   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           40   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           60   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           60   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           60   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           60   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           60   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           60   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           60   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           60   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           60   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           80   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           80   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           80   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           80   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           80   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           80   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           80   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           80   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           80   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4          100   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4          100   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4          100   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4          100   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4          100   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4          100   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4          100   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4          100   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4          100   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS1, 6 mesi di dati"
      ],
      "metadata": {
        "id": "DpGinhCohBcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS1_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS1_20[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS1_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS1_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS1_40[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS1_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS1_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS1_60[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS1_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS1_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS1_80[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS1_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS1_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS1_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS1\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS1_100[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS1_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS1_100)"
      ],
      "metadata": {
        "id": "Im49LfX5iFKl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "209a9e35-5215-4046-8975-931c1e76b4e9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           20           1.0  \n",
            "1           20           1.0  \n",
            "2           20           1.0  \n",
            "3           20           1.0  \n",
            "4           20           1.0  \n",
            "5           20           1.0  \n",
            "6           20           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           40           1.0  \n",
            "1           40           1.0  \n",
            "2           40           1.0  \n",
            "3           40           1.0  \n",
            "4           40           1.0  \n",
            "5           40           1.0  \n",
            "6           40           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           60           1.0  \n",
            "1           60           1.0  \n",
            "2           60           1.0  \n",
            "3           60           1.0  \n",
            "4           60           1.0  \n",
            "5           60           1.0  \n",
            "6           60           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           80           1.0  \n",
            "1           80           1.0  \n",
            "2           80           1.0  \n",
            "3           80           1.0  \n",
            "4           80           1.0  \n",
            "5           80           1.0  \n",
            "6           80           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0          100           1.0  \n",
            "1          100           1.0  \n",
            "2          100           1.0  \n",
            "3          100           1.0  \n",
            "4          100           1.0  \n",
            "5          100           1.0  \n",
            "6          100           1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS2, 1 mese di dati"
      ],
      "metadata": {
        "id": "TPwBqw2AhBjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS2_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS2_20[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS2_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS2_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS2_40[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS2_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS2_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS2_60[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS2_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS2_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS2_80[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS2_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS2_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS2_100[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS2_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS2_100)"
      ],
      "metadata": {
        "id": "2mdymqaPihT6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a8d1ecb-bc8f-4e0b-a540-d08eb6d6c35c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           20           1.0\n",
            "1     [2024-02]            1           20           1.0\n",
            "2     [2024-03]            1           20           1.0\n",
            "3     [2024-04]            1           20           1.0\n",
            "4     [2024-05]            1           20           1.0\n",
            "5     [2024-06]            1           20           1.0\n",
            "6     [2024-07]            1           20           1.0\n",
            "7     [2024-08]            1           20           1.0\n",
            "8     [2024-09]            1           20           1.0\n",
            "9     [2024-10]            1           20           1.0\n",
            "10    [2024-11]            1           20           1.0\n",
            "11    [2024-12]            1           20           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           40           1.0\n",
            "1     [2024-02]            1           40           1.0\n",
            "2     [2024-03]            1           40           1.0\n",
            "3     [2024-04]            1           40           1.0\n",
            "4     [2024-05]            1           40           1.0\n",
            "5     [2024-06]            1           40           1.0\n",
            "6     [2024-07]            1           40           1.0\n",
            "7     [2024-08]            1           40           1.0\n",
            "8     [2024-09]            1           40           1.0\n",
            "9     [2024-10]            1           40           1.0\n",
            "10    [2024-11]            1           40           1.0\n",
            "11    [2024-12]            1           40           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           60           1.0\n",
            "1     [2024-02]            1           60           1.0\n",
            "2     [2024-03]            1           60           1.0\n",
            "3     [2024-04]            1           60           1.0\n",
            "4     [2024-05]            1           60           1.0\n",
            "5     [2024-06]            1           60           1.0\n",
            "6     [2024-07]            1           60           1.0\n",
            "7     [2024-08]            1           60           1.0\n",
            "8     [2024-09]            1           60           1.0\n",
            "9     [2024-10]            1           60           1.0\n",
            "10    [2024-11]            1           60           1.0\n",
            "11    [2024-12]            1           60           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           80           1.0\n",
            "1     [2024-02]            1           80           1.0\n",
            "2     [2024-03]            1           80           1.0\n",
            "3     [2024-04]            1           80           1.0\n",
            "4     [2024-05]            1           80           1.0\n",
            "5     [2024-06]            1           80           1.0\n",
            "6     [2024-07]            1           80           1.0\n",
            "7     [2024-08]            1           80           1.0\n",
            "8     [2024-09]            1           80           1.0\n",
            "9     [2024-10]            1           80           1.0\n",
            "10    [2024-11]            1           80           1.0\n",
            "11    [2024-12]            1           80           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1          100           1.0\n",
            "1     [2024-02]            1          100           1.0\n",
            "2     [2024-03]            1          100           1.0\n",
            "3     [2024-04]            1          100           1.0\n",
            "4     [2024-05]            1          100           1.0\n",
            "5     [2024-06]            1          100           1.0\n",
            "6     [2024-07]            1          100           1.0\n",
            "7     [2024-08]            1          100           1.0\n",
            "8     [2024-09]            1          100           1.0\n",
            "9     [2024-10]            1          100           1.0\n",
            "10    [2024-11]            1          100           1.0\n",
            "11    [2024-12]            1          100           1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS2, 2 mesi di dati"
      ],
      "metadata": {
        "id": "0Kh75hmXhBpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS2_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS2_20[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS2_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS2_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS2_40[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS2_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS2_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS2_60[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS2_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS2_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS2_80[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS2_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS2_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS2_100[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS2_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS2_100)"
      ],
      "metadata": {
        "id": "n5Eu7tCKjGbI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4726d966-7021-4a0d-f55a-f901bd752dfd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           20           1.0\n",
            "1   [2024-02, 2024-03]            2           20           1.0\n",
            "2   [2024-03, 2024-04]            2           20           1.0\n",
            "3   [2024-04, 2024-05]            2           20           1.0\n",
            "4   [2024-05, 2024-06]            2           20           1.0\n",
            "5   [2024-06, 2024-07]            2           20           1.0\n",
            "6   [2024-07, 2024-08]            2           20           1.0\n",
            "7   [2024-08, 2024-09]            2           20           1.0\n",
            "8   [2024-09, 2024-10]            2           20           1.0\n",
            "9   [2024-10, 2024-11]            2           20           1.0\n",
            "10  [2024-11, 2024-12]            2           20           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           40           1.0\n",
            "1   [2024-02, 2024-03]            2           40           1.0\n",
            "2   [2024-03, 2024-04]            2           40           1.0\n",
            "3   [2024-04, 2024-05]            2           40           1.0\n",
            "4   [2024-05, 2024-06]            2           40           1.0\n",
            "5   [2024-06, 2024-07]            2           40           1.0\n",
            "6   [2024-07, 2024-08]            2           40           1.0\n",
            "7   [2024-08, 2024-09]            2           40           1.0\n",
            "8   [2024-09, 2024-10]            2           40           1.0\n",
            "9   [2024-10, 2024-11]            2           40           1.0\n",
            "10  [2024-11, 2024-12]            2           40           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           60           1.0\n",
            "1   [2024-02, 2024-03]            2           60           1.0\n",
            "2   [2024-03, 2024-04]            2           60           1.0\n",
            "3   [2024-04, 2024-05]            2           60           1.0\n",
            "4   [2024-05, 2024-06]            2           60           1.0\n",
            "5   [2024-06, 2024-07]            2           60           1.0\n",
            "6   [2024-07, 2024-08]            2           60           1.0\n",
            "7   [2024-08, 2024-09]            2           60           1.0\n",
            "8   [2024-09, 2024-10]            2           60           1.0\n",
            "9   [2024-10, 2024-11]            2           60           1.0\n",
            "10  [2024-11, 2024-12]            2           60           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           80           1.0\n",
            "1   [2024-02, 2024-03]            2           80           1.0\n",
            "2   [2024-03, 2024-04]            2           80           1.0\n",
            "3   [2024-04, 2024-05]            2           80           1.0\n",
            "4   [2024-05, 2024-06]            2           80           1.0\n",
            "5   [2024-06, 2024-07]            2           80           1.0\n",
            "6   [2024-07, 2024-08]            2           80           1.0\n",
            "7   [2024-08, 2024-09]            2           80           1.0\n",
            "8   [2024-09, 2024-10]            2           80           1.0\n",
            "9   [2024-10, 2024-11]            2           80           1.0\n",
            "10  [2024-11, 2024-12]            2           80           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2          100           1.0\n",
            "1   [2024-02, 2024-03]            2          100           1.0\n",
            "2   [2024-03, 2024-04]            2          100           1.0\n",
            "3   [2024-04, 2024-05]            2          100           1.0\n",
            "4   [2024-05, 2024-06]            2          100           1.0\n",
            "5   [2024-06, 2024-07]            2          100           1.0\n",
            "6   [2024-07, 2024-08]            2          100           1.0\n",
            "7   [2024-08, 2024-09]            2          100           1.0\n",
            "8   [2024-09, 2024-10]            2          100           1.0\n",
            "9   [2024-10, 2024-11]            2          100           1.0\n",
            "10  [2024-11, 2024-12]            2          100           1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS2, 4 mesi di dati"
      ],
      "metadata": {
        "id": "j4Hg2RlJhBuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS2_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS2_20[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS2_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS2_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS2_40[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS2_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS2_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS2_60[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS2_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS2_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS2_80[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS2_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS2_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS2_100[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS2_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS2_100)"
      ],
      "metadata": {
        "id": "N8ThHGY4jZ05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21de62a5-a50d-412e-c77f-837d4547f856"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           20   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           20   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           20   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           20   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           20   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           20   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           20   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           20   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           20   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           40   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           40   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           40   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           40   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           40   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           40   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           40   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           40   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           40   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           60   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           60   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           60   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           60   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           60   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           60   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           60   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           60   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           60   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           80   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           80   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           80   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           80   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           80   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           80   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           80   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           80   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           80   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4          100   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4          100   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4          100   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4          100   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4          100   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4          100   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4          100   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4          100   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4          100   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS2, 6 mesi di dati"
      ],
      "metadata": {
        "id": "xKdpPgJbhB04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS2_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS2_20[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS2_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS2_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS2_40[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS2_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS2_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS2_60[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS2_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS2_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS2_80[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS2_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS2_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS2_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS2\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS2_100[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS2_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS2_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlhAYI-qjq98",
        "outputId": "9457a0f9-1935-47ea-ce9c-45bb422164a8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           20           1.0  \n",
            "1           20           1.0  \n",
            "2           20           1.0  \n",
            "3           20           1.0  \n",
            "4           20           1.0  \n",
            "5           20           1.0  \n",
            "6           20           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           40           1.0  \n",
            "1           40           1.0  \n",
            "2           40           1.0  \n",
            "3           40           1.0  \n",
            "4           40           1.0  \n",
            "5           40           1.0  \n",
            "6           40           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           60           1.0  \n",
            "1           60           1.0  \n",
            "2           60           1.0  \n",
            "3           60           1.0  \n",
            "4           60           1.0  \n",
            "5           60           1.0  \n",
            "6           60           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           80           1.0  \n",
            "1           80           1.0  \n",
            "2           80           1.0  \n",
            "3           80           1.0  \n",
            "4           80           1.0  \n",
            "5           80           1.0  \n",
            "6           80           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0          100           1.0  \n",
            "1          100           1.0  \n",
            "2          100           1.0  \n",
            "3          100           1.0  \n",
            "4          100           1.0  \n",
            "5          100           1.0  \n",
            "6          100           1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS3, 1 mese di dati"
      ],
      "metadata": {
        "id": "vsjBfCVEhB7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS3_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS3_20[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS3_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS3_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS3_40[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS3_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS3_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS3_60[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS3_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS3_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS3_80[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS3_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS3_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS3_100[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS3_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS3_100)"
      ],
      "metadata": {
        "id": "CS3f8VgIj76Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8aa74c83-9e5a-4d57-9b0e-5ee5c3ee2b3c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           20           1.0\n",
            "1     [2024-02]            1           20           1.0\n",
            "2     [2024-03]            1           20           1.0\n",
            "3     [2024-04]            1           20           1.0\n",
            "4     [2024-05]            1           20           1.0\n",
            "5     [2024-06]            1           20           1.0\n",
            "6     [2024-07]            1           20           1.0\n",
            "7     [2024-08]            1           20           1.0\n",
            "8     [2024-09]            1           20           1.0\n",
            "9     [2024-10]            1           20           1.0\n",
            "10    [2024-11]            1           20           1.0\n",
            "11    [2024-12]            1           20           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           40           1.0\n",
            "1     [2024-02]            1           40           1.0\n",
            "2     [2024-03]            1           40           1.0\n",
            "3     [2024-04]            1           40           1.0\n",
            "4     [2024-05]            1           40           1.0\n",
            "5     [2024-06]            1           40           1.0\n",
            "6     [2024-07]            1           40           1.0\n",
            "7     [2024-08]            1           40           1.0\n",
            "8     [2024-09]            1           40           1.0\n",
            "9     [2024-10]            1           40           1.0\n",
            "10    [2024-11]            1           40           1.0\n",
            "11    [2024-12]            1           40           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           60           1.0\n",
            "1     [2024-02]            1           60           1.0\n",
            "2     [2024-03]            1           60           1.0\n",
            "3     [2024-04]            1           60           1.0\n",
            "4     [2024-05]            1           60           1.0\n",
            "5     [2024-06]            1           60           1.0\n",
            "6     [2024-07]            1           60           1.0\n",
            "7     [2024-08]            1           60           1.0\n",
            "8     [2024-09]            1           60           1.0\n",
            "9     [2024-10]            1           60           1.0\n",
            "10    [2024-11]            1           60           1.0\n",
            "11    [2024-12]            1           60           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           80           1.0\n",
            "1     [2024-02]            1           80           1.0\n",
            "2     [2024-03]            1           80           1.0\n",
            "3     [2024-04]            1           80           1.0\n",
            "4     [2024-05]            1           80           1.0\n",
            "5     [2024-06]            1           80           1.0\n",
            "6     [2024-07]            1           80           1.0\n",
            "7     [2024-08]            1           80           1.0\n",
            "8     [2024-09]            1           80           1.0\n",
            "9     [2024-10]            1           80           1.0\n",
            "10    [2024-11]            1           80           1.0\n",
            "11    [2024-12]            1           80           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1          100           1.0\n",
            "1     [2024-02]            1          100           1.0\n",
            "2     [2024-03]            1          100           1.0\n",
            "3     [2024-04]            1          100           1.0\n",
            "4     [2024-05]            1          100           1.0\n",
            "5     [2024-06]            1          100           1.0\n",
            "6     [2024-07]            1          100           1.0\n",
            "7     [2024-08]            1          100           1.0\n",
            "8     [2024-09]            1          100           1.0\n",
            "9     [2024-10]            1          100           1.0\n",
            "10    [2024-11]            1          100           1.0\n",
            "11    [2024-12]            1          100           1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS3, 2 mesi di dati"
      ],
      "metadata": {
        "id": "JgMLgffPhCAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS3_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS3_20[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS3_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS3_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS3_40[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS3_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS3_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS3_60[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS3_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS3_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS3_80[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS3_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS3_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS3_100[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS3_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS3_100)"
      ],
      "metadata": {
        "id": "c_XgtWMkkbnA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa713e50-1064-4f4b-d34a-e8e6db71af16"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           20           1.0\n",
            "1   [2024-02, 2024-03]            2           20           1.0\n",
            "2   [2024-03, 2024-04]            2           20           1.0\n",
            "3   [2024-04, 2024-05]            2           20           1.0\n",
            "4   [2024-05, 2024-06]            2           20           1.0\n",
            "5   [2024-06, 2024-07]            2           20           1.0\n",
            "6   [2024-07, 2024-08]            2           20           1.0\n",
            "7   [2024-08, 2024-09]            2           20           1.0\n",
            "8   [2024-09, 2024-10]            2           20           1.0\n",
            "9   [2024-10, 2024-11]            2           20           1.0\n",
            "10  [2024-11, 2024-12]            2           20           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           40           1.0\n",
            "1   [2024-02, 2024-03]            2           40           1.0\n",
            "2   [2024-03, 2024-04]            2           40           1.0\n",
            "3   [2024-04, 2024-05]            2           40           1.0\n",
            "4   [2024-05, 2024-06]            2           40           1.0\n",
            "5   [2024-06, 2024-07]            2           40           1.0\n",
            "6   [2024-07, 2024-08]            2           40           1.0\n",
            "7   [2024-08, 2024-09]            2           40           1.0\n",
            "8   [2024-09, 2024-10]            2           40           1.0\n",
            "9   [2024-10, 2024-11]            2           40           1.0\n",
            "10  [2024-11, 2024-12]            2           40           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           60           1.0\n",
            "1   [2024-02, 2024-03]            2           60           1.0\n",
            "2   [2024-03, 2024-04]            2           60           1.0\n",
            "3   [2024-04, 2024-05]            2           60           1.0\n",
            "4   [2024-05, 2024-06]            2           60           1.0\n",
            "5   [2024-06, 2024-07]            2           60           1.0\n",
            "6   [2024-07, 2024-08]            2           60           1.0\n",
            "7   [2024-08, 2024-09]            2           60           1.0\n",
            "8   [2024-09, 2024-10]            2           60           1.0\n",
            "9   [2024-10, 2024-11]            2           60           1.0\n",
            "10  [2024-11, 2024-12]            2           60           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           80           1.0\n",
            "1   [2024-02, 2024-03]            2           80           1.0\n",
            "2   [2024-03, 2024-04]            2           80           1.0\n",
            "3   [2024-04, 2024-05]            2           80           1.0\n",
            "4   [2024-05, 2024-06]            2           80           1.0\n",
            "5   [2024-06, 2024-07]            2           80           1.0\n",
            "6   [2024-07, 2024-08]            2           80           1.0\n",
            "7   [2024-08, 2024-09]            2           80           1.0\n",
            "8   [2024-09, 2024-10]            2           80           1.0\n",
            "9   [2024-10, 2024-11]            2           80           1.0\n",
            "10  [2024-11, 2024-12]            2           80           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2          100           1.0\n",
            "1   [2024-02, 2024-03]            2          100           1.0\n",
            "2   [2024-03, 2024-04]            2          100           1.0\n",
            "3   [2024-04, 2024-05]            2          100           1.0\n",
            "4   [2024-05, 2024-06]            2          100           1.0\n",
            "5   [2024-06, 2024-07]            2          100           1.0\n",
            "6   [2024-07, 2024-08]            2          100           1.0\n",
            "7   [2024-08, 2024-09]            2          100           1.0\n",
            "8   [2024-09, 2024-10]            2          100           1.0\n",
            "9   [2024-10, 2024-11]            2          100           1.0\n",
            "10  [2024-11, 2024-12]            2          100           1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS3, 4 mesi di dati"
      ],
      "metadata": {
        "id": "wz9Uz6kXhCGJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS3_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS3_20[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS3_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS3_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS3_40[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS3_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS3_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS3_60[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS3_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS3_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS3_80[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS3_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS3_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS3_100[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS3_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS3_100)"
      ],
      "metadata": {
        "id": "ib2ZhmZKkzxD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d3a77df-08ab-4ac2-e766-7caa514892a2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           20   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           20   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           20   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           20   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           20   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           20   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           20   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           20   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           20   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           40   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           40   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           40   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           40   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           40   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           40   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           40   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           40   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           40   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           60   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           60   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           60   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           60   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           60   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           60   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           60   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           60   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           60   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           80   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           80   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           80   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           80   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           80   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           80   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           80   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           80   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           80   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4          100   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4          100   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4          100   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4          100   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4          100   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4          100   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4          100   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4          100   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4          100   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS3, 6 mesi di dati"
      ],
      "metadata": {
        "id": "2yRjK8QjhCL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS3_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS3_20[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS3_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS3_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS3_40[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS3_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS3_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS3_60[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS3_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS3_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS3_80[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS3_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS3_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS3_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS3\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS3_100[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS3_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS3_100)"
      ],
      "metadata": {
        "id": "660lwddulJi9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4fc916b-4d9e-42bc-f326-2a083209beb8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           20           1.0  \n",
            "1           20           1.0  \n",
            "2           20           1.0  \n",
            "3           20           1.0  \n",
            "4           20           1.0  \n",
            "5           20           1.0  \n",
            "6           20           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           40           1.0  \n",
            "1           40           1.0  \n",
            "2           40           1.0  \n",
            "3           40           1.0  \n",
            "4           40           1.0  \n",
            "5           40           1.0  \n",
            "6           40           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           60           1.0  \n",
            "1           60           1.0  \n",
            "2           60           1.0  \n",
            "3           60           1.0  \n",
            "4           60           1.0  \n",
            "5           60           1.0  \n",
            "6           60           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           80           1.0  \n",
            "1           80           1.0  \n",
            "2           80           1.0  \n",
            "3           80           1.0  \n",
            "4           80           1.0  \n",
            "5           80           1.0  \n",
            "6           80           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0          100           1.0  \n",
            "1          100           1.0  \n",
            "2          100           1.0  \n",
            "3          100           1.0  \n",
            "4          100           1.0  \n",
            "5          100           1.0  \n",
            "6          100           1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS4, 1 mese di dati"
      ],
      "metadata": {
        "id": "3K9Ggcn8hCSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS4_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS4_20[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS4_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS4_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS4_40[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS4_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS4_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS4_60[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS4_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS4_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS4_80[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS4_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS4_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 1\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS4_100[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_1month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_1m_anomaly_DS4_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_1m_anomaly_DS4_100)"
      ],
      "metadata": {
        "id": "-k-HMfA_lbLJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7111b788-2b8b-43fa-e482-b050c2004ef4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           20           1.0\n",
            "1     [2024-02]            1           20           1.0\n",
            "2     [2024-03]            1           20           1.0\n",
            "3     [2024-04]            1           20           1.0\n",
            "4     [2024-05]            1           20           1.0\n",
            "5     [2024-06]            1           20           1.0\n",
            "6     [2024-07]            1           20           1.0\n",
            "7     [2024-08]            1           20           1.0\n",
            "8     [2024-09]            1           20           1.0\n",
            "9     [2024-10]            1           20           1.0\n",
            "10    [2024-11]            1           20           1.0\n",
            "11    [2024-12]            1           20           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           40           1.0\n",
            "1     [2024-02]            1           40           1.0\n",
            "2     [2024-03]            1           40           1.0\n",
            "3     [2024-04]            1           40           1.0\n",
            "4     [2024-05]            1           40           1.0\n",
            "5     [2024-06]            1           40           1.0\n",
            "6     [2024-07]            1           40           1.0\n",
            "7     [2024-08]            1           40           1.0\n",
            "8     [2024-09]            1           40           1.0\n",
            "9     [2024-10]            1           40           1.0\n",
            "10    [2024-11]            1           40           1.0\n",
            "11    [2024-12]            1           40           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           60           1.0\n",
            "1     [2024-02]            1           60           1.0\n",
            "2     [2024-03]            1           60           1.0\n",
            "3     [2024-04]            1           60           1.0\n",
            "4     [2024-05]            1           60           1.0\n",
            "5     [2024-06]            1           60           1.0\n",
            "6     [2024-07]            1           60           1.0\n",
            "7     [2024-08]            1           60           1.0\n",
            "8     [2024-09]            1           60           1.0\n",
            "9     [2024-10]            1           60           1.0\n",
            "10    [2024-11]            1           60           1.0\n",
            "11    [2024-12]            1           60           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1           80           1.0\n",
            "1     [2024-02]            1           80           1.0\n",
            "2     [2024-03]            1           80           1.0\n",
            "3     [2024-04]            1           80           1.0\n",
            "4     [2024-05]            1           80           1.0\n",
            "5     [2024-06]            1           80           1.0\n",
            "6     [2024-07]            1           80           1.0\n",
            "7     [2024-08]            1           80           1.0\n",
            "8     [2024-09]            1           80           1.0\n",
            "9     [2024-10]            1           80           1.0\n",
            "10    [2024-11]            1           80           1.0\n",
            "11    [2024-12]            1           80           1.0\n",
            "\n",
            "    train_months  window_size  damage size  anomaly rate\n",
            "0     [2024-01]            1          100           1.0\n",
            "1     [2024-02]            1          100           1.0\n",
            "2     [2024-03]            1          100           1.0\n",
            "3     [2024-04]            1          100           1.0\n",
            "4     [2024-05]            1          100           1.0\n",
            "5     [2024-06]            1          100           1.0\n",
            "6     [2024-07]            1          100           1.0\n",
            "7     [2024-08]            1          100           1.0\n",
            "8     [2024-09]            1          100           1.0\n",
            "9     [2024-10]            1          100           1.0\n",
            "10    [2024-11]            1          100           1.0\n",
            "11    [2024-12]            1          100           1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS4, 2 mesi di dati"
      ],
      "metadata": {
        "id": "GgHX6x3thCYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS4_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS4_20[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS4_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS4_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS4_40[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS4_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS4_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS4_60[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS4_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS4_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS4_80[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS4_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS4_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 2\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS4_100[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_2month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_2m_anomaly_DS4_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_2m_anomaly_DS4_100)"
      ],
      "metadata": {
        "id": "3HGkrLsdl2Ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6680b0e-04fb-4edf-eeea-220d8d38c2e5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           20           1.0\n",
            "1   [2024-02, 2024-03]            2           20           1.0\n",
            "2   [2024-03, 2024-04]            2           20           1.0\n",
            "3   [2024-04, 2024-05]            2           20           1.0\n",
            "4   [2024-05, 2024-06]            2           20           1.0\n",
            "5   [2024-06, 2024-07]            2           20           1.0\n",
            "6   [2024-07, 2024-08]            2           20           1.0\n",
            "7   [2024-08, 2024-09]            2           20           1.0\n",
            "8   [2024-09, 2024-10]            2           20           1.0\n",
            "9   [2024-10, 2024-11]            2           20           1.0\n",
            "10  [2024-11, 2024-12]            2           20           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           40           1.0\n",
            "1   [2024-02, 2024-03]            2           40           1.0\n",
            "2   [2024-03, 2024-04]            2           40           1.0\n",
            "3   [2024-04, 2024-05]            2           40           1.0\n",
            "4   [2024-05, 2024-06]            2           40           1.0\n",
            "5   [2024-06, 2024-07]            2           40           1.0\n",
            "6   [2024-07, 2024-08]            2           40           1.0\n",
            "7   [2024-08, 2024-09]            2           40           1.0\n",
            "8   [2024-09, 2024-10]            2           40           1.0\n",
            "9   [2024-10, 2024-11]            2           40           1.0\n",
            "10  [2024-11, 2024-12]            2           40           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           60           1.0\n",
            "1   [2024-02, 2024-03]            2           60           1.0\n",
            "2   [2024-03, 2024-04]            2           60           1.0\n",
            "3   [2024-04, 2024-05]            2           60           1.0\n",
            "4   [2024-05, 2024-06]            2           60           1.0\n",
            "5   [2024-06, 2024-07]            2           60           1.0\n",
            "6   [2024-07, 2024-08]            2           60           1.0\n",
            "7   [2024-08, 2024-09]            2           60           1.0\n",
            "8   [2024-09, 2024-10]            2           60           1.0\n",
            "9   [2024-10, 2024-11]            2           60           1.0\n",
            "10  [2024-11, 2024-12]            2           60           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2           80           1.0\n",
            "1   [2024-02, 2024-03]            2           80           1.0\n",
            "2   [2024-03, 2024-04]            2           80           1.0\n",
            "3   [2024-04, 2024-05]            2           80           1.0\n",
            "4   [2024-05, 2024-06]            2           80           1.0\n",
            "5   [2024-06, 2024-07]            2           80           1.0\n",
            "6   [2024-07, 2024-08]            2           80           1.0\n",
            "7   [2024-08, 2024-09]            2           80           1.0\n",
            "8   [2024-09, 2024-10]            2           80           1.0\n",
            "9   [2024-10, 2024-11]            2           80           1.0\n",
            "10  [2024-11, 2024-12]            2           80           1.0\n",
            "\n",
            "           train_months  window_size  damage size  anomaly rate\n",
            "0   [2024-01, 2024-02]            2          100           1.0\n",
            "1   [2024-02, 2024-03]            2          100           1.0\n",
            "2   [2024-03, 2024-04]            2          100           1.0\n",
            "3   [2024-04, 2024-05]            2          100           1.0\n",
            "4   [2024-05, 2024-06]            2          100           1.0\n",
            "5   [2024-06, 2024-07]            2          100           1.0\n",
            "6   [2024-07, 2024-08]            2          100           1.0\n",
            "7   [2024-08, 2024-09]            2          100           1.0\n",
            "8   [2024-09, 2024-10]            2          100           1.0\n",
            "9   [2024-10, 2024-11]            2          100           1.0\n",
            "10  [2024-11, 2024-12]            2          100           1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS4, 4 mesi di dati"
      ],
      "metadata": {
        "id": "F_MHaP8YhCdP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS4_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS4_20[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS4_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS4_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS4_40[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS4_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS4_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS4_60[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS4_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS4_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS4_80[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS4_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS4_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 4\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS4_100[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_4month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_4m_anomaly_DS4_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_4m_anomaly_DS4_100)"
      ],
      "metadata": {
        "id": "FwmbnoqwmLxf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dbcdbc3-0594-4df4-8ee6-4a5a9b823120"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           20   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           20   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           20   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           20   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           20   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           20   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           20   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           20   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           20   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           40   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           40   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           40   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           40   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           40   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           40   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           40   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           40   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           40   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           60   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           60   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           60   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           60   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           60   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           60   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           60   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           60   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           60   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4           80   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4           80   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4           80   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4           80   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4           80   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4           80   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4           80   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4           80   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4           80   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n",
            "\n",
            "                            train_months  window_size  damage size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04]            4          100   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05]            4          100   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06]            4          100   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07]            4          100   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08]            4          100   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09]            4          100   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10]            4          100   \n",
            "7  [2024-08, 2024-09, 2024-10, 2024-11]            4          100   \n",
            "8  [2024-09, 2024-10, 2024-11, 2024-12]            4          100   \n",
            "\n",
            "   anomaly rate  \n",
            "0           1.0  \n",
            "1           1.0  \n",
            "2           1.0  \n",
            "3           1.0  \n",
            "4           1.0  \n",
            "5           1.0  \n",
            "6           1.0  \n",
            "7           1.0  \n",
            "8           1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario di danno DS4, 6 mesi di dati"
      ],
      "metadata": {
        "id": "ctk-T5ZEhC1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_DS4_20 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 20)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS4_20[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":20, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS4_20 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS4_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_40 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 40)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS4_40[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":40, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS4_40 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS4_40)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_60 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 60)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS4_60[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":60, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS4_60 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS4_60)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_80 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 80)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS4_80[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":80, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS4_80 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS4_80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_DS4_100 = df_anomaly[(df_anomaly[\"Damage Scenario\"] == \"DS4\") & (df_anomaly[\"Damage Size\"] == 100)]\n",
        "\n",
        "#parametri\n",
        "features = [\"Mode 1\", \"Mode 2\", \"Mode 3\", \"Mode 4\", \"Mode 5\", \"Mode 6\", \"temperatura\"]\n",
        "results = []\n",
        "window_size = 6\n",
        "n_months = 12\n",
        "start_date = new_df[\"timestamp\"].min()\n",
        "\n",
        "for m in range(1, n_months - window_size + 2):\n",
        "  train_start = start_date + pd.DateOffset(months=m-1)\n",
        "  train_end = start_date + pd.DateOffset(months=m-1+window_size)\n",
        "  train_data = new_df[(new_df[\"timestamp\"] >= train_start) & (new_df[\"timestamp\"] < train_end)]\n",
        "\n",
        "  scaler_X = StandardScaler()\n",
        "\n",
        "  X_train = scaler_X.fit_transform(train_data[features])\n",
        "  X_val = scaler_X.transform(df_DS4_100[features])\n",
        "\n",
        "  Y_train = X_train[:, :6]\n",
        "  Y_val = X_val[:, :6]\n",
        "\n",
        "  vae_temp = VAE_temp(input_dim=X_train.shape[1], output_dim=Y_train.shape[1], latent_dim=2)\n",
        "\n",
        "\n",
        "  # Inizializzare il modello con tensori dummy\n",
        "  dummy_x = tf.zeros((1, X_train.shape[1]))\n",
        "  _ = vae_temp(dummy_x)\n",
        "\n",
        "  vae_temp.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "  vae_temp.load_weights(f\"/content/drive/MyDrive/VAE_temp_6month_{m}.weights.h5\")\n",
        "\n",
        "\n",
        "  #calcolo della soglia su dati normali\n",
        "  X_pred_train = vae_temp.predict(X_train, verbose=0)\n",
        "  mse_train = np.mean(np.square(Y_train - X_pred_train), axis=1)\n",
        "  mean_mse = np.mean(mse_train)\n",
        "  std_mse = np.std(mse_train)\n",
        "  threshold = mean_mse + 3 * std_mse\n",
        "\n",
        "  X_pred = vae_temp.predict(X_val, verbose=0)\n",
        "  mse = np.mean(np.square(Y_val - X_pred), axis=1)\n",
        "\n",
        "  anomalies = mse > threshold\n",
        "  anomaly_rate = np.mean(anomalies)\n",
        "\n",
        "  train_months = sorted(train_data[\"timestamp\"].dt.to_period(\"M\").unique())\n",
        "  results.append({\"train_months\": [str(x) for x in train_months], \"window_size\": len(train_months),  \"damage size\":100, \"anomaly rate\": anomaly_rate})\n",
        "\n",
        "results_df_6m_anomaly_DS4_100 = pd.DataFrame(results)\n",
        "print(\"\\n\", results_df_6m_anomaly_DS4_100)"
      ],
      "metadata": {
        "id": "6IP6s8MDmxK7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "035f3028-94c7-46ad-d955-2430a4ad41eb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           20           1.0  \n",
            "1           20           1.0  \n",
            "2           20           1.0  \n",
            "3           20           1.0  \n",
            "4           20           1.0  \n",
            "5           20           1.0  \n",
            "6           20           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           40           1.0  \n",
            "1           40           1.0  \n",
            "2           40           1.0  \n",
            "3           40           1.0  \n",
            "4           40           1.0  \n",
            "5           40           1.0  \n",
            "6           40           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           60           1.0  \n",
            "1           60           1.0  \n",
            "2           60           1.0  \n",
            "3           60           1.0  \n",
            "4           60           1.0  \n",
            "5           60           1.0  \n",
            "6           60           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0           80           1.0  \n",
            "1           80           1.0  \n",
            "2           80           1.0  \n",
            "3           80           1.0  \n",
            "4           80           1.0  \n",
            "5           80           1.0  \n",
            "6           80           1.0  \n",
            "\n",
            "                                         train_months  window_size  \\\n",
            "0  [2024-01, 2024-02, 2024-03, 2024-04, 2024-05, ...            6   \n",
            "1  [2024-02, 2024-03, 2024-04, 2024-05, 2024-06, ...            6   \n",
            "2  [2024-03, 2024-04, 2024-05, 2024-06, 2024-07, ...            6   \n",
            "3  [2024-04, 2024-05, 2024-06, 2024-07, 2024-08, ...            6   \n",
            "4  [2024-05, 2024-06, 2024-07, 2024-08, 2024-09, ...            6   \n",
            "5  [2024-06, 2024-07, 2024-08, 2024-09, 2024-10, ...            6   \n",
            "6  [2024-07, 2024-08, 2024-09, 2024-10, 2024-11, ...            6   \n",
            "\n",
            "   damage size  anomaly rate  \n",
            "0          100           1.0  \n",
            "1          100           1.0  \n",
            "2          100           1.0  \n",
            "3          100           1.0  \n",
            "4          100           1.0  \n",
            "5          100           1.0  \n",
            "6          100           1.0  \n"
          ]
        }
      ]
    }
  ]
}